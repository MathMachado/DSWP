{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "fork-of-notebook1ca06f35f5.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryssoga/DSWP/blob/master/fork_of_notebook1ca06f35f5_crys_hyper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "KOsmZI4lt9t8"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "JWK9wJ-_t9uE"
      },
      "source": [
        "#df = pd.read_csv('/kaggle/input/labdata-churn-challenge-2020/train.csv')\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOPOEiuuXb-"
      },
      "source": [
        "# eu\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "\n",
        "url_train = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/test.csv'\n",
        "url_sample_submission = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/sample_submission.csv'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)\n",
        "df_sample_submission = pd.read_csv(url_sample_submission)\n",
        "\n",
        "df = df_train.copy()\n",
        "df_teste = df_test.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgchNcw2Kes_"
      },
      "source": [
        "df_sample_submission.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UJHhWh9KiYu"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWKsLD00KwmX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ERJfKIfOt9uM"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Nj2DFFRNt9uT"
      },
      "source": [
        "df_churn = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNVOd-U9uzXe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mgT2KGJBt9ub"
      },
      "source": [
        "df_churn.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iX0DMBegt9ug"
      },
      "source": [
        "df_churn.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jkprrLqCt9uk"
      },
      "source": [
        "df_churn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R3hg6GGQt9us"
      },
      "source": [
        "df_churn['Churn'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MFUqmH2Bt9uz"
      },
      "source": [
        "#df_teste = pd.read_csv('/kaggle/input/labdata-churn-challenge-2020/test.csv')\n",
        "#df_teste.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw59Z8COt9u6"
      },
      "source": [
        "Tratamento dos NaN's: Mediana e Moda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mt8yBGPat9u7"
      },
      "source": [
        "df_churn.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJStLm07t9u_"
      },
      "source": [
        "Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9vSe45kBt9vA"
      },
      "source": [
        "def f_trata_outliers(df):\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        df[i][df[i] < lim_inf] = lim_inf\n",
        "        df[i][df[i] > lim_sup] = lim_sup\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S-Y2TJ-Gt9vE"
      },
      "source": [
        "def f_trata_col(df):\n",
        "    df.columns = df.columns.str.lower()\n",
        "    df['tenure'] = df['tenure'].fillna(df['tenure'].median())\n",
        "    df['totalcharges'][df['totalcharges'] == ' '] = df['totalcharges'].notna().median()\n",
        "    df['totalcharges'] = pd.to_numeric(df['totalcharges'])\n",
        "    df = f_trata_outliers(df)\n",
        "    ohe = pd.get_dummies(df)\n",
        "    return ohe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jz-4KOA0t9vK"
      },
      "source": [
        "df_churn = f_trata_col(df_churn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i57fUZmDt9vP"
      },
      "source": [
        "df_X = df_churn.drop(columns= 'churn', axis= 1)\n",
        "df_y = df_churn['churn']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1G0I_EKLjQk"
      },
      "source": [
        "df_teste = f_trata_col(df_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-79A_gsLpPJ"
      },
      "source": [
        "df_teste.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8J8ej6t9vT"
      },
      "source": [
        "MODELO: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O_8spMrGt9vU"
      },
      "source": [
        "i_CV = 10 # Número de Cross-Validations\n",
        "i_Seed = 22091980 # semente por questões de reproducibilidade\n",
        "# f_Test_Size = 0.3 # Proporção do dataframe de validação (outros valores poderiam ser 0.15, 0.20 ou 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eDY6msH0t9vY"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(df_X, df_y, test_size = f_Test_Size, random_state = i_Seed)\n",
        "\n",
        "y_teste = df_sample_submission['Churn']\n",
        "X_treinamento = df_X.copy()\n",
        "y_treinamento = df_y.copy()\n",
        "X_teste = df_teste.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvjefldsvLkG"
      },
      "source": [
        "f'\"X_treinamento.shape:\" {X_treinamento.shape}, \"y_treinamento_shape:\"{y_treinamento.shape},\"X_teste.shape:\"{X_teste.shape},\"y_teste.shape:\"{y_teste.shape}'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8sEAItOvNlO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xjUjFaykt9vf"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Instancia...\n",
        "ml_XGB= XGBClassifier(silent=False, \n",
        "                         scale_pos_weight=1,\n",
        "                        learning_rate=0.01,  \n",
        "                        colsample_bytree = 1,\n",
        "                        subsample = 0.8,\n",
        "                        objective='binary:logistic', \n",
        "                        n_estimators=1000, \n",
        "                        reg_alpha = 0.3,\n",
        "                        max_depth= 3, \n",
        "                        gamma=1, \n",
        "                        max_delta_step=5)\n",
        "\n",
        "# Treina... \n",
        "ml_XGB.fit(X_treinamento, y_treinamento)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WNW3FqS6t9vl"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4EH4l3lAt9vo"
      },
      "source": [
        "def funcao_cross_val_score(modelo, X_treinamento, y_treinamento, CV):\n",
        "    #versão com cross_val_score::\n",
        "    a_scores_CV = cross_val_score(modelo, X_treinamento, y_treinamento, cv = CV)\n",
        "    print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "    print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "    return a_scores_CV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OpfEVbVNt9vt"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB, X_treinamento, y_treinamento, i_CV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3YR5pimot9vz"
      },
      "source": [
        "y_pred = ml_XGB.predict(X_teste)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4vLhKwMn_IV"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbwTsGMZoCDf"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iQhLNFkyt9v5"
      },
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "cf_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i1AWis2Xt9v-"
      },
      "source": [
        "ml_XGB.fit(df_X, df_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oWoxfLE1t9wC"
      },
      "source": [
        "#df_teste_submit = f_trata_col(df_teste)\n",
        "df_teste_submit = df_teste.copy()\n",
        "df_teste_submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XIQCm5jCt9wJ"
      },
      "source": [
        "y_teste_submit = ml_XGB.predict(df_teste_submit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T9LGBShGt9wQ"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(df_teste_submit['id'],y_teste_submit), columns = ['id','Churn'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MzStMVKLt9wU"
      },
      "source": [
        "df_submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zUM9gFa1t9wa"
      },
      "source": [
        "df_submit.to_csv('submit12.csv',index = False, sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jlaC52Xat9we"
      },
      "source": [
        "df_submit.Churn.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW0venFNJW67"
      },
      "source": [
        "df_sample_submission['Churn'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWHKDCPTZYrG"
      },
      "source": [
        "734/1105"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0UNTOG3o5lo"
      },
      "source": [
        "#\n",
        "# 05/11/2020\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrFUEpDrqSpI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap3WMXqDthu9"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV # para otimizar os hiperparâmetros dos modelos preditivos\n",
        "from sklearn.model_selection import cross_val_score # Para o CV (Cross-Validation)\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from time import time\n",
        "from operator import itemgetter\n",
        "from scipy.stats import randint\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def GridSearchOptimizer(modelo, ml_Opt, d_hiperparametros, X_treinamento, y_treinamento, X_teste, y_teste, i_CV, l_colunas):\n",
        "    ml_GridSearchCV = GridSearchCV(modelo, d_hiperparametros, cv = i_CV, n_jobs = -1, verbose= 10, scoring = 'accuracy')\n",
        "    start = time()\n",
        "    ml_GridSearchCV.fit(X_treinamento, y_treinamento)\n",
        "    tempo_elapsed = time()-start\n",
        "    #print(f\"\\nGridSearchCV levou {tempo_elapsed:.2f} segundos.\")\n",
        "\n",
        "    # Hiperparâmetros que otimizam a classificação:\n",
        "    print(f'\\nHiperparâmetros otimizados: {ml_GridSearchCV.best_params_}')\n",
        "    \n",
        "    if ml_Opt == 'ml_DT2':\n",
        "        print(f'\\nDecisionTreeClassifier *********************************************************************************************************')\n",
        "        ml_Opt = DecisionTreeClassifier(criterion= ml_GridSearchCV.best_params_['criterion'], \n",
        "                                        max_depth= ml_GridSearchCV.best_params_['max_depth'],\n",
        "                                        max_leaf_nodes= ml_GridSearchCV.best_params_['max_leaf_nodes'],\n",
        "                                        min_samples_split= ml_GridSearchCV.best_params_['min_samples_leaf'],\n",
        "                                        min_samples_leaf= ml_GridSearchCV.best_params_['min_samples_split'], \n",
        "                                        random_state= i_Seed)\n",
        "        \n",
        "    elif ml_Opt == 'ml_RF2':\n",
        "        print(f'\\nRandomForestClassifier *********************************************************************************************************')\n",
        "        ml_Opt = RandomForestClassifier(bootstrap= ml_GridSearchCV.best_params_['bootstrap'], \n",
        "                                        max_depth= ml_GridSearchCV.best_params_['max_depth'],\n",
        "                                        max_features= ml_GridSearchCV.best_params_['max_features'],\n",
        "                                        min_samples_leaf= ml_GridSearchCV.best_params_['min_samples_leaf'],\n",
        "                                        min_samples_split= ml_GridSearchCV.best_params_['min_samples_split'],\n",
        "                                        n_estimators= ml_GridSearchCV.best_params_['n_estimators'],\n",
        "                                        random_state= i_Seed)\n",
        "        \n",
        "    elif ml_Opt == 'ml_AB2':\n",
        "        print(f'\\nAdaBoostClassifier *********************************************************************************************************')\n",
        "        ml_Opt = AdaBoostClassifier(algorithm='SAMME.R', \n",
        "                                    base_estimator=RandomForestClassifier(bootstrap = False, \n",
        "                                                                          max_depth = 10, \n",
        "                                                                          max_features = 'auto', \n",
        "                                                                          min_samples_leaf = 1, \n",
        "                                                                          min_samples_split = 2, \n",
        "                                                                          n_estimators = 400), \n",
        "                                    learning_rate = ml_GridSearchCV.best_params_['learning_rate'], \n",
        "                                    n_estimators = ml_GridSearchCV.best_params_['n_estimators'], \n",
        "                                    random_state = i_Seed)\n",
        "        \n",
        "    elif ml_Opt == 'ml_GB2':\n",
        "        print(f'\\nGradientBoostingClassifier *********************************************************************************************************')\n",
        "        ml_Opt = GradientBoostingClassifier(learning_rate = ml_GridSearchCV.best_params_['learning_rate'], \n",
        "                                            n_estimators = ml_GridSearchCV.best_params_['n_estimators'], \n",
        "                                            max_depth = ml_GridSearchCV.best_params_['max_depth'], \n",
        "                                            min_samples_split = ml_GridSearchCV.best_params_['min_samples_split'], \n",
        "                                            min_samples_leaf = ml_GridSearchCV.best_params_['min_samples_leaf'], \n",
        "                                            max_features = ml_GridSearchCV.best_params_['max_features'])\n",
        "        \n",
        "    elif ml_Opt == 'ml_XGB2':\n",
        "        print(f'\\nXGBoostingClassifier *********************************************************************************************************')\n",
        "        ml_Opt = XGBoostingClassifier(learning_rate= ml_GridSearchCV.best_params_['learning_rate'], \n",
        "                                      max_depth= ml_GridSearchCV.best_params_['max_depth'], \n",
        "                                      colsample_bytree= ml_GridSearchCV.best_params_['colsample_bytree'], \n",
        "                                      subsample= ml_GridSearchCV.best_params_['subsample'], \n",
        "                                      gamma= ml_GridSearchCV.best_params_['gamma'], \n",
        "                                      min_child_weight= ml_GridSearchCV.best_params_['min_child_weight'])\n",
        "        \n",
        "    # Treina novamente usando os hiperparâmetros otimizados...\n",
        "    ml_Opt.fit(X_treinamento, y_treinamento)\n",
        "\n",
        "    # Cross-Validation com 10 folds\n",
        "    print(f'\\n********* CROSS-VALIDATION ***********')\n",
        "    a_scores_CV = funcao_cross_val_score(ml_Opt, X_treinamento, y_treinamento, i_CV)\n",
        "\n",
        "    # Faz predições com os hiperparâmetros otimizados...\n",
        "    y_pred = ml_Opt.predict(X_teste)\n",
        "  \n",
        "    # Importância das COLUNAS\n",
        "    print(f'\\n********* IMPORTÂNCIA DAS COLUNAS ***********')\n",
        "    df_importancia_variaveis = pd.DataFrame(zip(l_colunas, ml_Opt.feature_importances_), columns= ['coluna', 'importancia'])\n",
        "    df_importancia_variaveis = df_importancia_variaveis.sort_values(by= ['importancia'], ascending=False)\n",
        "    print(df_importancia_variaveis)\n",
        "\n",
        "    # Matriz de Confusão\n",
        "    print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "    cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "    cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "    cf_categories = ['Zero', 'One']\n",
        "    mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n",
        "\n",
        "    return ml_Opt, ml_GridSearchCV.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3MsUONPwIV9"
      },
      "source": [
        "# Dicionário de Hiperparâmetros para XGBoost:\n",
        "d_hiperparametros_XGB = {'min_child_weight': [i for i in np.arange(1, 13)]} #,\n",
        "#                'gamma': [i for i in np.arange(0, 5, 0.5)],\n",
        "#                'subsample': [0.6, 0.8, 1.0],\n",
        "#                'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "#                'max_depth': [3, 4, 5, 7, 9],\n",
        "#                'learning_rate': [i for i in np.arange(0.01, 1, 0.1)]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX27FCKmwSni"
      },
      "source": [
        "# Invoca a função\n",
        "\n",
        "l_colunas = X_treinamento.columns\n",
        "ml_XGB, best_params= GridSearchOptimizer(ml_XGB, 'ml_XGB2', d_hiperparametros_XGB, X_treinamento, y_treinamento, X_teste, y_teste, i_CV, l_colunas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7E0oyxEtbGi"
      },
      "source": [
        "# Como o procedimento acima levou 372 minutos para executar, então vou estimar ml_XGB2 abaixo usando os parâmetros acima estimados\n",
        "best_params= {'colsample_bytree': 0.8, 'gamma': 0.5, 'learning_rate': 0.51, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6}\n",
        "\n",
        "ml_XGB2= XGBClassifier(min_child_weight= best_params['min_child_weight'], \n",
        "                       gamma= best_params['gamma'], \n",
        "                       subsample= best_params['subsample'], \n",
        "                       colsample_bytree= best_params['colsample_bytree'], \n",
        "                       max_depth= best_params['max_depth'], \n",
        "                       learning_rate= best_params['learning_rate'], \n",
        "                       random_state= i_Seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPG3JZIpRZ-T"
      },
      "source": [
        "# SELECIONA AS COLUNAS IMPORTANTES\n",
        "\n",
        "# plot feature importance\n",
        "from xgboost import plot_importance\n",
        "\n",
        "xgb.plot_importance(ml_XGB2, color = 'red')\n",
        "plt.title('importance', fontsize = 20)\n",
        "plt.yticks(fontsize = 10)\n",
        "plt.ylabel('features', fontsize = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmpRC2lHW-KP"
      },
      "source": [
        "ml_XGB2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f9MIEBiyq-5"
      },
      "source": [
        "X_treinamento_XGB, X_teste_XGB= seleciona_colunas_relevantes(ml_XGB2, X_treinamento, X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huy18gKI5qad"
      },
      "source": [
        "# TREINA O CLASSIFICADOR COM AS COLUNAS RELEVANTES\n",
        "best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3-PaTdc5vZk"
      },
      "source": [
        "# Treina com as COLUNAS relevantes...\n",
        "ml_XGB2.fit(X_treinamento_XGB, y_treinamento)\n",
        "\n",
        "# Cross-Validation com 10 folds\n",
        "a_scores_CV = funcao_cross_val_score(ml_XGB2, X_treinamento_XGB, y_treinamento, i_CV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty3CecgTZbtF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcvY-VdL6VIZ"
      },
      "source": [
        "# VALIDA O MODELO USANDO O DATAFRAME X_TESTE\n",
        "\n",
        "y_pred_XGB = ml_XGB2.predict(X_teste_XGB)\n",
        "\n",
        "# Calcula acurácia\n",
        "accuracy_score(y_teste, y_pred_XGB)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}