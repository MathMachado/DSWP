{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio_RFB.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryssoga/DSWP/blob/master/Desafio_RFB_01_PyCaret_19nov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOPOEiuuXb-"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
        "%matplotlib inline\n",
        "\n",
        "url_train = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_test.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypwM33UBpCw"
      },
      "source": [
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oDXHvVPustij",
        "outputId": "b93757ec-e115-4582-e1c6-56ba0371b978"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 63), \"df_test.shape:\": (1000, 62)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj2DFFRNt9uT",
        "outputId": "4fdc2ca6-c935-44f8-e614-a1018a61ed59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11033 entries, 0 to 11032\n",
            "Data columns (total 63 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      11033 non-null  int64  \n",
            " 1   cnae2   11033 non-null  int64  \n",
            " 2   rf2     11033 non-null  object \n",
            " 3   md1     11033 non-null  float64\n",
            " 4   md2     11033 non-null  float64\n",
            " 5   md3     11033 non-null  float64\n",
            " 6   md4     11033 non-null  float64\n",
            " 7   md5     11033 non-null  float64\n",
            " 8   md6     11033 non-null  float64\n",
            " 9   md7     11033 non-null  float64\n",
            " 10  md8     11033 non-null  float64\n",
            " 11  md9     11033 non-null  float64\n",
            " 12  md10    11033 non-null  float64\n",
            " 13  md11    11033 non-null  float64\n",
            " 14  md12    11033 non-null  float64\n",
            " 15  mc1     10431 non-null  float64\n",
            " 16  mc2     10431 non-null  float64\n",
            " 17  mc3     10431 non-null  float64\n",
            " 18  mc4     11033 non-null  float64\n",
            " 19  ind01   10999 non-null  float64\n",
            " 20  ind02   10999 non-null  float64\n",
            " 21  ind03   10999 non-null  float64\n",
            " 22  ind04   10999 non-null  float64\n",
            " 23  ind05   10999 non-null  float64\n",
            " 24  ind06   10999 non-null  float64\n",
            " 25  ind07   10999 non-null  float64\n",
            " 26  ind08   10999 non-null  float64\n",
            " 27  ind09   10999 non-null  float64\n",
            " 28  ind10   10999 non-null  float64\n",
            " 29  ind11   10999 non-null  float64\n",
            " 30  ind12   10999 non-null  float64\n",
            " 31  ind13   10999 non-null  float64\n",
            " 32  ind14   10999 non-null  float64\n",
            " 33  ind15   10999 non-null  float64\n",
            " 34  ind16   10999 non-null  float64\n",
            " 35  ind17   10999 non-null  float64\n",
            " 36  ind18   10999 non-null  float64\n",
            " 37  ind19   10999 non-null  float64\n",
            " 38  ind20   10999 non-null  float64\n",
            " 39  ind21   10434 non-null  float64\n",
            " 40  ind22   10434 non-null  float64\n",
            " 41  ind23   10434 non-null  float64\n",
            " 42  ind24   10434 non-null  float64\n",
            " 43  ind25   10434 non-null  float64\n",
            " 44  ind26   10434 non-null  float64\n",
            " 45  ind27   10434 non-null  float64\n",
            " 46  ind28   10999 non-null  float64\n",
            " 47  ind29   10999 non-null  float64\n",
            " 48  ind30   10999 non-null  float64\n",
            " 49  ind31   10999 non-null  float64\n",
            " 50  ind32   10999 non-null  float64\n",
            " 51  ind33   10999 non-null  float64\n",
            " 52  ind34   10999 non-null  float64\n",
            " 53  ind35   10999 non-null  float64\n",
            " 54  ind36   10999 non-null  float64\n",
            " 55  ind37   10999 non-null  float64\n",
            " 56  ind38   10434 non-null  float64\n",
            " 57  ind39   10434 non-null  float64\n",
            " 58  ind40   10999 non-null  float64\n",
            " 59  ind41   10999 non-null  float64\n",
            " 60  ind42   10434 non-null  float64\n",
            " 61  ind43   10434 non-null  float64\n",
            " 62  target  11033 non-null  bool   \n",
            "dtypes: bool(1), float64(59), int64(2), object(1)\n",
            "memory usage: 5.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNVOd-U9uzXe",
        "outputId": "83a7dc81-5bef-454b-c91e-60ae74288ff5"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'cnae2', 'rf2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7',\n",
              "       'md8', 'md9', 'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4',\n",
              "       'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24',\n",
              "       'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32',\n",
              "       'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
              "       'ind41', 'ind42', 'ind43', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "mgT2KGJBt9ub",
        "outputId": "eea02333-d133-4a95-f54e-01d19e50b9e3"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6007.300462</td>\n",
              "      <td>53.105774</td>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106722</td>\n",
              "      <td>0.157427</td>\n",
              "      <td>0.346646</td>\n",
              "      <td>0.364934</td>\n",
              "      <td>0.378858</td>\n",
              "      <td>0.397906</td>\n",
              "      <td>0.305112</td>\n",
              "      <td>0.355596</td>\n",
              "      <td>0.007454</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.141280</td>\n",
              "      <td>0.170552</td>\n",
              "      <td>0.034556</td>\n",
              "      <td>0.019556</td>\n",
              "      <td>0.003789</td>\n",
              "      <td>0.014774</td>\n",
              "      <td>0.004045</td>\n",
              "      <td>0.694791</td>\n",
              "      <td>0.700189</td>\n",
              "      <td>0.544750</td>\n",
              "      <td>0.538172</td>\n",
              "      <td>0.339573</td>\n",
              "      <td>0.333567</td>\n",
              "      <td>0.099865</td>\n",
              "      <td>0.570295</td>\n",
              "      <td>0.550792</td>\n",
              "      <td>0.005119</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.331121</td>\n",
              "      <td>0.367397</td>\n",
              "      <td>0.999182</td>\n",
              "      <td>0.489044</td>\n",
              "      <td>0.910992</td>\n",
              "      <td>0.729703</td>\n",
              "      <td>0.659605</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>0.134177</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.170692</td>\n",
              "      <td>0.090905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3470.840481</td>\n",
              "      <td>19.885298</td>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305922</td>\n",
              "      <td>0.315114</td>\n",
              "      <td>0.470182</td>\n",
              "      <td>0.451587</td>\n",
              "      <td>0.449015</td>\n",
              "      <td>0.473002</td>\n",
              "      <td>0.430549</td>\n",
              "      <td>0.440732</td>\n",
              "      <td>0.069064</td>\n",
              "      <td>0.031814</td>\n",
              "      <td>0.029262</td>\n",
              "      <td>0.312289</td>\n",
              "      <td>0.322844</td>\n",
              "      <td>0.161135</td>\n",
              "      <td>0.129848</td>\n",
              "      <td>0.059799</td>\n",
              "      <td>0.118014</td>\n",
              "      <td>0.062567</td>\n",
              "      <td>0.452090</td>\n",
              "      <td>0.450725</td>\n",
              "      <td>0.455767</td>\n",
              "      <td>0.457155</td>\n",
              "      <td>0.433901</td>\n",
              "      <td>0.434164</td>\n",
              "      <td>0.221941</td>\n",
              "      <td>0.425365</td>\n",
              "      <td>0.412976</td>\n",
              "      <td>0.060052</td>\n",
              "      <td>0.013340</td>\n",
              "      <td>0.018207</td>\n",
              "      <td>0.470638</td>\n",
              "      <td>0.482118</td>\n",
              "      <td>0.028595</td>\n",
              "      <td>0.499903</td>\n",
              "      <td>0.284768</td>\n",
              "      <td>0.444134</td>\n",
              "      <td>0.473863</td>\n",
              "      <td>0.071093</td>\n",
              "      <td>0.340858</td>\n",
              "      <td>0.016514</td>\n",
              "      <td>0.009535</td>\n",
              "      <td>0.376258</td>\n",
              "      <td>0.206764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3018.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6016.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9003.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862600</td>\n",
              "      <td>0.932700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id         cnae2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  10434.000000  10434.000000\n",
              "mean    6007.300462     53.105774  ...      0.170692      0.090905\n",
              "std     3470.840481     19.885298  ...      0.376258      0.206764\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%     3018.000000     42.000000  ...      0.000000      0.000000\n",
              "50%     6016.000000     47.000000  ...      0.000000      0.000000\n",
              "75%     9003.000000     69.000000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7U16Y6SQ4Zs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "1bfaa59c-c8b3-44d4-b470-9f221cdd5cdf"
      },
      "source": [
        "l_train_unique = []\n",
        "for i in df_train.columns:\n",
        "  l_train_unique.append(len(df_train[i].unique()))\n",
        "  #print(\"coluna:\", i, \" - len(df_train[i].unique()):\", len(df_train[i].unique()))\n",
        "\n",
        "df_train_unique = pd.DataFrame(zip(df_train.columns,l_train_unique))\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>11033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cnae2</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rf2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>md1</td>\n",
              "      <td>8829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>md2</td>\n",
              "      <td>10968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>ind40</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>ind41</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>ind42</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>ind43</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>target</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0      1\n",
              "0       id  11033\n",
              "1    cnae2     80\n",
              "2      rf2     10\n",
              "3      md1   8829\n",
              "4      md2  10968\n",
              "..     ...    ...\n",
              "58   ind40      3\n",
              "59   ind41      3\n",
              "60   ind42      3\n",
              "61   ind43      4\n",
              "62  target      2\n",
              "\n",
              "[63 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2JdxJRJShUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "f24734e0-41ae-4153-c402-dbfef6a396a7"
      },
      "source": [
        "df_train_unique.rename(columns={0:'coluna',1:'qtde_unique'})\n",
        "df_train_unique = df_train_unique.set_index(0).T\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11033</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>8829</td>\n",
              "      <td>10968</td>\n",
              "      <td>10967</td>\n",
              "      <td>8168</td>\n",
              "      <td>5612</td>\n",
              "      <td>379</td>\n",
              "      <td>10970</td>\n",
              "      <td>10968</td>\n",
              "      <td>8282</td>\n",
              "      <td>5777</td>\n",
              "      <td>340</td>\n",
              "      <td>10967</td>\n",
              "      <td>9925</td>\n",
              "      <td>1484</td>\n",
              "      <td>8157</td>\n",
              "      <td>10451</td>\n",
              "      <td>14</td>\n",
              "      <td>1417</td>\n",
              "      <td>194</td>\n",
              "      <td>14</td>\n",
              "      <td>765</td>\n",
              "      <td>227</td>\n",
              "      <td>2101</td>\n",
              "      <td>2522</td>\n",
              "      <td>331</td>\n",
              "      <td>45</td>\n",
              "      <td>22</td>\n",
              "      <td>1554</td>\n",
              "      <td>2503</td>\n",
              "      <td>830</td>\n",
              "      <td>77</td>\n",
              "      <td>24</td>\n",
              "      <td>45</td>\n",
              "      <td>13</td>\n",
              "      <td>488</td>\n",
              "      <td>429</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>748</td>\n",
              "      <td>159</td>\n",
              "      <td>164</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0     id  cnae2  rf2   md1    md2  ...  ind40  ind41  ind42  ind43  target\n",
              "1  11033     80   10  8829  10968  ...      3      3      3      4       2\n",
              "\n",
              "[1 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yll7hKsUxWUK",
        "outputId": "22b004c4-e69a-4b96-b4ac-b14d83bb0602"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpnm_zhckXD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0293f89-1ee1-450d-cbf5-f1d686cfaf06"
      },
      "source": [
        "df_nan = df_train.isna().sum()\n",
        "df_nan[df_nan.values>0].sort_values()\n",
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy8hCEistGiR",
        "outputId": "f532aa00-480d-4eb9-e0d1-9096d0858f5b"
      },
      "source": [
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIaxV70rhhE-",
        "outputId": "f7e2eced-6a2d-4ec6-8ce2-3cbd338cfeac"
      },
      "source": [
        "df_nan[df_nan.values==34].index   \n",
        "\n",
        "# 32 colunas/variÃ¡veis que possuem 34 NaN cada\n",
        "#'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "#'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "#'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "#'ind40', 'ind41']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind28', 'ind29', 'ind30', 'ind31',\n",
              "       'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind40', 'ind41'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ERGm38u0oN",
        "outputId": "4f72eb49-82b0-4638-970d-04453d1c448d"
      },
      "source": [
        "len(df_nan[df_nan.values==34].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49eQZdrEpex6",
        "outputId": "eab85b83-a8e8-415d-e8b3-a23864d6ff33"
      },
      "source": [
        "df_nan[df_nan.values==599].index    \n",
        "\n",
        "# 11 colunas/variÃ¡veis que possuem 599 NaN cada:\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "# 'ind38', 'ind39',\n",
        "# 'ind42', 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind38',\n",
              "       'ind39', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o593PHygvLJ8",
        "outputId": "0e4aa74f-9572-4e25-9d89-5aa08cc581b1"
      },
      "source": [
        "len(df_nan[df_nan.values==599].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5mETHrgpe_I",
        "outputId": "4b37dbdb-ef2f-4d98-cfd1-534af3742742"
      },
      "source": [
        "df_nan[df_nan.values==602].index    \n",
        "\n",
        "# 3 colunas/variÃ¡veis que possuem 602 NaN cada\n",
        "# ['mc1', 'mc2', 'mc3']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHecZd8jfuGi",
        "outputId": "722fece4-a4fa-49e2-a0e8-cb209f74ac2d"
      },
      "source": [
        "linhas_602nan = df_train['mc1'][df_train['mc1'].isna()].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   26,    27,    32,    34,    47,    64,    76,    88,   100,\n",
              "              121,\n",
              "            ...\n",
              "            10848, 10891, 10911, 10921, 10935, 10941, 10979, 10986, 10991,\n",
              "            11007],\n",
              "           dtype='int64', length=602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EUky3VvxJH"
      },
      "source": [
        "linhas_599nan = df_train['ind21'][df_train['ind21'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI4pULl0wble",
        "outputId": "1fbcf7a7-e9f0-4d47-d135-2cd10f15172a"
      },
      "source": [
        "len(set(list(linhas_602nan)) & set(list(linhas_599nan)))  \n",
        "# 602nan e 599nan apresentam 596 linhas em comum\n",
        "# entÃ£o tem 3 linhas em 599nan que nÃ£o estÃ£o em 602 nan e\n",
        "# 6 linhas em 602nan que nÃ£o estÃ£o em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXs7y99OyUEG",
        "outputId": "a6e963f8-43b9-4e53-d3cd-73c036721f9b"
      },
      "source": [
        "set(list(linhas_602nan)) - set(list(linhas_599nan)) # 6 linhas {1213, 1224, 3233, 5346, 6101, 7297} em 602nan mas nÃ£o em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpep48R0N19",
        "outputId": "54405911-141a-480b-dd4b-57daf90b6354"
      },
      "source": [
        "set(list(linhas_599nan)) - set(list(linhas_602nan)) # 3 linhas {5788, 10284, 10965} em 599nan mas nÃ£o em 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5788, 10284, 10965}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VghwKgdRwF2Y"
      },
      "source": [
        "linhas_34nan = df_train['ind01'][df_train['ind01'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozi0Gw990yml",
        "outputId": "04e1e738-a686-462c-fcc0-5b3493479a69"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_599nan))  # 34nan e 599nan nÃ£o apresentam linhas nan em comum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFs38gIx0zIQ",
        "outputId": "ccb5b11a-512a-45df-b75a-fbae70a82fe6"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_602nan)) # linhas {1213, 1224, 3233, 5346, 6101, 7297} em comum em 34nan e 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g41VmVkq-_R",
        "outputId": "5dee64cb-b577-4005-9ccb-cc336e42ca62"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdaAew8P89Jn",
        "outputId": "067f5309-3973-4017-8fb3-e069c718d740"
      },
      "source": [
        "df_train[df_train['mc1'].notna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    7917\n",
              "True     2514\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Ly8LJv2_9J_x",
        "outputId": "fa8b025e-00fc-4ad8-aa29-17f3a08c7bb5"
      },
      "source": [
        "df_train[df_train['mc1'].notna()].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.00000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.00000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5998.586521</td>\n",
              "      <td>53.33851</td>\n",
              "      <td>0.011993</td>\n",
              "      <td>0.013208</td>\n",
              "      <td>0.118480</td>\n",
              "      <td>0.014551</td>\n",
              "      <td>0.009693</td>\n",
              "      <td>0.002250</td>\n",
              "      <td>0.016025</td>\n",
              "      <td>0.032519</td>\n",
              "      <td>0.017690</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.134538</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.079664</td>\n",
              "      <td>0.133032</td>\n",
              "      <td>0.311410</td>\n",
              "      <td>0.330905</td>\n",
              "      <td>0.345606</td>\n",
              "      <td>0.365514</td>\n",
              "      <td>0.321753</td>\n",
              "      <td>0.37509</td>\n",
              "      <td>0.007881</td>\n",
              "      <td>0.001454</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.149238</td>\n",
              "      <td>0.178966</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.020676</td>\n",
              "      <td>0.00391</td>\n",
              "      <td>0.014755</td>\n",
              "      <td>0.004276</td>\n",
              "      <td>0.677786</td>\n",
              "      <td>0.686280</td>\n",
              "      <td>0.544727</td>\n",
              "      <td>0.53817</td>\n",
              "      <td>0.339742</td>\n",
              "      <td>0.333741</td>\n",
              "      <td>0.099889</td>\n",
              "      <td>0.570311</td>\n",
              "      <td>0.550781</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.295011</td>\n",
              "      <td>0.333269</td>\n",
              "      <td>0.999135</td>\n",
              "      <td>0.460636</td>\n",
              "      <td>0.907238</td>\n",
              "      <td>0.714602</td>\n",
              "      <td>0.644526</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>0.134254</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.170790</td>\n",
              "      <td>0.090957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3467.890242</td>\n",
              "      <td>19.98793</td>\n",
              "      <td>0.042113</td>\n",
              "      <td>0.026769</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.040304</td>\n",
              "      <td>0.037191</td>\n",
              "      <td>0.025934</td>\n",
              "      <td>0.029294</td>\n",
              "      <td>0.027583</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>0.038919</td>\n",
              "      <td>0.022033</td>\n",
              "      <td>0.013933</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007199</td>\n",
              "      <td>0.267626</td>\n",
              "      <td>0.283498</td>\n",
              "      <td>0.456864</td>\n",
              "      <td>0.438529</td>\n",
              "      <td>0.436875</td>\n",
              "      <td>0.463864</td>\n",
              "      <td>0.435993</td>\n",
              "      <td>0.44446</td>\n",
              "      <td>0.070991</td>\n",
              "      <td>0.032711</td>\n",
              "      <td>0.030087</td>\n",
              "      <td>0.319113</td>\n",
              "      <td>0.328067</td>\n",
              "      <td>0.164659</td>\n",
              "      <td>0.133429</td>\n",
              "      <td>0.06070</td>\n",
              "      <td>0.117785</td>\n",
              "      <td>0.064327</td>\n",
              "      <td>0.458565</td>\n",
              "      <td>0.456224</td>\n",
              "      <td>0.455770</td>\n",
              "      <td>0.45715</td>\n",
              "      <td>0.433962</td>\n",
              "      <td>0.434225</td>\n",
              "      <td>0.221986</td>\n",
              "      <td>0.425340</td>\n",
              "      <td>0.412952</td>\n",
              "      <td>0.059627</td>\n",
              "      <td>0.012832</td>\n",
              "      <td>0.018721</td>\n",
              "      <td>0.456070</td>\n",
              "      <td>0.471405</td>\n",
              "      <td>0.029402</td>\n",
              "      <td>0.498472</td>\n",
              "      <td>0.290112</td>\n",
              "      <td>0.451626</td>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>0.340941</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.206812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3012.500000</td>\n",
              "      <td>42.00000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002518</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.020741</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130695</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6006.000000</td>\n",
              "      <td>47.00000</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.005624</td>\n",
              "      <td>0.112164</td>\n",
              "      <td>0.002776</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007169</td>\n",
              "      <td>0.024386</td>\n",
              "      <td>0.005072</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131472</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.58330</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8990.500000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>0.006366</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.118149</td>\n",
              "      <td>0.011908</td>\n",
              "      <td>0.004606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016753</td>\n",
              "      <td>0.033129</td>\n",
              "      <td>0.017071</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133913</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918500</td>\n",
              "      <td>0.95860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id        cnae2  ...         ind42         ind43\n",
              "count  10431.000000  10431.00000  ...  10428.000000  10428.000000\n",
              "mean    5998.586521     53.33851  ...      0.170790      0.090957\n",
              "std     3467.890242     19.98793  ...      0.376344      0.206812\n",
              "min        0.000000      0.00000  ...      0.000000      0.000000\n",
              "25%     3012.500000     42.00000  ...      0.000000      0.000000\n",
              "50%     6006.000000     47.00000  ...      0.000000      0.000000\n",
              "75%     8990.500000     69.00000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.00000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWABZ-yWrQH2",
        "outputId": "e5092897-4659-4d79-969e-cc54bd1c11c4"
      },
      "source": [
        "df_train['target'].value_counts()   22,84% True e 77,16% False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3hg6GGQt9us"
      },
      "source": [
        "# Total de 46 Colunas/variÃ¡veis que apresentam NaN:\n",
        "# 'mc1', 'mc2', 'mc3',\n",
        "# 'ind01', 'ind02', 'ind03', 'ind04', 'ind05','ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30',\n",
        "# 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
        "# 'ind41', 'ind42', 'ind43'\n",
        "sendo:\n",
        "  # 32 colunas/variÃ¡veis que possuem 34 NaN cada\n",
        "    #'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "    #'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "    #'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "    #'ind40', 'ind41'\n",
        "  # 11 colunas/variÃ¡veis que possuem 599 NaN cada:\n",
        "    # 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "    # 'ind38', 'ind39',\n",
        "    # 'ind42', 'ind43'\n",
        "  # 3 colunas/variÃ¡veis que possuem 602 NaN cada\n",
        "    # ['mc1', 'mc2', 'mc3']\n",
        "\n",
        "# 602nan e 599nan apresentam 596 linhas em comum, entÃ£o:\n",
        "# 3 linhas em 599nan que nÃ£o estÃ£o em 602 nan : {5788, 10284, 10965}\n",
        "# 6 linhas em 602nan que nÃ£o estÃ£o em 599nan : {1213, 1224, 3233, 5346, 6101, 7297}\n",
        "\n",
        "# 602nan e 34nan apresentam 6 linhas em comum {1213, 1224, 3233, 5346, 6101, 7297} , que sÃ£o as mesmas 6 linhas que nÃ£o estÃ£o em 599nan\n",
        "# 599nan e 34nan nÃ£o apresentam linhas em comum\n",
        "\n",
        "# Total de 633 linhas com NaN ( = 596 + 3 + 6 + 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUqmH2Bt9uz"
      },
      "source": [
        "s_coluna = pd.Series(list(df_train.columns))\n",
        "s_qtde = pd.Series(list(df_train.isna().sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOMEunK3U29"
      },
      "source": [
        "df_nan = pd.DataFrame(zip(s_coluna, s_qtde),columns = ['coluna','qtde_nan'])\n",
        "df_nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3rZDA3t3q2p"
      },
      "source": [
        "df_nan[df_nan['qtde_nan']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLD7DW9a3t-J",
        "outputId": "ac583888-6975-4f49-a1c1-c1d0ba843a64"
      },
      "source": [
        "len(df_nan[df_nan['qtde_nan']!=0])        # 46 variÃ¡veis/colunas apresentam NaN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKbN8oAZ6uRf",
        "outputId": "5d4a510a-76b9-4598-d86d-66b71d00973f"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PBBF4-719u",
        "outputId": "bd2e3929-89c5-4f4b-941b-61015797e002"
      },
      "source": [
        "df_train['ind06'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind32'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5441\n",
              "1.0000    4081\n",
              "0.1671      62\n",
              "0.1534      41\n",
              "0.1644      38\n",
              "Name: ind06, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyl-JR3y8B_9",
        "outputId": "5d1e8982-89c7-4a49-d77a-735e570da7da"
      },
      "source": [
        "df_train['ind32'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    6958\n",
              "1.0    4041\n",
              "Name: ind32, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyySiN6PK3iU",
        "outputId": "907b60c3-6ce4-4fd4-a96c-40b8cb143622"
      },
      "source": [
        "df_train['ind04'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind05'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5812\n",
              "1.0000    3151\n",
              "0.0833     532\n",
              "0.9167     258\n",
              "0.1667     224\n",
              "Name: ind04, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-2Obx4LK3xA",
        "outputId": "3d1043e4-60e6-406a-f734-ea7bb12f6d7f"
      },
      "source": [
        "df_train['ind05'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    4776\n",
              "1.0000    3161\n",
              "0.0833     434\n",
              "0.9167     250\n",
              "0.1667     179\n",
              "Name: ind05, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbhjyN3LUU2",
        "outputId": "baf93d03-285c-4688-d097-956ff3360fcf"
      },
      "source": [
        "df_train['ind03'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind31'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    6844\n",
              "1.0000    3642\n",
              "0.0027      21\n",
              "0.0055      12\n",
              "0.1671      11\n",
              "Name: ind03, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ZuDkAPLUgt",
        "outputId": "3e432775-b12a-41e4-fccd-f69eaabbcab3"
      },
      "source": [
        "df_train['ind31'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    7357\n",
              "1.0    3642\n",
              "Name: ind31, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrx-HSHHMyCq",
        "outputId": "55126dd1-48a4-43eb-900e-8f0db36de927"
      },
      "source": [
        "df_train['ind23'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind24'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5018\n",
              "1.0000    2847\n",
              "0.0833     833\n",
              "0.1667     400\n",
              "0.2500     218\n",
              "Name: ind23, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMjX8IY2MyNP",
        "outputId": "c53eb23f-5d06-435d-c8f8-92076a19f984"
      },
      "source": [
        "df_train['ind24'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5136\n",
              "1.0000    2837\n",
              "0.0833     835\n",
              "0.1667     377\n",
              "0.2500     208\n",
              "Name: ind24, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMeKN8lNUIt",
        "outputId": "cc01503e-5456-426f-ae20-6ce841716839"
      },
      "source": [
        "df_train['ind42'].value_counts().head()   #alta correlaÃ§Ã£o com 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "1.0    1781\n",
              "Name: ind42, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXgzAeTgNUSM",
        "outputId": "6a572209-11ab-4302-8ccb-662e0738f363"
      },
      "source": [
        "df_train['ind43'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "0.5    1665\n",
              "1.0     116\n",
              "Name: ind43, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-xtwpcNrad",
        "outputId": "9fe5fdf5-f4f2-4bf5-d673-e3ebdacc1719"
      },
      "source": [
        "df_train['md2'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015110    8\n",
              "0.001655    7\n",
              "0.004966    6\n",
              "0.001986    6\n",
              "0.001324    5\n",
              "Name: md2, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8QRBw3Nrnf",
        "outputId": "43c65572-3f64-46bb-caab-4dd7660ad0b9"
      },
      "source": [
        "df_train['md8'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.039463    8\n",
              "0.017749    7\n",
              "0.025066    6\n",
              "0.019375    5\n",
              "0.019700    5\n",
              "Name: md8, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltYMeW-N1wG",
        "outputId": "f916e55d-abb8-46ae-b123-250e71288746"
      },
      "source": [
        "df_train['md7'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022106    8\n",
              "0.001986    7\n",
              "0.001655    6\n",
              "0.007449    6\n",
              "0.003310    5\n",
              "Name: md7, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo_VW-5a_6hL",
        "outputId": "42af1401-fa12-4e09-ddcc-c5f507918878"
      },
      "source": [
        "df_train['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv5QEKyPl0iG",
        "outputId": "35a463c7-5c68-4265-d5cd-bfb87ee1fcfa"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "cnae2     0\n",
              "rf2       0\n",
              "md1       0\n",
              "md2       0\n",
              "         ..\n",
              "ind40     0\n",
              "ind41     0\n",
              "ind42     0\n",
              "ind43     0\n",
              "target    0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxu66h0D2ZuV"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJStLm07t9u_"
      },
      "source": [
        "Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vSe45kBt9vA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WirO9VPz6tR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrodOQuDsKpc"
      },
      "source": [
        "def calcula_outliers(df):\n",
        "    Q1 = []\n",
        "    Q3 = []\n",
        "    IQR = []\n",
        "    linf = []\n",
        "    lsup = []\n",
        "    qtde_inf = []\n",
        "    qtde_sup = []\n",
        "    col = []\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        Q1.append(q1)\n",
        "        Q3.append(q3)\n",
        "        IQR.append(iqr)\n",
        "        linf.append(lim_inf)\n",
        "        lsup.append(lim_sup)\n",
        "        qtde_inf.append(len(df[df[i]<lim_inf]))\n",
        "        qtde_sup.append(len(df[df[i]>lim_sup]))\n",
        "        col.append(i)\n",
        "    return (Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6MkPFtYu7x7"
      },
      "source": [
        "Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col = calcula_outliers(df_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9t9BOagvPXU"
      },
      "source": [
        "df_outliers = pd.DataFrame(np.array([Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup]), columns=[lcol] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "0EcHYgrfzoIN",
        "outputId": "7965cfb7-0685-46e1-e75e-97fffd0f714d"
      },
      "source": [
        "df_outliers.rename(index = {0:'q1', 1:'q3', 2:'iqr', 3:'lim_inf', 4:'lim_sup', 5:'abaixo_lim_inf', 6:'acima_lim_sup'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>q1</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>q3</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iqr</th>\n",
              "      <td>0.006032</td>\n",
              "      <td>0.010318</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013209</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.016188</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_inf</th>\n",
              "      <td>-0.009046</td>\n",
              "      <td>-0.013055</td>\n",
              "      <td>0.098338</td>\n",
              "      <td>-0.016855</td>\n",
              "      <td>-0.006283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.016656</td>\n",
              "      <td>0.002453</td>\n",
              "      <td>-0.024269</td>\n",
              "      <td>-0.010959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.001895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_sup</th>\n",
              "      <td>0.015083</td>\n",
              "      <td>0.028217</td>\n",
              "      <td>0.129641</td>\n",
              "      <td>0.028091</td>\n",
              "      <td>0.010472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036180</td>\n",
              "      <td>0.050965</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.018265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138690</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abaixo_lim_inf</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acima_lim_sup</th>\n",
              "      <td>1658.000000</td>\n",
              "      <td>1181.000000</td>\n",
              "      <td>1203.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1718.000000</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1110.000000</td>\n",
              "      <td>1098.000000</td>\n",
              "      <td>1129.000000</td>\n",
              "      <td>1578.000000</td>\n",
              "      <td>339.0</td>\n",
              "      <td>1297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1233.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        md1          md2          md3  ... ind41 ind42 ind43\n",
              "q1                 0.000003     0.002422     0.110077  ...   NaN   NaN   NaN\n",
              "q3                 0.006035     0.012740     0.117903  ...   NaN   NaN   NaN\n",
              "iqr                0.006032     0.010318     0.007826  ...   NaN   NaN   NaN\n",
              "lim_inf           -0.009046    -0.013055     0.098338  ...   NaN   NaN   NaN\n",
              "lim_sup            0.015083     0.028217     0.129641  ...   NaN   NaN   NaN\n",
              "abaixo_lim_inf     0.000000     0.000000     4.000000  ...   0.0   0.0   0.0\n",
              "acima_lim_sup   1658.000000  1181.000000  1203.000000  ...   0.0   0.0   0.0\n",
              "\n",
              "[7 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "j004R47yzwCU",
        "outputId": "03cf0785-03b9-4384-d70d-a2aa4ad79054"
      },
      "source": [
        "df_train.drop(['id','cnae2'],axis=1,inplace=False).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001607</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106393</td>\n",
              "      <td>0.156942</td>\n",
              "      <td>0.345577</td>\n",
              "      <td>0.363809</td>\n",
              "      <td>0.377947</td>\n",
              "      <td>0.396748</td>\n",
              "      <td>0.304172</td>\n",
              "      <td>0.354500</td>\n",
              "      <td>0.007431</td>\n",
              "      <td>0.001371</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.170026</td>\n",
              "      <td>0.034449</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.003777</td>\n",
              "      <td>0.014728</td>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.695732</td>\n",
              "      <td>0.701113</td>\n",
              "      <td>0.555893</td>\n",
              "      <td>0.540622</td>\n",
              "      <td>0.325660</td>\n",
              "      <td>0.319979</td>\n",
              "      <td>0.094443</td>\n",
              "      <td>0.573265</td>\n",
              "      <td>0.549543</td>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.330101</td>\n",
              "      <td>0.366265</td>\n",
              "      <td>0.999184</td>\n",
              "      <td>0.487537</td>\n",
              "      <td>0.911266</td>\n",
              "      <td>0.730536</td>\n",
              "      <td>0.660654</td>\n",
              "      <td>0.004804</td>\n",
              "      <td>0.126892</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.161425</td>\n",
              "      <td>0.085969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012535</td>\n",
              "      <td>0.012276</td>\n",
              "      <td>0.013302</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305507</td>\n",
              "      <td>0.314749</td>\n",
              "      <td>0.469850</td>\n",
              "      <td>0.451344</td>\n",
              "      <td>0.448622</td>\n",
              "      <td>0.472732</td>\n",
              "      <td>0.430218</td>\n",
              "      <td>0.440494</td>\n",
              "      <td>0.068959</td>\n",
              "      <td>0.031765</td>\n",
              "      <td>0.029217</td>\n",
              "      <td>0.311906</td>\n",
              "      <td>0.322485</td>\n",
              "      <td>0.160898</td>\n",
              "      <td>0.129652</td>\n",
              "      <td>0.059707</td>\n",
              "      <td>0.117835</td>\n",
              "      <td>0.062471</td>\n",
              "      <td>0.451710</td>\n",
              "      <td>0.450337</td>\n",
              "      <td>0.445655</td>\n",
              "      <td>0.444689</td>\n",
              "      <td>0.425934</td>\n",
              "      <td>0.426005</td>\n",
              "      <td>0.217015</td>\n",
              "      <td>0.413842</td>\n",
              "      <td>0.401642</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.013319</td>\n",
              "      <td>0.018179</td>\n",
              "      <td>0.470270</td>\n",
              "      <td>0.481805</td>\n",
              "      <td>0.028551</td>\n",
              "      <td>0.499867</td>\n",
              "      <td>0.284372</td>\n",
              "      <td>0.443702</td>\n",
              "      <td>0.473509</td>\n",
              "      <td>0.069146</td>\n",
              "      <td>0.332867</td>\n",
              "      <td>0.016488</td>\n",
              "      <td>0.009520</td>\n",
              "      <td>0.367939</td>\n",
              "      <td>0.202125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.138900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860800</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                md1           md2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  11033.000000  11033.000000\n",
              "mean       0.011670      0.012928  ...      0.161425      0.085969\n",
              "std        0.041618      0.026515  ...      0.367939      0.202125\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.000003      0.002422  ...      0.000000      0.000000\n",
              "50%        0.000316      0.005415  ...      0.000000      0.000000\n",
              "75%        0.006035      0.012740  ...      0.000000      0.000000\n",
              "max        1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJF8Q05rbSF",
        "outputId": "d9835c6f-551b-4605-ab2f-9ff7464e9c1b"
      },
      "source": [
        "df_test.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JWJ0Z3ZBT8x",
        "outputId": "82b334d4-5001-4a31-c9f8-914aeab58285"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqmeyNYfBUkz"
      },
      "source": [
        "def f_trata_outliers(df):\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        df[i][df[i] < lim_inf] = lim_inf\n",
        "        df[i][df[i] > lim_sup] = lim_sup\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN--_ZdBdAb"
      },
      "source": [
        "f_trata_outliers(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6RCkr7CSAO"
      },
      "source": [
        "f_trata_outliers(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Y2TJ-Gt9vE"
      },
      "source": [
        "# funÃ§Ã£o que trata NaN:\n",
        "def f_trata_NaN(df):\n",
        "    coluna_nan = df.isna().sum()[df.isna().sum().values>0].index\n",
        "    for col in coluna_nan:\n",
        "      df[col] = df[col].fillna(df[col].median())\n",
        "    return df"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-4KOA0t9vK"
      },
      "source": [
        "# tratando NaN nos dataframes df_train e df_test:\n",
        "df_train = f_trata_NaN(df_train)\n",
        "df_test = f_trata_NaN(df_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0E1CSAYnch8"
      },
      "source": [
        "# criando dummies em df_train e df_test:\n",
        "df_train = pd.get_dummies(df_train, drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, drop_first=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Es33OXkQnyLc",
        "outputId": "0ea8aa72-ca3f-42fb-cd96-8ef1648ecbe8"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\":{df_test.shape}'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 72), \"df_test.shape:\":(1000, 71)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWjvdF3F2Xs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU4mjAscF4Ge"
      },
      "source": [
        "### PULAR PARA PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3tEEKJF2pO"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfiez91PF20t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj5Nlm_iEggt",
        "outputId": "7e32c74e-508b-4c85-bffb-13cdcc9e345e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train['target'].astype('category')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         True\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "11028    False\n",
              "11029    False\n",
              "11030     True\n",
              "11031    False\n",
              "11032     True\n",
              "Name: target, Length: 11033, dtype: category\n",
              "Categories (2, object): [False, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i57fUZmDt9vP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9098a979-065d-4cf5-90bd-977906908a55"
      },
      "source": [
        "# definindo X (sem 'id' e 'target'), y (variÃ¡vel target) e X_submit (sem 'id'): \n",
        "X = df_train.drop(columns= ['id','target'], axis= 1)\n",
        "y = df_train['target']\n",
        "X_submit = df_test.drop(columns='id',axis=1)\n",
        "\n",
        "f'\"X.shape:\":{X.shape}, \"y.shape:\":{y.shape}, \"X_submit.shape:\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X.shape:\":(11033, 70), \"y.shape:\":(11033,), \"X_submit.shape:\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsYMnSZXKogI",
        "outputId": "050ed15b-a6a2-48f3-e15e-f3250de8b219"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cnae2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8', 'md9',\n",
              "       'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4', 'ind01', 'ind02',\n",
              "       'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
              "       'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18',\n",
              "       'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26',\n",
              "       'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32', 'ind33', 'ind34',\n",
              "       'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40', 'ind41', 'ind42',\n",
              "       'ind43', 'rf2_d', 'rf2_i', 'rf2_k', 'rf2_p', 'rf2_q', 'rf2_r', 'rf2_s',\n",
              "       'rf2_v', 'rf2_y', 'rf2_z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8J8ej6t9vT"
      },
      "source": [
        "MODELO: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpaBkXMzmLwh"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsRI-rGxmnQC"
      },
      "source": [
        "# FunÃ§Ã£o para cross validation:\n",
        "def funcao_cross_val_score(modelo, X_treinamento, y_treinamento, CV):\n",
        "    #versÃ£o com cross_val_score::\n",
        "    a_scores_CV = cross_val_score(modelo, X_treinamento, y_treinamento, cv = CV)\n",
        "    print(f'MÃ©dia das AcurÃ¡cias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "    print(f'std mÃ©dio das AcurÃ¡cias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "    return a_scores_CV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaez67ksHsc0"
      },
      "source": [
        "# FunÃ§Ã£o para Confusion Matrix:\n",
        "from sklearn.metrics import confusion_matrix \n",
        "def mostra_confusion_matrix(cf, \n",
        "                            group_names = None, \n",
        "                            categories = 'auto', \n",
        "                            count = True, \n",
        "                            percent = True, \n",
        "                            cbar = True, \n",
        "                            xyticks = False, \n",
        "                            xyplotlabels = True, \n",
        "                            sum_stats = True, \n",
        "                            figsize = (8, 8), \n",
        "                            cmap = 'Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_8spMrGt9vU"
      },
      "source": [
        "i_CV = 10 # NÃºmero de Cross-Validations\n",
        "i_Seed = 22091980 # semente por questÃµes de reproducibilidade\n",
        "f_Test_Size = 0.3 # ProporÃ§Ã£o do dataframe de validaÃ§Ã£o (outros valores poderiam ser 0.15, 0.20 ou 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDY6msH0t9vY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "864288a8-1c95-4378-93a6-c0ace2604968"
      },
      "source": [
        "# Definindo dataframes de TREINAMENTO e TESTE a partir de X e y:\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = f_Test_Size, random_state = i_Seed)\n",
        "f'\"X_treinamento.shape:\" {X_treinamento.shape}, \"y_treinamento_shape:\"{y_treinamento.shape},\"X_teste.shape:\"{X_teste.shape},\"y_teste.shape:\"{y_teste.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento.shape:\" (7723, 70), \"y_treinamento_shape:\"(7723,),\"X_teste.shape:\"(3310, 70),\"y_teste.shape:\"(3310,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjUjFaykt9vf"
      },
      "source": [
        "# Instancia...\n",
        "ml_XGB= XGBClassifier(silent=False,\n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 1,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=1000, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth= 3, \n",
        "                      gamma=1, \n",
        "                      max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTFhHr6Ar4mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623d16c7-d681-46a3-f908-a035a9fc2c8b"
      },
      "source": [
        "# Modelo treinado sobre base \"train-split-test\"\n",
        "ml_XGB.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
              "              learning_rate=0.01, max_delta_step=5, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=False, subsample=0.8, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EH4l3lAt9vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6bc8da-8467-4c10-ceb3-4d79613a7dc6"
      },
      "source": [
        "# Chamando a funÃ§Ã£o do CROSS VALIDATION - Modelo treinado sobre base \"train-split-test\":\n",
        "\n",
        "a_scores_CV = funcao_cross_val_score(ml_XGB, X_treinamento, y_treinamento, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.39\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHujyPesnWF",
        "outputId": "9c5bcd70-b10e-46fd-bcc1-af15cf57f38d"
      },
      "source": [
        "y_pred = ml_XGB.predict(X_teste)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3185  125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TXeOdfIsPkp",
        "outputId": "2587031c-0e86-4569-eec6-6a4beb2d825f"
      },
      "source": [
        "y_submit_0 = ml_XGB.predict(X_submit)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_0, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Mr2xE0EMnQ"
      },
      "source": [
        "# CV com X_treinamento e y_treinamento:       # Modelo treinado sobre base \"train-split-test\"\n",
        "# AcurÃ¡cia MÃ©dia / STD mÃ©dio\n",
        "# 77,38 / 0,54  tirando outliers - 70% X\n",
        "# 77,39 / 0,51  sem tirar outliers - 70% X\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste)\n",
        "# 0: 3177, 1: 133 => tirando outliers de df_train - 30% X\n",
        "# 0: 3185, 1: 125 => sem tirar outliers de df_train - 30% X\n",
        "\n",
        "# y_submit = ml_XGB.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "#  ???????????  => tirando outliers de df_train (nÃ£o rodei)\n",
        "# 0: 952, 1: 48 => sem tirar outliers de df_train (70% X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "iQhLNFkyt9v5",
        "outputId": "5de1fb25-c83b-4706-c3e7-06fcabda7dbd"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "********* CONFUSION MATRIX - PARAMETER TUNNING ***********\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAIKCAYAAABBQBSMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hURdvH8e+dhN5Dkya9o1QFBZEmIIL0JioKCgooFlB6E6zYRRAQBVEUFRUQQYoNFQF5EJEiVXrvhJIyzx9ZYoAkLIeEJO7v817nYnf2nDNz9vHdO/fMnDnmnENEREQuLSi5GyAiIpJaKGiKiIj4SUFTRETETwqaIiIiflLQFBER8ZOCpoiIiJ8UNEVEJFUxs0Jm9p2ZrTGzv8yst698mJntNLOVvq1JrGP6m9lGM1tvZo1ilTf2lW00s36XrDsp7tPMULmXbv6UVO/wsreSuwkiiSJ9CJZU506K3/tT/3srwfaaWT4gn3NuhZllAX4HWgDtgBPOudEX7F8OmAbcCOQHFgClfB//DdwG7ACWAR2dc2viqzvE0xWJiIgkE+fcbmC37/VxM1sLFEjgkObAx865M8AWM9tIdAAF2Oic2wxgZh/79o03aKp7VkREvLOgxN8up3qzIkBl4DdfUS8zW2Vmk8wsh6+sALA91mE7fGXxlcdLQVNERFIUM+tmZstjbd3i2S8z8DnwmHPuGDAWKA5UIjoTfTmx26buWRER8c4Sf7jUOTceGJ9wtZaG6ID5oXNuhu+4vbE+nwDM9r3dCRSKdXhBXxkJlMdJmaaIiKQqZmbAu8Ba59wrscrzxdqtJbDa93om0MHM0plZUaAksJToiT8lzayomaUFOvj2jZcyTRER8e4yxyATSU3gHuBPM1vpKxsAdDSzSoADtgLdAZxzf5nZdKIn+EQAPZ1zkQBm1guYBwQDk5xzfyVUsYKmiIh4lwTds5finFsMcd5GMyeBY0YBo+Ion5PQcRdS96yIiIiflGmKiIh3ydM9m2wC62pFRESugDJNERHxLhnGNJOTgqaIiHin7lkRERGJizJNERHxLsC6Z5VpioiI+EmZpoiIeBdgY5oKmiIi4p26Z0VERCQuyjRFRMS7AOueDayrFRERuQLKNEVExDuNaYqIiEhclGmKiIh3ATamqaApIiLeBVjQDKyrFRERuQLKNEVExLsgTQQSERGROCjTFBER7wJsTFNBU0REvNN9miIiIhIXZZoiIuJdgHXPBtbVioiIXAFlmiIi4l2AjWkqaIqIiHfqnhUREZG4KNMUERHvAqx7VpmmiIiIn5RpioiIdwE2pqmgKSIi3ql7VkREROKiTFNERLwLsO7ZwLpaERGRK6BMU0REvNOYpoiIiMRFmaaIiHgXYGOaCpoiIuJdgAXNwLpaERGRK6BMU0REvNNEIBEREYmLMk0REfEuwMY0FTRFRMQ7dc+KiIhIXJRpioiIdwHWPRtYVysiInIFlGmKiIh3ATamqaApIiKeWYAFTXXPioiI+EmZpoiIeKZMU0REROKkTFNERLwLrERTmaaIiIi/lGmKiIhngTamqaApIiKeBVrQVPesiIiIn5RpioiIZ8o0RUREJE7KNEVExLNAyzQVNEVExLvAipnqnhUREfGXMk0REfEs0LpnlWmKiIj4SZmmiIh4FmiZpoKmiIh4FmhBU92zIiIiflKmKSIininTFBERkTgp0xQREe8CK9FUpikiIuIvZZoiIuJZoI1pKmiKiIhngRY01T0rIiLiJ2WaIiLimTJNERERiZMyTRER8S6wEk0FTRER8U7dsyIiIhInZZoiIuKZMk0REZEUzMwKmdl3ZrbGzP4ys96+8lAzm29mG3z/5vCVm5m9YWYbzWyVmVWJda7Ovv03mFnnS9WtoCkiIp6ZWaJvfogAnnTOlQNqAD3NrBzQD1jonCsJLPS9B7gdKOnbugFjfW0PBYYC1YEbgaHnAm18FDRFRMSz5AiazrndzrkVvtfHgbVAAaA5MNm322Sghe91c2CKi7YEyG5m+YBGwHzn3CHn3GFgPtA4oboVNEVEJNUysyJAZeA3IK9zbrfvoz1AXt/rAsD2WIft8JXFVx4vBU0REfHOEn8zs25mtjzW1i3Oqs0yA58DjznnjsX+zDnnAJfIV6ugeTlCs2Viycf9WPJxP7bMf5ZN80bGvE8TEpyoda37ejjTRj8Q875lg0qMH353otYB0OuuOmRInybm/RdvPky2zBkSvR5JmSpfV5Z2rZrHbDt37oh33xrVKidavV3vu4c772hE25Z30rlTB7Zu2XzZ5+j50IMcO3aMY8eO8cm0D2PK9+3by5OPPZpobZWrzzk33jlXLdY2/sJ9zCwN0QHzQ+fcDF/xXl+3K75/9/nKdwKFYh1e0FcWX3m8dMvJZTh09CQ1OjwPwMDuTTgZdobXPlgY83lwcBCRkVGJVl/lsoUoU+wa1m3ek2jnvFCvTnWZNmcZp06HA9DykbFJVpekPOnSpWf6jK+Spe7nXhhN+QrX8dn0T3hl9Iu8MWbcZR0/ZtwEAHbu3MEnH0+jfcdOAOTJk5eXX3sj0dsrcUuOW04sutJ3gbXOuVdifTQT6Aw87/v3q1jlvczsY6In/Rx1zu02s3nAs7Em/zQE+idUtzLNKzR++N28MbADP07pw7OPtWBg9yY8dk/9mM+XfzqAa/OFAtChyQ389EEflnzcjzcHdiAoKOH/2F7/YBFPd210UXnG9GkZN7QTP33Qh1+nPU3TOtcBkCF9Gqa+0IUVnw/kk5cf5McpfahS7trocw1oz+IPn+L3zwYy6KEmAPToeCv5cmdj7vjezB0f/Zf5uq+HkzN7Jp559E66t6sdU2fs63r83vosntqXpZ/0jzmX/DeEnTzJg106075NS1q3aMZ3ixZctM/+/fu4/95OtGvVnFbNm7Li9+UA/PLzYu65qz3t27Skz+OPEnbypF91Vq1Wje3btuGc45XRL9CqeVNat2jG3G/mJFjf7bfV4/DhQ7z+6svs2L6Ndq2a88roF9i5cwetmjcF4O6O7di4cUNMXV3vu4e/Vv9JWFgYQwb15672bWjXukWc1ykpWk3gHqCema30bU2IDpa3mdkGoIHvPcAcYDOwEZgA9ABwzh0CngGW+bYRvrJ4KdNMBAXyZKfOfS8TFeUY2D3uIFK6aF7aNKxC3ftfISIiitf6t6NDkxv4aPbSeM/7+bcr6Nb2FooVynVe+dMPNOL7ZX/z0PAPyZY5Az9N7cuiJevp1vYWDh8Lo0rrUZQrno/fPu4Xc8ywt2Zx+FgYQUHGN+88SoWS+Xl72g88enc9Gnd7nYNHzv+B+2zeCl7q25p3pv8IQOuGlbmzxxjq1yhD8WvzUOvulzAzPnutOzWrFOfnFZu8fn2SjM6cOU27Vs0ByF+wIKNfeZ1X3xhD5syZOXz4EPd0bE+duvXPyybmfD2bm2vW4sHuDxMZGcnp06c4fPgQE94ZyzsT3yNjxoxMmjieKZPf46EevS7Zhh++/44SpUqxcP63rF+3jk9nfMWRw4e5q30bqlarFmd9sfV+/Ek2btgQkzHH7mJu1LgJ3879hhK9SrJ//z72799H+QrX8cZrr3Bj9RqMGPkcx44do1OHtlSvcTMZM2ZMjK81oCRHpumcW0z8q97Wv7DAN77ZM55zTQIm+Vu3gmYimLHgf0RFJTzeXPfG0lQpdy2Lpz4FQIZ0adh/6ESCx0RGRfHqlAX07dKQb39eE1Ne/6ay3HHrdTx2b/R/G+nThlAoXw5urlyMtz76HoA1m3bz54ZdMce0bliFLq1qEhIcxDW5s1K2WD5Wx/r8Qn+s30HuHFnIlzsbuXJk5sixMHbsPULPu+rS4KYyLPEF5MwZ0lHi2jwKmqnUhd2z4eHhvPHaK6z4fRlBFsS+fXs5eOAAuXLnjtmnQoXrGDpoABEREdSt14AyZcuyfNl3bN60kfvu7hhznusrVUqw7v5P9yF9uvTkL1CAfgMG88Hk92jc5A6Cg4PJmSsXVW+4gb/+/DPO+vzVsPHtPPRgF3r0epRv537DbQ2j7yb49ZfFfP/dIqa8F/1befbMGfbs3k2x4sX9PrdEC7QVgRQ0E0HYqTMxryMiI8/rdk2fNnqSjZkxddZvDHlz5mWd+6Ovl9K3S0PWbNwdU2ZAxz4T2fDPvvgPjKVw/pw8dk99at39IkeOn2L88LtJl/bS/9PPWPA/WjaoRN6cWfns2xW+64CXJn3Lu5//fFnXIanDnNmzOHz4ENOmzyBNmjTcfls9zpw9c94+VavdwKQpU/nphx8YMrAf93S+nyxZs1Ljppq8MPqVeM58sXNjmpcSV33Nmre45HEAefPmJXv27Py9fh3z5n7DoCHDAHAOXnntDYoULeZ3e0VAY5qJ7p9dh6hUNnoyVqUyBSlSICcA3y1dT8sGlcidIzMAObJm5Np8CS48AUBERBRvTv2ORzrVjSlb8OtaenS4NeZ9xdIFAfh15WZaN4xeHapMsWuoUCI/AFkzp+fk6TMcPXGaPKFZaFizXMyxx0+eIXPG9HHW/dm832nbqCotG1Rmxvz/ATD/l7V0bn4TmTKkBSB/7mwx1ySp34kTxwkNzUmaNGlY+tsSdu26eCLhrl07yZkzF63btqNl67asXfMX11esxMr/rWDbP/8AEBYWxtatWy6r7spVqzHvm2+IjIzk0KFDrFi+nArXXR9nfbFlypQpwfHTRo2b8N6kiRw/fpxSpcsAcHPNWnz04VSie+1g7do18R4vl5AEt5ykZMo0E9mXC1fSqemN/P7ZQJb9uTUmG1y3eQ/Dx8xm1theBJkRHhHJ489PZ9vuw5c85/tf/kq/B/9dpOK5CXN5qU9rlk0fQFCQsXXnQVr3Hsc7039i4jP3sOLzgfy9ZS9rNu/m6IlTbNq2nz/W7eCPLwazY89hlqz8d3r/pBk/M3NMD3bvP0rjbufPOFy7eQ+ZM6Zn174j7DkQfQvUwiXrKFP0Gr6f3AeAk6fOcP/Ayew/nHBXs6QOTZo249GeD9O6RTPKla9A0WIXZ2LLly7l/ffeJSQkhIwZMzLyuRcIDQ1lxKjn6Nf3Cc6GnwWg1yOPUaRIUb/rrt/gNlb98T/atmqOmfHYk33JlTs3M7/84qL6YsuePQeVKlehVfOm1LrllphZtOfc1rARLz4/im4P9Ygp6/ZQD158/lnatLyTqKgoChQsyFtvv3M5X5UEKDv3l1ZiylC5V+KfVC4pKMhIExLMmbMRFC2YiznjenF9i2cIj4hM7qalSoeXvZXcTRBJFOlDki5/u/aRmYn+e7/tzTtTbL6pTPM/JGP6tMyd0Js0IUEYRu/npitgikiS0kQguap+nNKHtBdMyuk6aAp/bYx/Zmt8ToSdoVanFxOraSJX7LFHe7Jrx/mrDPV+og81a92STC0SuTLqnk1BCubNzsRn7iVPziw4B5M+/5kx075nYPcmdGl1c8y44dC3ZjJv8RpCs2Xio5e6UrV8YabOXMLjL3wac652javSt0sjnHPs3n+ULoMmX3QvpiRM3bOJ79ixYwwfMoiNG//GzBj+zLP88vNiPv9sOqE5ohcBeeSxJ7il9q2XOJNcjqTsni3Se3ai/95vfb1pik1flWmmIBGRUfR7ZQYr1+0gc8Z0/PLR0yz8bR0Ab0797rwl+wBOnwlnxNuzKVciP+WL54spDw4O4qW+bajSeiQHj5xkVO/mPNT+Vka9M+eqXo/IhV58bhQ1a93Cy6+9QfjZs5w6fTp6JaF776Pz/V2Tu3kil6RbTlKQPQeOsXJddFfWibAzrNuyh/y5s8e7f9jps/yycjOnz4SfV24WvZ27LSRL5gzs3n806Rou4ofjx4/z++/LaNm6DQBp0qYla9asydwquVLJ9BDqZKOgmUJdmy+USqULsmz1VgAe6lCbpZ/0Z9zQTmTPkvBTSCIiouj97Ccsmz6Azd+Oomyxa3j/y1+uQqtF4rdzxw5y5AhlyMD+tGvdgmFDBhIWFgbAxx99SJuWzRgyqD/HjuoPvFQlwO7TVNBMgTJlSMu00Q/Qd/TnHD95mgmf/kS5ZsOo3uF59hw4xvNPtErw+JCQIB5scws1Or5AsYYDWf33Tvp2aXiVWi8St8jICNatXUPbDh2Z/vmXZMiQgUkTx9OufUdmz53P9M+/InfuPIx+6flLn0wkmShopjAhIUFMG/0gn3yznK8W/QHAvkPHiYpyOOeYNONnqlUonOA5KpaKXiFoy44DAHw2fwU1Kmq5MEleefNeQ96813D99RUBuK1hY9atXUPOXLkIDg4mKCiIVm3asvrPP5O5pXI51D0ryWrc0E6s37KHN6Yuiim7Jte/4z7N61VkzabdcR0aY9f+o5Qpdg25fMvb1a9RhvVbku6ZnCL+yJU7N3mvuSbmgdO/LfmVYsWLs3//v2soL1qwgBIlSyZXE0UuSbNnU5CbKxWjU9Pq/Pn3zpiniAx9aybtGlXj+tIFcc7xz+5DPDJyWswx674eTpZM6UmbJoRmda+naY8xrNu8h2fHf8P8iY8RHhHJtt2H6DZ0anJdlkiMfgMG0//pPoSHh1OwYCFGjHyO558byfp16zCD/PkLMHjYiORuplyGlJ4ZJjbdpykSD92nKf8VSXmfZvEnv0n03/tNL9+eYiOxMk0REfEswBJNBU0REfEu0LpnNRFIRETET8o0r7KShfPwwQtdYt4XLZCTZ8Z+zVsffc/DHW6le7tbiIxyzP1pNQNf/+qi42+7uSyj+7YhOCiI97/8hdHvzQdgwbuPkTlT9MOk84RmYfnqrbR7YgIt6ldi8MN3cPjoSdo9MYFDR09StGAuRvRqxj393rsq1yz/fUMG9efHH74nNDQnM76afdHnx44eZcjgAezYvo20adMxfOSzlCxZKvqzONajrVipMq++/BI/L/6R0mXKMuq56AcRzJ71FUcOH+bue++7mpcnCQiwRFNB82rb8M8+anSIvnk7KMjYNG8UM7/7g9rVStK0znXc2P55zoZHkNt3u0hsQUHGa/3accfDb7Fz7xEWf9iX2T/8ybrNe2jQ9bWY/aaNfoBZ368C4OEOt1Lr7hdpXq8S7W+vxtiPf2BYz6YMe/viHzYRr5q3aEXHu+5mYP+n4/x84oRxlClTltfeGMOWzZt4duQIJkyaDMS9Hu3x48dZt3YNn30xi2FDBrLh7/UUurYwX30xg7ffmXg1L03kPOqeTUZ1byzNlh372bb7MN3a3sLo9+ZzNjwCIOaJJrHdUKEIm7YfYOvOg4RHRPLpvBU0rXP9eftkyZSeW28oxazvooNmVFQU6dKEkDF9WsIjIqlZuTh7Dxxj07b9SX+BEjCqVruBrNmyxfv55k2buLF6DQCKFivOrl07OXjgQLzr0QYFGRERETjnOH3qNCEhIUx+7106drqHNGnSXJVrEv9ocQO5ato2qsr0ub8DUKJwHmpWLs6PU/rw7cTeVC137UX758+TjR17D8e837n3MAVyn/9D1azu9Xy/dD3HT54G4KVJ8/l63CM0qV2B6XOX0+/Bxjw3YW4SXpXIxUqVLsPC+d8C8OeqVezetYu9e/fEux5tpkyZqXVLbdq3bkGu3LnJnCULf/65inr1GyTzlciFzj0gIjG3lExBM5mkCQnmjluvY8b8/wEQEhxEaLZM1L53NANe/ZKpL3a5xBni1q7xv4EYYNFv66jZ6UXaPPYOTetcz7zFf1GycB4+eqkrYwZ3JEN6/dUuSa/LA904dvw47Vo1Z9pHH1CmTFmCgoLjXY8W4P6uDzJ9xlf0eaofY958nZ69HmXGZ5/S94nejB/3djJfkQQqBc1k0qhWOVau286+Q8cB2Ln3CF8uXAnA8r/+ISrKxSyDd86ufUcpmDdHzPsCeXOwM9Yjv3Jmz0S18kX45qfVF9WXIX0a7mlWnXHTf2TQQ3fwwOAP+GXlZjrcfkNSXJ7IeTJnzswzo55j+oyvGPXcixw+fJiChQrFux5tbGvXrsE5R+EiRfl23lxeeuV1tm/fzj//bE2GK5ELBQVZom8pmYJmMmnXuNp5GeGs71dx6w3RswlLXJuHtGlCOHDBuObyv/6hxLW5KZw/J2lCgmnbqApf+yb8ALRsUJlvflrNmbMRF9X3+L0NeHvaD0RERJEhfRocjqioKDKmT5tEVyjyr2PHjhF+9iwAMz77lCrVqpE5c+Z416ONbcybr9Pzkd5EREQQFRUJRP9Qnz51+upehAiaPZssMqZPS73qZegVaw3ZyV/+yjvDOrH80wGcDY/kgSEfAJAvdzbeHnIXLR8ZS2RkFI+/MJ1Zb/ckOMiY/NUS1m7+dyH2to2qMvq9by+qL1/ubFSrUJhnx38DwNhpP7B46lMcPR5GuycmJPHVSiB4us8TLF+2lCNHDnNbvdo83PMRIiKi/3hr174jWzZvYtCAfphB8RIlGT5iVMyxca1He86ihQsoX74CefLkBaB0mbK0btGMUqVKUbpMmat7kRKnlD4Gmdi09qxIPLT2rPxXJOXasxUGzU/03/vVI29LsaFY3bMiIiJ+UvesiIh4Fmjds8o0RURE/KRMU0REPEvpK/gkNmWaIiIiflKmKSIingVapqmgKSIingVYzFT3rIiIiL+UaYqIiGeB1j2rTFNERMRPyjRFRMSzAEs0FTRFRMQ7dc+KiIhInJRpioiIZwGWaCrTFBER8ZcyTRER8SzQxjQVNEVExLMAi5nqnhUREfGXMk0REfEs0LpnlWmKiIj4SZmmiIh4FmCJpjJNERERfynTFBERzwJtTFNBU0REPAuwmKnuWREREX8p0xQREc8CrXtWmaaIiIiflGmKiIhnAZZoKmiKiIh36p4VERGROCnTFBERz5RpioiISJyUaYqIiGcBlmgqaIqIiHfqnhUREZE4KdMUERHPAizRVKYpIiLiL2WaIiLiWaCNaSpoioiIZwEWM9U9KyIi4i9lmiIi4llQgKWayjRFRET8pExTREQ8C7BEU5mmiIiIv5RpioiIZ7rlRERExE9BgRUz1T0rIiLiL2WaIiLiWaB1zyrTFBER8ZMyTRER8SzAEk0FTRER8c4IrKip7lkREUl1zGySme0zs9WxyoaZ2U4zW+nbmsT6rL+ZbTSz9WbWKFZ5Y1/ZRjPrd6l6lWmKiIhnyXjLyfvAW8CUC8pfdc6Njl1gZuWADkB5ID+wwMxK+T4eA9wG7ACWmdlM59ya+CpV0BQRkVTHOfejmRXxc/fmwMfOuTPAFjPbCNzo+2yjc24zgJl97Ns33qCp7lkREfHMzBJ9u0K9zGyVr/s2h6+sALA91j47fGXxlcdLQVNERDwzS4rNupnZ8lhbNz+bMxYoDlQCdgMvJ/b1qntWRERSFOfceGC8h+P2nnttZhOA2b63O4FCsXYt6CsjgfI4KdMUERHPgswSffPKzPLFetsSODezdibQwczSmVlRoCSwFFgGlDSzomaWlujJQjMTqkOZpoiIpDpmNg2oA+Qysx3AUKCOmVUCHLAV6A7gnPvLzKYTPcEnAujpnIv0nacXMA8IBiY55/5KqF4FTRER8Sy5VgRyznWMo/jdBPYfBYyKo3wOMMffetU9KyIi4idlmiIi4lmgPeVEQVNERDwLsJip7lkRERF/KdMUERHPruQWkdRImaaIiIiflGmKiIhngZVnKmiKiMgVCLTZs+qeFRER8ZMyTRER8SwZH0KdLOINmmb2JtHr98XJOfdokrRIREQkhUoo01x+1VohIiKpUqCNacYbNJ1zk2O/N7OMzrmwpG+SiIikFgEWMy89EcjMbjKzNcA63/uKZvZ2krdMREQkhfFn9uxrQCPgIIBz7g+gdlI2SkREUgczS/QtJfPrlhPn3PYLiiKToC0iIiIpmj+3nGw3s5sBZ2ZpgN7A2qRtloiIpAaBdsuJP5nmQ0BPoACwC6jkey8iIhJQLplpOucOAJ2uQltERCSVSeljkInNn9mzxcxslpntN7N9ZvaVmRW7Go0TEZGUzZJgS8n86Z79CJgO5APyA58C05KyUSIiIimRP0Ezo3PuA+dchG+bCqRP6oaJiEjKF2SW6FtKltDas6G+l9+YWT/gY6LXom0PzLkKbRMREUlREpoI9DvRQfJc2O8e6zMH9E+qRomISOqQwhPDRJfQ2rNFr2ZDREQk9Qm02bN+PU/TzCoA5Yg1lumcm5JUjRIREUmJLhk0zWwoUIfooDkHuB1YDChoiogEuABLNP2aPdsGqA/scc7dD1QEsiVpq0RERFIgf7pnTznnoswswsyyAvuAQkncLhERSQVS+i0iic2foLnczLIDE4ieUXsC+DVJWyUiIqlCgMVMv9ae7eF7Oc7M5gJZnXOrkrZZIiIiKU9CixtUSegz59yKpGmSiIikFrrl5F8vJ/CZA+rF9+F3n4703CAREZGUKqHFDepezYaIiEjq488tGP8lgXa9IiIinvm1IpCIiEhcNKYpIiLip6DAipmX7p61aHeb2RDf+2vN7Makb5qIiEjK4s+Y5tvATUBH3/vjwJgka5GIiKQaQZb4W0rmT/dsdedcFTP7H4Bz7rCZpU3idomIiKQ4/gTNcDMLJvreTMwsNxCVpK0SEZFUQROBLvYG8AWQx8xGEf3Uk0FJ2ioREUkVUnp3amLzZ+3ZD83sd6IfD2ZAC+fc2iRvmYiISArjz0OorwXCgFmxy5xz25KyYSIikvIFWO+sX92zXxM9nmlAeqAosB4on4TtEhERSXH86Z69LvZ739NPesSzu4iIBBA9hPoSnHMrzKx6UjRGRERSl0BbwNyfMc0nYr0NAqoAu5KsRSIiIimUP5lmllivI4ge4/w8aZojIiKpSYD1ziYcNH2LGmRxzvW5Su0RERFJseINmmYW4pyLMLOaV7NBIiKSemgi0L+WEj1+udLMZgKfAifPfeicm5HEbRMREUlR/BnTTA8cBOrx7/2aDlDQFBEJcAGWaCYYNPP4Zs6u5t9geY5L0laJiEiqoLVn/xUMZOb8YHmOgqaIiASchILmbufciKvWEhERSXUCbSJQQos5BNY3ISIicgkJZZr1r1orREQkVQqwRDP+oOmcO3Q1GyIiIqlPoE0ECrS1dkVERDy77KeciIiInGMBNv1FmaaIiIiflGmKiIhngTamqaApIt5Iyn4AACAASURBVCKeBVrQVPesiIiIn5RpioiIZxZgN2oq0xQREfGTMk0REfFMY5oiIiISJ2WaIiLiWYANaSpoioiId3o0mIiIiMRJmaaIiHimiUAiIiISJ2WaIiLiWYANaSpoioiId0F6NJiIiIjERZmmiIh4Fmjds8o0RURE/KRMU0REPNMtJyIiIn4KMkv0zR9mNsnM9pnZ6lhloWY238w2+P7N4Ss3M3vDzDaa2SozqxLrmM6+/TeYWedLXq+H70hERCS5vQ80vqCsH7DQOVcSWOh7D3A7UNK3dQPGQnSQBYYC1YEbgaHnAm18FDRFRMQzs8Tf/OGc+xE4dEFxc2Cy7/VkoEWs8iku2hIgu5nlAxoB851zh5xzh4H5XByIz6OgKSIiKYqZdTOz5bG2bn4emtc5t9v3eg+Q1/e6ALA91n47fGXxlcdLE4FERMSzpHjKiXNuPDD+Cs/hzMwlUpNiKNMUEZH/ir2+bld8/+7zle8ECsXar6CvLL7yeCloioiIZ8k1phmPmcC5GbCdga9ild/rm0VbAzjq68adBzQ0sxy+CUANfWXxUvesiIh4llyZl5lNA+oAucxsB9GzYJ8HpptZV+AfoJ1v9zlAE2AjEAbcD+CcO2RmzwDLfPuNcM5dOLnoPAqaIiKS6jjnOsbzUf049nVAz3jOMwmY5G+9CpoiIuKZBdjisxrTFBER8ZMyTRER8Syw8kwFTRERuQJJcZ9mSqbuWRERET8p0xQREc8CK89UpikiIuI3ZZoiIuJZgA1pKmiKiIh3uk9TRERE4qRMU0REPAu0zCvQrldERMQzZZoiIuKZxjRFREQkTso0RUTEs8DKMxU0RUTkCqh7VkREROKkTFNERDwLtMwr0K5XRETEM2WaIiLiWaCNaSpoioiIZ4EVMtU9KyIi4jdlmiIi4lmA9c4q0xQREfGXMk0REfEsKMBGNRU0RUTEM3XPioiISJyUaYqIiGcWYN2zyjRFRET8pExTREQ8C7QxTQVNERHxLNBmz6p7VkRExE/KNEVExLNA655VpikiIuInZZoiIuKZMk0RERGJk4Kmn+5rdhODe90ds+3fuyvefbu1rpNo9T7X72GG9u4c837LhrU81+/hRDv/OT/Nn83hg/tj3r/7+ih2btuc6PVIynPkyGHatWpOu1bNqVe7Jg3q3hLzPvzs2USt6/bb6tG6RTPatGxG9we7cGD//ksfdIF7O3UAYOfOHcyZPSum/K/Vf/L8syMTra3iH0uC/0vJ1D3rp7Rp0/HMW1OTpe5jRw/zx/JfqFjt5iSrY/HCrylYpDg5cuYGoGvvgUlWl6Qs2bPnYPqMrwAYO+ZNMmbMSOf7u8Z8HhERQUhI4v1UTHxvMjlyhPLGa68wccI79Bsw6LKOn/LhxwDs2rmTOXNm06RpMwDKV7iO8hWuS7R2in+CUnaMS3QKmh6dPhXG68/05eSJ40RGRND6nu5UuenW8/Y5cugAY54fyOmwk0RGRdK5x1OUrlCZP1cs4YsPJxARHk6eawrwwOODSZ8hY7x1NWl1N7M+ee+ioBkVGcn098ew7s8VhIeH06Bpa+re3oqoqCg+GDuatauWE5orL8EhwdS+rRk31KrPlx9NZOXSxZw9e4YSZa7j/kf6s/znRWzZsJZxLw0hbdp0DH55Ii8PfZwOXR9ly4a17Nu9gw5dHwWiM9ItG9dy78N9+XnRN8yfNZ3I8HCKlS5P5x5PERQcnPhftlx1gwf0I226tKxbu5ZKlauQOXPm84Jpq+ZNefPtcRQoUJDZs77io6kfEBEeToXrKzJw8FCC/fjvoGrVanz04QecOXOGkSOGseav1QQHB9PnqX7cWL0GGzduYMjA/kSEhxPlonj5tTcpXLgINapVZsny//H6qy+zZfMm2rVqTrPmLSlTtiyT35/EG2+N5Y5GDfjk8y/JmjUrAM1ub8j7H3yEBQUxcvhQ9uyO7inq228AlatUTbovUv5zFDT9dPbsGQb3uhuAXNfkp1f/Z3l00AtkyJiZ40ePMOLJrlSuURuLNSr+6/fzuK5KDe7scD9RkZGcOXOa40ePMPPj93h61FukS5+Brz+dwtwvPqLFXQ/EW3eJstfx+6/fs/aP5aTPmCmm/IdvZ5IhU2aGvfY+4eFnGdnnQSpUrsHWjWs5sG8Xz479mGNHDtP/ofbUvi36r/EGzdrG1PXO6KGsXLqYG2rVZ8Hsz+jQ9VGKlix7Xt3VatblmScfiAmav/20gDvb38eubVtY+tMCBr00gZCQECaPeZFfvp9HrfpNEucLl2S3d+9epnz4McHBwYwd82ac+2zetIl533zD5KnTSJMmDaNGDGPO7Fk0a97ikuf/4YfvKVGyFB9P+xAz+PzLWWzZvImHHuzKzDnz+PSTj+l0z73c0fROws+eJTIq6rzjez/+JJPfn8Rbb78DwLKlvwEQFBREnXr1WLRwPi1atmbVqj/Ilz8/OXPlol/fJ7n73s5UqVqN3bt28XD3rnw565sr/KYCW0rvTk1sCpp+urB7NiIigk8nj2X96pUEmXH44H6OHj5E9tCcMfsULVWOd18bSWRkBFVq3Erh4qVYuXQxu7ZvYWSfB33nCadEmUt3Kd3ZoQszP3mPdvf3iilb/b/f2L5lI8sXLwIgLOwEe3Zt4+81f3BDrfoEBQWRPTQnZa//9y/ptat+Z85nUzl75jQnThyjwLXFqFz9lnjrzZotB7mvyc/GdX9yTf5r2b1jKyXLVWTB7M/YunEdwx+7D4j+oyJr9hz+fZmSKjRs2PiSGeNvS35l7ZrVdGrfBoDTZ04TmjNngsc8cH9ngoOCKFm6NL0efYwhg/rT8a7oP0iLFitOvvz5+WfrFipWrMSE8ePYu2cP9W9rSOHCRfxue6PGTXhn7BhatGzNvDlf06hx9B9zS5b8wuZNG2P2O3HiBGEnT5IxU6b4TiVyHgVNj379bi7Hjx5h+OuTCQkJ4cn7WxAefua8fcpUqMyAF8bxx7KfmfjqCBq1vItMmbNQvtKN9Hj68iYslKtYjc+njGPjutX/FjrHPQ/14bqqNc7bd9XyX+I8x9mzZ5jy9osMe20yOXPn5YsPJxAefumJHjVq38bSnxaSr2Bhqt5UJzqbdo6a9ZvQ7r6el3UdknpkyJAh5nVwcDBRsTK9s2ei/1t3OJo1b0nvx5/0+7znxjQvpUnTZlx3fUV+/PF7ej3UjUFDh1O9xk1+1VGxUmW2b9vGoUOHWLRoAQ8+FD15zkVF8cG06aRLl87v9krCdMuJ+OVU2AmyZstBSEgIa/9YzoF9uy/a58C+3WTLHkqdxi2o3ag5/2xaR/EyFdiwdhV7d20H4MzpU+zZuc2vOu/scD9zPv8g5n2FKjVYNOdzIiIiANizcxtnTp+iZNmKLP/5O6Kiojh6+CDr/lwBEDMTMkvWbJw+FcaynxfFnCt9hoycDjsZZ71Vb6rDiiU/suSHb6le+zYAylWqxvKfF3HsyCEAThw/Gud3IP8N+QsUYO3aNQCsXfMXO3fuAKB69ZtY8O08Dh48CMDRI0fYtWvnZZ27SpVqzPk6ehbs1q1b2LN7N0WKFmPH9u0ULFSITnffS5169dnw9/rzjsuUKRNhJ+P+b9bMqNegAaNffI5ixYqT3dcLctPNtZj24b//P7Ru7drLaqtcTLNnxS831WnMqyOeZGCPuyhSsgz5Cha5aJ91q1YwZ8ZUgoNDSJ8hA92eGEbWbDl48PEhjH1xMOHh4QC0vqc71xS49pJ1VryhJlmyZo95f2uj5hzYt5uhj96Lw5Ela3Z6D36JajXrsuaPZQx4uAOhufJSuHhpMmTKTKbMWbi1UQsG9LiLbDlynjd+WavBHbw/5oWYiUCxZcqSlfyFirBr2xaKly4PQIFri9H6nod4adCjRDlHcHAw9/boS648+bx8nZLCNbitEbNmfkXLO+/guuuvp3CRIgAUL1GCno8+xsMPdiHKRRESkoYBg4aQP38Bv8/dvuNdjBwxjNYtmhEcHMyIUc+RNm1a5s39htmzviJNSAg5c+XigQe7n3dcyVKlCQoKom3LO7mzRSvKlD1/PL5R4ybc1b4Nz4x6Pqbs6QEDeXbkCNq0bEZkRCRVqlVj8NAR3r8YCTjmnEv0ky7ZeCTxTyqX5fSpMNJnyMiJY0cZ9vj9DHppwnnjrXJplYpkv/ROIqlA+pCkS99+/PtQov/e1y4VmmLTTWWa/1GvDn+SsBPHiYgIp3mHLgqYIiKJQEEzhXh95FMc2HP+KkPt7u910SQff/V/fmxiNEvEk04d2l60mtCo51+kZKnSydQiSSopfQwysal7ViQe6p6V/4qk7J5dvOFwov/e1yqZI8VGYmWaKdjJE8eZ9MYodv6zGTAeeGwQJcpex/yZ01n49WdYUBCVbqhJ+y6P8Mt3c/nm83/vI92+dSPDX59C4eKlku8CRC5w7Ngxhg8ZxMaNf2NmDH/mWYoUKcpTfR5n186d5C9QgJdefo2s2bIld1NF4qRMMwUb/8pwSpWvRJ1GzYkID+fMmdNs27SemZ+8zxPDXyFNmrQcO3KIrNnPv+dt+9aNvP7MU4x+d0Yytfy/QZlm4hvU/2mqVK1GqzbR3benTp/m3fHjyJotO10f7Ma7E8Zz7NhRHn+yb3I39T8lKTPNn5Mg06yZgjNN3aeZQoWdPMH61f/j1oZ3AhCSJg2ZMmdh4ZwZNG17L2nSpAW4KGACLPnhW2r47qcUSSmOHz/O778vo2Xr6NWD0qRNS9asWfnuu4Xc2SJ62b07W7Tgu0ULkrOZIglS92wKtX/PLrJky8HEV59h25YNFClRhru7P8HendtY/9dKPpsyjjRp09Kh66MUK1XuvGN/+3EBjw1+KZlaLhK3nTt2kCNHKEMG9mf9+nWUK1+ep/oN5NDBg+TOnQeAXLlyc8i3UIKkDkEBtiSQMs0UKioqkn82rqdek1Y88+YHpEufntmfTiYyKpKTx48x5JV3ad/lEcY8P4DYXeyb1q0mXbr0FCxSPBlbL3KxyMgI1q1dQ9sOHZn++ZdkyJCBSRPHn7ePmQXeumySqihoplA5cuYhNFceipepAMANNevxz8b1hObMQ7Wbo9d/LV66PGZBHD92JOa4JT/Op8atDZOr2SLxypv3GvLmvYbrr68IwG0NG7Nu7RpCc+Zk//59AOzfv4/Q0EuvSysphyXBlpIpaKZQ2UNzEpo7D7t3/APAmj+Wk//aolS56VbWrvodiF5rNjIiPGZpvaioKJYuXhizPqxISpIrd27yXnMNW7dsBqKfkFKseHHq1K3HzC+/BGDml19St2795GymXK4Ai5oa00zB7u7eh3EvDSEiIoI81+TngccGky59Bia+NpIBPToSEpKGB58YGvMMz/Wr/0fOXHnIk8//dT9FrqZ+AwbT/+k+hIeHU7BgIUaMfI4oF0XfJx7jyxmfkS9/fl56+bXkbqZIvHTLiUg8dMuJ/Fck5S0nv206mui/99WLZ0ux+aa6Z0VERPyk7lkREfEs0CY7K2heZQf372X8y8OiH95sRt3GLWjYvAMnjh/l7ecHcWDfLnLlyU/PfqPIlCXrRcePHtybTetXU7JcRZ4Y9kpM+YRXRrBu9QoyZswMwAOPD6Fw8VIs+3kRM6aOJ3OWrPQe9BKZs2Zj7+4dfDZ5LD37jbpq1y3/bUMG9efHH74nNDQnM76afdHnx48fZ8DTfdmzexcRkZF0vr8LLVq2BuDhbl35c9UfVKpSlbfefifmmP5PPcmGDX9T+9a6PPrYEwCMH/c2JUqWol79BlfnwuSSAixmKmhebcHBwXR8oDdFSpThVNhJhvbuTPnKN7J4wdeUq1iNpu06M3v6ZGZ/OoX2XXpddPztre/m7JnTfPfNFxd91qHLI9xQ6/yZhwtmfcqwV99n+S/f8ev387jtznZ8PmUcre/pftHxIl41b9GKjnfdzcD+T8f5+SfTPqRY8eK8+fY4Dh06RPM7GnPHHc1IkzYt93V5gFOnTvHZp5/E7P/3+nWkS5+ez76YRfcH7uf48eOcPn2KP1etottDPa7WZYlcRGOaV1n20FwUKVEGgAwZM5G/UBEOH9zPiiU/UqvBHQDUanAHK5b8EOfx5SvdQPoMGf2uz8yICD/L2TOnCQ4JYf3q/5EtR06uKXDtlV+MiE/VajckuMi6mRF28iTOOcLCTpItWzaCQ6L/Zq9e4yYyZcp03v4hIWk4c/o0UVFRREREEBwUxNtvvkGPXo8k6XWIBwF2y4mCZjLav3cX/2z+m+Kly3PsyCGyh+YCIFuOnNHdt5fpsynjGNizEx+Of5Xw8OhnGTZt15kXBvZi5dLF1Li1IV99PInmHbsk6nWIXEqHuzqxefMmGtS5hTYt7uSp/gMJCor/56dY8eLkyBFKhzYtqV2nLtu2bSPKRVG2XPmr2GqRi6l7NpmcPhXGm6P60enBx8ngG4c8J/q+y8v7c6vtfT3IliMnERHhvPfmc3z96RRa3PUAFSpXp0Ll6gAsXjiHitVuZs/ObXwz40MyZc5Kp25PkC59+sS6LJE4/bJ4MWXKlGXie1PYvm0b3R+8nypVq5E5c+Z4j3mq/8CY14/0eIjBw4Yz4Z2x/L1+HTVuqknrtu2uRtPlEgLtIdTKNJNBREQEbz7bj5vrNqZazbpA9NNKjhw6AMCRQwfImj3HZZ0ze2guzIw0adJyS4OmbP57zXmfnzl9msULZlO/aVu++HAC3Z4YSqlyFfn1+7mJc1EiCfjqyxnUv60hZsa1hQtToEBBtmze7Nex3y1aQLny5QkLC2P79m289MrrzP92HqdOnUriVos/zi0XnJhbSqageZU553j39ZHkL1SExi3viimvXP0WFi/4GoDFC76mSo3al3XecwHXOceKJT9QsPD5C7bPmTGV2+5sT0hICGfPnAEMCzLOnjl9ZRck4odr8uXjtyW/AnDwwAG2bt1CwUIFL3lceHg4U6dM5r4uD3Dm9JmY1a+ioiIJDw9P0jaLxEUrAl1lf/+1klFPdadgkRIxj9Rp0/lhipeuwJjnB3Bw/x5y5s5Hz/6jyJwlG1s2rGXRnBl07R3dVTXqqW7s3v4Pp0+fInOWrHTtPYjrqtbg+f49OH70CA7HtUVLcV+vp2MmDB0+uJ/33niWJ4a/CsDSnxbyxUcTyJgpC70Hv0jWbJeX1QYKrQjkv6f7PMHyZUs5cuQwoTlz8nDPR4iIiACgXfuO7Nu3l8ED+3Ng/36cc3R54EGaNmsOwH333MXWLZsJCwsjW/bsDBsxipq1bgFg6pT3yZIlK81btsI5R7++T7Jx4wZq3VJbD6q+DEm5ItCKrccS/fe+SpGsKTbfVNAUiYeCpvxXKGgmHk0EEhER71JseEsaGtMUERHxkzJNERHxLNBuOVHQFBERz1L6LSKJTd2zIiIiflKmKSIingVYoqlMU0RExF/KNEVExLsASzUVNEVExLNAmz2r7lkRERE/KdMUERHPdMuJiIhICmdmW83sTzNbaWbLfWWhZjbfzDb4/s3hKzcze8PMNprZKjOr4rVeBU0REfHMkmC7DHWdc5Wcc9V87/sBC51zJYGFvvcAtwMlfVs3YOxlX6iPgqaIiHiXzFHzAs2Byb7Xk4EWscqnuGhLgOxmls9LBQqaIiKSGjngWzP73cy6+cryOud2+17vAfL6XhcAtsc6doev7LJpIpCIiHiWFLec+IJgt1hF451z4y/YrZZzbqeZ5QHmm9m62B8655yZJfqzPhU0RUQkRfEFyAuD5IX77PT9u8/MvgBuBPaaWT7n3G5f9+s+3+47gUKxDi/oK7ts6p4VERHPzBJ/u3SdlsnMspx7DTQEVgMzgc6+3ToDX/lezwTu9c2irQEcjdWNe1mUaYqISGqTF/jCoiNsCPCRc26umS0DpptZV+AfoJ1v/zlAE2AjEAbc77ViBU0REfEsOdY2cM5tBirGUX4QqB9HuQN6JkbdCpoiIuKdVgQSERGRuCjTFBERz/SUExEREYmTMk0REfEs0J5yoqApIiKeBVjMVPesiIiIv5RpioiIdwGWairTFBER8ZMyTRER8SzQbjlR0BQREc8CbfasumdFRET8pExTREQ8C7BEU5mmiIiIv5RpioiIdwGWairTFBER8ZMyTRER8Uy3nIiIiPhJt5yIiIhInJRpioiIZwGWaCrTFBER8ZcyTRER8S7AUk0FTRER8SzQZs+qe1ZERMRPyjRFRMQz3XIiIiIicVKmKSIingVYoqmgKSIi3ql7VkREROKkTFNERK5AYKWayjRFRET8pExTREQ805imiIiIxEmZpoiIeBZgiaaCpoiIeKfuWREREYmTMk0REfFMTzkRERGROCnTFBER7wIr0VTQFBER7wIsZqp7VkRExF/KNEVExDPdciIiIiJxUqYpIiKeBdotJwqaIiLiXWDFTHXPioiI+EuZpoiIeBZgiaYyTREREX8p0xQREc90y4mIiIjESZmmiIh4pltORERE/KTuWREREYmTgqaIiIifFDRFRET8pDFNERHxLNDGNBU0RUTEs0CbPavuWRERET8p0xQREc8CrXtWmaaIiIiflGmKiIhnAZZoKmiKiMgVCLCoqe5ZERERPynTFBERz3TLiYiIiMRJmaaIiHimW05EREQkTso0RUTEswBLNBU0RUTkCgRY1FT3rIiIiJ+UaYqIiGe65URERETipExTREQ8C7RbTsw5l9xtEBERSRXUPSsiIuInBU0RERE/KWiKiIj4SUFTUhQzizSzlWa22sw+NbOMV3Cu982sje/1RDMrl8C+dczsZg91bDWzXP6WX7DPicusa5iZ9bncNopI4lHQlJTmlHOuknOuAnAWeCj2h2bmaca3c+4B59yaBHapA1x20BSRwKKgKSnZT0AJXxb4k5nNBNaYWbCZvWRmy8xslZl1B7Bob5nZejNbAOQ5dyIz+97MqvleNzazFWb2h5ktNLMiRAfnx31Z7i1mltvMPvfVsczMavqOzWlm35rZX2Y2ET8WETOzL83sd98x3S747FVf+UIzy+0rK25mc33H/GRmZRLjyxSRK6f7NCVF8mWUtwNzfUVVgArOuS2+wHPUOXeDmaUDfjazb4HKQGmgHJAXWANMuuC8uYEJQG3fuUKdc4fMbBxwwjk32rffR8CrzrnFZnYtMA8oCwwFFjvnRpjZHUBXPy6ni6+ODMAyM/vcOXcQyAQsd849bmZDfOfuBYwHHnLObTCz6sDbQD0PX6OIJDIFTUlpMpjZSt/rn4B3ie42Xeqc2+Irbwhcf268EsgGlARqA9Occ5HALjNbFMf5awA/njuXc+5QPO1oAJSzf+/czmpmmX11tPId+7WZHfbjmh41s5a+14V8bT0IRAGf+MqnAjN8ddwMfBqr7nR+1CEiV4GCpqQ0p5xzlWIX+ILHydhFwCPOuXkX7NckEdsRBNRwzp2Ooy1+M7M6RAfgm5xzYWb2PZA+nt2dr94jF34HIpIyaExTUqN5wMNmlgbAzEqZWSbgR6C9b8wzH1A3jmOXALXNrKjv2FBf+XEgS6z9vgUeOffGzM4FsR+Bu3xltwM5LtHWbMBhX8AsQ3Sme04QcC5bvovobt9jwBYza+urw8ys4iXqEJGrREFTUqOJRI9XrjCz1cA7RPeafAFs8H02Bfj1wgOdc/uBbkR3hf7Bv92js4CW5yYCAY8C1XwTjdbw7yze4UQH3b+I7qbddom2zgVCzGwt8DzRQfuck8CNvmuoB4zwlXcCuvra9xfQ3I/vRESuAq09KyIi4idlmiIiIn5S0BQREfGTgqaIiIifFDRFRET8pKApIiLiJwVNERERPyloioiI+ElBU0RExE8KmiIiIn5S0BQREfGTgqaIiIifFDRFRET8pKApIiLiJwVNERERPyloSrIysxZm5nwPaE71zKyqmf1pZhvN7A0zszj26et7budKM1ttZpFmFmpmpWOVrzSzY2b2mO+Yimb2q+/cs8ws69W/OhHR8zQlWZnZJ0B+YJFzbmgS1RHsnItMinPHUddSoh9g/RswB3jDOfdNAvs3Ax53ztW7oDwY2AlUd879Y2bLgD7OuR/MrAtQ1Dk3OMkuRETipExTko2ZZQZqAV2BDr6yYDMb7cvAVpnZI77yG8zsFzP7w8yWmlkWM7vPzN6Kdb7ZZlbH9/qEmb1sZn8AN5nZEDNb5jvv+HMZoJmVMLMFvvOuMLPiZjbFzFrEOu+HZtbcj+vJB2R1zi1x0X+NTgFaXOKwjsC0OMrrA5ucc//43pcCfvS9ng+0vlR7RCTxhSR3AySgNQfmOuf+NrODZlYVuBEoAlRyzkX4ui3TAp8A7Z1zy3xdk6cuce5MwG/OuScBzGyNc26E7/UHQFNgFvAh8Lxz7gszS0/0H5LvAo8DX5pZNuBmoLOZlfa1Iy51gALAjlhlO3xlcTKzjEBjoFccH3fg/GD6F9Hf15dAW6DQ/9u792Cry3qP4++PoqRBXss4ZMERGzIvVKBmmZeMk1YWE10srbyUt9LyWFbT1X/SbKbSxuMpG0ubstQoogIvo0SWZmGCgBQFdiNPR0UFRQM//fE8q36u1tqszd6bvZn5vGbWrLWe9bs8vz0yX5/f5fN0PfKIGDIpmjGcjgO+WD9fXb9PBC6zvQHA9gOS9gNW276jtj0M0OFyYdNG4LrG9yMkfQjYEdgVWCLpFmC87Vl1u+vrsvMlXSrpmZQR3XW1P8uBKd12uIn+dPI64FbbD7RtZ3vgWOAjjeaTgIslfRyYDTzR351FxMClaMawkLQrcCSwnyQD2wIG7ujHZjbw1EsMT2t8Xt+6jllHkJcCU23/UdKn2pbt5ErgeMqI78S6nU2NNP8MPKfR9pza1k37aLLlaGCh7ftaDbbvAabXfjwfeM0m+h8RQyDXNGO4zASusv082xNs7wmsBO4CTpU0Cv5ZXJcD4yRNq21j6++rgCmStpG0J+XUbietAvn/9TrqTADbjwB/0OrTVgAACatJREFUal2/lDS6njIF+Brw/rrc0vq+3PaULq81tlcDD0s6uF4zfQfw/U4dqqd9D+vy+79d55T0rPq+DfAx4LIuxxoRQyhFM4bLccCstrbrgHHAH4BF9Saet9l+AngLcEltu4FSCG+lFNqlwMXAwk47sr0G+ApwNzCPp45mTwDOkrQI+Bnw7LrOfcAy4Ip+HtcZwOXACuB3wI8BJJ0m6bTGcjOA622va64s6enAq4Dvtm33OEm/Ae4B/rIZ/YqIQZBHTiI6qCPOxcCLbT803P2JiJEhI82INpKOoowyL0nBjIimjDQjIiJ6lJFmREREj1I0Y1jV3NVWBus1jbtXB7LN8+sp1m6/nybpHQPdTx/b32T+bGPZaZI2SJrZaPuspCWSljXX7892I2JopGjGcHusPrKxL+WB/eYdprQePekP25+wfWMfv19m+8r+d7Vn/wO8G9i7vl7daaGaL3shcH2j7RDgZcD+wL7ANMqjKT1vNyKGTopmjCQLgEmSDpe0QNJsYGnNo72oZscuknRqawVJ59XR112SLqhtX2uN3CRdIGlpXe9zte1Tks6tn6dIuq3+PkvSLrX9FkkXquTc/kbSob0cQD/zZ99Heczm/xptpjxOsz0wGtgOuG8zc20jYpAlEShGhDqiPBqYW5teDOxre6Wk9wAP2Z4maTRwq6TrgcmUPNaDbD9agxCa29yN8jzkZNuWtHOHXV8JvK/OHnI+8ElqqAEwyvaBko6p7UcNVv6spPG1b0dQRpMA2P65pJuB1YCAL9leJmlqL9uNiKGVohnDbQdJv66fF1DC0g8BfmF7ZW2fDuzfuO63E+X05FHAFbYfhZJT27bth4D1wFclzQHmNH+sqTw7255fm74OXNNYpBUw8CtKiDy2Byt/9gvAebafbK4jaRLwAv4Vx3dDHeVuKqA+IraAFM0Ybo/ZfkoRqkWkmZQjymhwXtty/9XXhussKQdSptmaSZlN5Mi+1mnzeH3fSP23Moj5s1OBq+ux7g4cI2kD5X8GbrO9tu7vx8BLgat63G5EDKFc04ytwTzgdEnbQQksr3FzNwAntu647XB6dgywk+0fUab6OqD5ew0ueLBxvfIEYD59GKz8WdsTa+buBOBa4Azb36NECB4maVQ93sOAZf3JtY2IoZORZmwNLqecHl1YC8bfgDfYnitpCvBLSU8APwI+2lhvLPB9lVlOBJzTYdvvBC6rhff31BlNBugMSuD7DpTs2X/mz0K5e7ePda+ljIYXU24Kmmv7B31tNyK2nCQCRURE9CinZyMiInqUohkREdGjFM0Y0dpi9n7Q5VnLgWx/laTd6+e1/VhvoqTba6TdtyVt32W5j9Rlljfv9pX0gRqVd7ekb9Xrrkj6ag1qWCTp2nozU0SMECmaMdI1Y/YeAM4c7g5VFwKftz0JeBA4uX0BSfsAbwVeSIm8u7SmG40HzgKm1uPati4H8AHbB9jen3In7XuH/lAiolcpmrE1+Tk1BUfSXpLmSvpVjdybXNv3qHF4d9XXIbX9e3XZJTVhaLPVO3iPpNzpCiUUoVOk3euBq20/XoMaVgAH1t9GUYIdRgE7An8BsP1wYx87UO6gjYgRIo+cxFZBJdz8lZTEIIAvA6fZ/q2kg4BLKYXsYmC+7Rl1ndbpzZNsPyBpB+AOSdfZvr/LvsZS0ok6eRslK3aN7Q21rVuk3Xjgtsb3PwHja1Te5ygjyceA6203Q9uvAI4BlgL/3aUfETEMUjRjpGvF7I0HllFi5cZQovauaUTQja7vR1Ie/Mf2RkqUHsBZkmbUz3tSknc6Fk3bj9B3VN7um300Zf1dKKPQicAaynEcb/sbdf8n1oJ/CfAW4IqB7C8iBk9Oz8ZI14rZex4loOBMyn+3a9rSeF7QbQOSDqfk1L7U9gHAnZSZRLotP7befNTptQ+l2O6sf01b1i3S7s+UAk3bckcBK23/zfbfKRm3hzRXrAX/auCN3foZEVteimZsFWoo+1mU05WPAislvQnK9T9JrYi8m4DTa/u2NZR9J+DBOhPKZODgTezrkT6i8pbWqblupuTZQkkV6hRpNxt4q6TRkiZSRre/oJyWPVjSjvXa5SuBZfU4JrWOCTgWuGcz/lwRMURSNGOrYftOYBFwHPB24GRJdwFLKKc7Ac4GjpC0mDI7yT6U6cZGSVoGXMBTrzNurvOAcyStAHajXmuVdKzKFGPYXgJ8h3Jtci5wpu2Ntm+n3ES0kBKXtw3lGq2Ar9e+LwbGAecPQl8jYpAkRi8iIqJHGWlGRET0KEUzIiKiRymaERERPUrRjGHXyJdtvSZI2k3SzZLWSvpSH+u+VtKdNf1nqaRTt2TfO/RnV0k3SPptfd+ly3JzJa2RNKfL7xc3s3AlvULSQkkbJM3stE5EDL0UzRgJHmt7rGMVsB74OHBut5UkbUe56/R19fnLFwG3DKQj9bGPgfy7+DBwk+29KY+/fLjLchcBJ3Tpw1Sgvdj+AXgX8M0B9C0iBihFM0Yk2+ts/5RSPLsZS0m1ur+u87jt5dBnBu05dWaRuyW9v7ZNUJmF5ErgbmBPSR+UdIfKbCOf7kfXX0/JooXumbTYvgl4pL29JgFdBHyobflVthcBT/ajLxExyBKjFyNBKyoPSlLOjD6XrmqW7GzgXkk3AXOAb9l+kg4ZtJJeApwIHER5JvJ2SfMps5TsDbzT9m2SptfvB9blZkt6he2fSFpAKdbtzrV9I7CH7dW17a/AHv38W7wXmG17dSMiMCJGiBTNGAlaUXn9ZvsUSftRounOBV5FOY35bxm0kl4OzLK9DkDSd4FDKck999puhR5Mr6876/cxlCL6E9uH9qNvltTzg9CS/gN4E3B4r+tExJaVohlbPduLgcWSrgJWUopmf61rfBbwGdv/275QDyPN+ySNqyPFcZQZUXr1ImASsKKOMneUtKLO2RkRI0CuacZWS9KYGsbeMgW4t37ulEG7AHhDzXx9OjCDzlOAzQNOqrOpIGm8pGcB2D60SybtjXXd2ZQsWuieSduR7R/afrbtCbYnAI+mYEaMLInRi2Enaa3tMR3aVwHPALanTKE13fbSxu9jgW8De1HmpVwHnG37l5L2oNxZ+5/ARuD0Oo/lOcBJdROX2/6CpAnAHNv7NrZ9NnBK/boWON7273o4lt0oebPPpRTwN9drr1Mp83+eUpdbAEymnPq9HzjZ9rxufxdJ04BZlLtq1wN/tf3CTfUnIgZXimZERESPcno2IiKiRymaERERPUrRjIiI6FGKZkRERI9SNCMiInqUohkREdGjFM2IiIgepWhGRET06B/04yIG9mMwQQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKFg_7V13qj"
      },
      "source": [
        "### Treinando o modelo sobre toda a base (100% de df_train, X_treinamento = 100% X, y_treinamento = 100% y)\n",
        "ml_XGB.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyMkW8EB-s1U"
      },
      "source": [
        "ml_XGB_1 = XGBClassifier(silent=False,\n",
        "                         scale_pos_weight=1,\n",
        "                         learning_rate=0.01,  \n",
        "                         colsample_bytree = 1,\n",
        "                         subsample = 0.8,\n",
        "                         objective='binary:logistic', \n",
        "                         n_estimators=1000, \n",
        "                         reg_alpha = 0.3,\n",
        "                         max_depth= 3, \n",
        "                         gamma=1, \n",
        "                         max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1AWis2Xt9v-"
      },
      "source": [
        "# treinando o modelo sobre toda a base X (100% de df_train)\n",
        "ml_XGB1.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsWDYOunJXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382f9662-bae4-4563-fbf8-1beae73a3be6"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.8\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTnHowjpQTQ"
      },
      "source": [
        "# ml_XGB_1                            # Modelo treinado sobre X e y (100% df_train)\n",
        "\n",
        "# CV com X e y:                                             # Modelo treinado sobre toda base X (100% df_train)\n",
        "# AcurÃ¡ciaMÃ©dia / STD mÃ©dio\n",
        "# ??????????? => tirando outliers\n",
        "# 77,80 / 0,559  => sem tirar outliers\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste) ====> X_teste (% sobre X)\n",
        "# 0: 3194, 1: 116 => tirando outliers de df_train\n",
        "# 0: 3199, 1: 111 => sem tirar outliers de df_train\n",
        "\n",
        "# y_submit calculado com modelo treinado sobre TODA A BASE 'X' (100% df_train):\n",
        "\n",
        "# y_submit = ml_XGB_1.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "# 0: 955, 1: 45 => tirando outliers de df_train ==> PyLadies.csv com pontuaÃ§Ã£o = 0,4610\n",
        "# 0: 956, 1: 44 => sem tirar outliers de df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uUSripHII-8",
        "outputId": "7257fa2c-54cd-41af-f7f5-32174e77b062"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.8\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzvFPvCuJNbG",
        "outputId": "84b321e3-02cd-4324-cf97-c46e948b13fd"
      },
      "source": [
        "y_pred_1 = ml_XGB_1.predict(X_teste)\n",
        "unique_elements, counts_elements = np.unique(y_pred_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3199  111]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53EqCaJgJsGg"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred_1)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bafMtn3IQzi",
        "outputId": "be823d3f-a9b3-42a9-a060-1d40a478b53c"
      },
      "source": [
        "y_submit_1 = ml_XGB_1.predict(X_submit)\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9LGBShGt9wQ"
      },
      "source": [
        "df_submit_1 = pd.DataFrame(zip(df_test['id'],y_submit_1), columns = ['id','target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "MzStMVKLt9wU",
        "outputId": "cd759c29-e9a3-496d-cd20-763741fdae63"
      },
      "source": [
        "df_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  target\n",
              "0  3411   False\n",
              "1  2177   False\n",
              "2  8400   False\n",
              "3   464   False\n",
              "4  6672   False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUM9gFa1t9wa"
      },
      "source": [
        "df_submit_1.to_csv('PyLadies.csv',index = False, sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3zYdWgrzaOg"
      },
      "source": [
        "### LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llWEkYjWzZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732a26e2-e18d-416c-eef9-4bbd8a658a30"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmo-OjUYzZl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892f8e50-78ea-4ec8-dcdb-2b9343f6d26f"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.3MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQmrMW_zpAi"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNuQMi0Lz9Gg"
      },
      "source": [
        "X_train = X\n",
        "y_train = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDTQPmLA2ANY"
      },
      "source": [
        "X_test = X_submit\n",
        "y_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-uejECUyItk"
      },
      "source": [
        "# Preprocessing our data\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#tfidf = TfidfVectorizer(max_features=2000)\n",
        "#X_train = tfidf.fit_transform(df_train).toarray()\n",
        "#X_test = tfidf.transform(df_test).toarray()\n",
        "#y_train, y_test = df_train, df_test\n",
        "X_train_sub, X_valid, y_train_sub, y_valid = train_test_split(X_train, y_train, test_size=0.5,random_state=1234)\n",
        "# Setting up our results dataframe\n",
        "df_results = pd.DataFrame(columns=['accuracy', 'run_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOVl-3DayIt6"
      },
      "source": [
        "lgbm = LGBMClassifier(n_estimators=2000,\n",
        "                      feature_fraction=0.06,\n",
        "                      bagging_fraction=0.67,\n",
        "                      bagging_freq=1,\n",
        "                      verbose=0,\n",
        "                      n_jobs=6,\n",
        "                      random_state=1234,\n",
        "                      force_row_wise=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kB4dRc2yIt6"
      },
      "source": [
        "cb = CatBoostClassifier(n_estimators=2000,\n",
        "                        colsample_bylevel=0.06,\n",
        "                        max_leaves=31,\n",
        "                        subsample=0.67,\n",
        "                        verbose=0,\n",
        "                        thread_count=6,\n",
        "                        random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-enhLnbPyIt6"
      },
      "source": [
        "models = [lgbm, cb]\n",
        "model_names = [i.__class__.__name__ for i in models]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIujmOn_yIt6"
      },
      "source": [
        "es_models = ['LGBMClassifier',\n",
        "             'CatBoostClassifier']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptnWWC5ByIt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a23ffe-8e1c-44e0-d156-d109f8b2fe66"
      },
      "source": [
        "for m, n in zip(models, model_names):\n",
        "    \n",
        "    start_time = time()\n",
        "    if n in es_models:\n",
        "        m.fit(X_train_sub,\n",
        "              y_train_sub,\n",
        "              eval_set = [(X_valid, y_valid)],\n",
        "              early_stopping_rounds=15,\n",
        "              verbose=0)\n",
        "    else:\n",
        "        m.fit(X_train, y_train)\n",
        "    \n",
        "    run_time = time() - start_time\n",
        "    accuracy = np.mean(m.predict(X_test) == y_test)\n",
        "        \n",
        "    df_results.loc[n] = [accuracy, run_time]\n",
        "    \n",
        "    del m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsoMfK1dyIt_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ffba49ac-bc08-48ee-958c-ce1693a63fd4"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.917237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoostClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.017664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  run_time\n",
              "LGBMClassifier           0.0  0.917237\n",
              "CatBoostClassifier       0.0  2.017664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAoPBG4WyIuA"
      },
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJO5N2i8yIuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc4f76f-d7c2-408a-e2ea-5e2ddb2a7adc"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_lgbm, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [961  39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wBQ5TByIuA"
      },
      "source": [
        "y_pred_cb = cb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjEtLNQKyIuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fa58f0-da53-4ba6-c995-d18d25182939"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_cb, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [965 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PsK2T-H7DZY"
      },
      "source": [
        "### ZENILSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lGpednyItU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c12_fw4I7TAt"
      },
      "source": [
        "i_Seed = 19961108\n",
        "\n",
        "preditoras = X\n",
        "target = y\n",
        "df_testeTratado = X_submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oACaNC2F9yD6"
      },
      "source": [
        "df_testeTratado.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbmI06k3yItY"
      },
      "source": [
        "## Aqui, como passo intermediÃ¡rio, executei o modelo usando o dataframe default (getDataFrameDefault) e analisei a importÃ¢ncia das features:\n",
        "## entÃ£o fui modificando o dataframe excluindo as features menos importantes...\n",
        "## OBS: para utilizar, carregar antes a funÃ§Ã£o treina_testa\n",
        "'''\n",
        "df_default = otdf_Treino.getDataFrameDefault()\n",
        "preditoras = df_default.copy()\n",
        "preditoras.drop(columns=[\"Churn\",\"id\"],inplace=True)\n",
        "target = df_treinoTratado[\"Churn\"]\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0] #considerei todas as features que nÃ£o sÃ£o do tipo \"flutuante\" como categÃ³ricas\n",
        "print(f\"Qtde de features categÃ³ricas: {len(categorical_features_indices)}\")\n",
        "print(f\"Colunas preditoras: {preditoras.columns}\")\n",
        "\n",
        "acc = treina_testa(mostrarFI=True)\n",
        "print(f\"acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5oQMioHz93b"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mew6XsGRyItW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4bb2f9-06ad-4394-9e8e-5d5cc292b8ba"
      },
      "source": [
        "#considerei todas as features que nÃ£o sÃ£o do tipo \"flutuante\" como categÃ³ricas\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0]\n",
        "len(categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0JVbdH89w1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "75e5259a-2030-4858-83f1-ea56124d2eaf"
      },
      "source": [
        "acc = treina_testa(mostrarFI=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-d21779ef0020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-648fed880d09>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'bool' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEf7qd9yItW"
      },
      "source": [
        "ts=0.30\n",
        "it=300\n",
        "lr=0.03\n",
        "depth=5\n",
        "gerarArquivo=False\n",
        "mostrarFI=False\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg1ZO8CoyItX"
      },
      "source": [
        "catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oer3P4jcyItX"
      },
      "source": [
        "catb_tuned = catb.fit(X_treinamento, y_treinamento) # cat_features=categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITg22JTLyItY"
      },
      "source": [
        "y_pred = catb_tuned.predict(X_submit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS_5F2K4yItY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3dccaa-29d4-4911-a30f-26f6661740bd"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [963 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNshKeM8qKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11aa5ab0-d619-4186-d397-8385c720a5fb"
      },
      "source": [
        "categorical_features_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1y8ZaNQyItZ"
      },
      "source": [
        "def treina_testa(ts=0.30,it=300, lr=0.03, depth=5, gerarArquivo=False, mostrarFI=False):\n",
        "   X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)#, random_state = i_Seed)\n",
        "   catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)\n",
        "   catb_tuned = catb.fit(  X_treinamento, y_treinamento, cat_features=categorical_features_indices)\n",
        "   y_pred = catb_tuned.predict(X_submit)\n",
        "   acc_catb = round(accuracy_score(y_pred, y_teste) * 100, 2)\n",
        "   #print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\n",
        "   if (mostrarFI == True):\n",
        "      l_fi = list(zip(catb_tuned.feature_importances_,X_treinamento.columns))\n",
        "      print(l_fi)\n",
        "\n",
        "   if gerarArquivo == True: \n",
        "      df_id = df_test[[\"id\"]]\n",
        "      df_teste3 = df_testeTratado #.drop(columns=[\"id\"],axis=1)\n",
        "      resposta = catb_tuned.predict(df_teste3)\n",
        "      resposta_df = pd.DataFrame(resposta, columns=['target'])\n",
        "      resultado_submissao = pd.concat([df_id, resposta_df],axis=1)\n",
        "      resultado_submissao.head().T\n",
        "      filename = 'submissao_kaggle_catb_fs_ts0{}_it{}_lr{}_depth{}_sc{}.csv'.format(round(ts*100,0),it, lr, depth,str(int(acc_catb*100)))\n",
        "      resultado_submissao.to_csv(filename, index=False)   \n",
        "      print(filename)\n",
        "   return acc_catb   \n",
        "   #result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHlX8NFSBDwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f84da2ec-226a-455d-e82c-8d2d5a7fb96a"
      },
      "source": [
        "f'\"X_treinamento=\" : {X_treinamento.shape}, \"y_treinamento=\" : {y_treinamento.shape}, \"X_teste=\":{X_teste.shape},\"y_teste=\":{y_teste.shape},\"X_submit=\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento=\" : (7723, 70), \"y_treinamento=\" : (7723,), \"X_teste=\":(3310, 70),\"y_teste=\":(3310,),\"X_submit=\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlK6ScvayItZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "2de6fc56-250a-42ac-9318-5121166b6373"
      },
      "source": [
        "#l_ts = [0.22, 0.24, 0.25, 0.26, 0.28, 0.30, 0.32]\n",
        "#l_it =  [300, 400, 500], \n",
        "#l_lr = [0.02, 0.03, 0.04]\n",
        "#l_depth = [2, 3, 4, 5]\n",
        "l_ts, l_it, l_lr, l_depth = [0.26], [400], [0.02], [3]\n",
        "resultado = {}\n",
        "\n",
        "for vez in range(1,11):\n",
        "   resultado[vez] = {\"ts\":[], \"it\":[], \"lr\":[],\"depth\":[],\"score\":[]}\n",
        "   for ts in l_ts:\n",
        "       print(f'execuÃ§Ã£o {vez}/ts {ts}...')\n",
        "       for it in l_it:\n",
        "           for lr in l_lr:\n",
        "               for depth in l_depth:\n",
        "                  res = treina_testa(ts=ts, it=it, lr=lr, depth=depth,gerarArquivo=False, mostrarFI=False) #nÃ£o vai salvar o arquivo e nem mostrar as melhores features\n",
        "                  resultado[vez][\"ts\"].append(ts)\n",
        "                  resultado[vez][\"it\"].append(it)\n",
        "                  resultado[vez][\"lr\"].append(lr)\n",
        "                  resultado[vez][\"depth\"].append(depth)\n",
        "                  resultado[vez][\"score\"].append(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execuÃ§Ã£o 1/ts 0.26...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-c7cedf244408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgerarArquivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#nÃ£o vai salvar o arquivo e nem mostrar as melhores features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"it\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-cd249ff4f9ff>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 2869]"
          ]
        }
      ]
    }
  ]
}