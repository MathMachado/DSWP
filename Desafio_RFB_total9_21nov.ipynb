{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio_RFB.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1c144d3fa0740febc6f6b1b71f2d61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73af26aeda37421e9ec3e6fe4225dc5e",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_916c3d41ee614a359d0deabf4ee4f5c1"
          }
        },
        "73af26aeda37421e9ec3e6fe4225dc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "916c3d41ee614a359d0deabf4ee4f5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdbcbdc76dcb43018462e5f36435861a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_a24262f7ecc94602b971c1b691c5fbf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26aa0af112f04548b8ff70ea52b3aa78"
          }
        },
        "a24262f7ecc94602b971c1b691c5fbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26aa0af112f04548b8ff70ea52b3aa78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryssoga/DSWP/blob/master/Desafio_RFB_total9_21nov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOPOEiuuXb-"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0klE9on9bLm"
      },
      "source": [
        "url_total_9 = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Dataframes/total_9.csv'\n",
        "df_total = pd.read_csv(url_total_9)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7m_dYQrBdrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f73d241-38bd-460c-81be-8f7d11a7681a"
      },
      "source": [
        "df_total['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8513\n",
              "1    2520\n",
              "2    1000\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoSXzkV1BlfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7833a2-d9ab-493f-b231-1909c3aa4659"
      },
      "source": [
        "df_total[df_total['target'] == 2].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([11033, 11034, 11035, 11036, 11037, 11038, 11039, 11040, 11041,\n",
              "            11042,\n",
              "            ...\n",
              "            12023, 12024, 12025, 12026, 12027, 12028, 12029, 12030, 12031,\n",
              "            12032],\n",
              "           dtype='int64', length=1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg0y_ylqAweG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a92faef7-acb0-4df4-a912-1c20393fe47a"
      },
      "source": [
        "df_TRAIN = df_total[0:11033].copy()\n",
        "df_TEST = df_total[11033:].copy()\n",
        "f'\"df_TRAIN.shape:\":{df_TRAIN.shape}, \"df_TEST.shape:\": {df_TEST.shape}'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_TRAIN.shape:\":(11033, 80), \"df_TEST.shape:\": (1000, 80)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTbc03ziEdmE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52ce0c3a-5b1a-487c-93e1-e4471d2ed372"
      },
      "source": [
        "df_TEST.drop(['target'],axis=1,inplace=True)\n",
        "f'\"df_TEST.shape:\": {df_TEST.shape}'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_TEST.shape:\": (1000, 79)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omnNRKL5FRkP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a164ec9-9c02-47cb-f416-1576402321e7"
      },
      "source": [
        "df_train = df_TRAIN.copy()\n",
        "df_test = df_TEST.copy()\n",
        "\n",
        "df_train.set_index('id', inplace=True)\n",
        "df_test.set_index('id',inplace=True)\n",
        "\n",
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 79), \"df_test.shape:\": (1000, 78)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgi7suWiJs-1"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zf0yCY_0MIFw",
        "outputId": "baa6218b-0c53-4f7b-e048-e8854c804634"
      },
      "source": [
        "# criando dummies em df_train e df_test:\n",
        "\n",
        "df_train = pd.get_dummies(df_train, drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, drop_first=False)\n",
        "\n",
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 106), \"df_test.shape:\": (1000, 104)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp3lzZ3KMQYW"
      },
      "source": [
        "## PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F9_sJ10M9-G",
        "outputId": "3c6255cd-eb21-4c5d-f18e-98a3c2decad1"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.10.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.4.6)\n",
            "Requirement already satisfied: catboost>=0.23.2 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.24.3)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.1.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.18.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.0)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.2)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.12.1)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.8.4)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret) (7.5.1)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.9.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.1.2)\n",
            "Requirement already satisfied: imbalanced-learn>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.7.0)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.14.0)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.23.2)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.11.0)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.2.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from kmodes>=0.10.1->pycaret) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: numba!=0.47,>=0.46 in /usr/local/lib/python3.6/dist-packages (from umap-learn->pycaret) (0.48.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (50.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (4.53.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.8.0)\n",
            "Requirement already satisfied: alembic<=1.4.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.4.1)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.14.1)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.1.11)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.18.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.12.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (4.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.13)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.20)\n",
            "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (20.0.4)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.2.4)\n",
            "Requirement already satisfied: azure-storage-blob in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (12.6.0)\n",
            "Requirement already satisfied: suod in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.0.4)\n",
            "Requirement already satisfied: combo in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.1.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (5.0.8)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.12)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.2)\n",
            "Requirement already satisfied: phik>=0.9.10 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.10.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.4.2)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.4.0)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.0.6)\n",
            "Requirement already satisfied: visions[type_image_path]==0.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (20.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (3.6.4)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (1.15)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.35.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.2->pycaret) (2.1.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret) (7.0.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (3.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba!=0.47,>=0.46->umap-learn->pycaret) (0.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (2.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.1.3)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.0.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.7)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython>=2.1.0->mlflow->pycaret) (4.0.5)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.8.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker>=4.0.0->mlflow->pycaret) (0.57.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob->mlflow->pycaret) (3.2.1)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob->mlflow->pycaret) (1.9.0)\n",
            "Requirement already satisfied: msrest>=0.6.10 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob->mlflow->pycaret) (0.6.19)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.6.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (2.5)\n",
            "Requirement already satisfied: imagehash; extra == \"type_image_path\" in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (4.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.6.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (8.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.4.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret) (3.0.4)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (1.14.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (0.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (19.0.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (3.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.2.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAjtbymSkJ2"
      },
      "source": [
        "# Carregar bibliotecas\n",
        "import numpy as np                                    # Numpy\n",
        "import pandas as pd                                   # Pandas\n",
        "from sklearn.model_selection import train_test_split  # Scikit separar treino/teste\n",
        "import pycaret\n",
        "from pycaret.classification import *                                        # Pycaret\n",
        "from pycaret.regression import *                      # Pycaret para RegressÃ£o\n",
        "from pycaret.utils import enable_colab                # Para executar grÃ¡ficos no Colab\n",
        "from pycaret import classification as pyclass \n",
        "from pycaret import regression as pyreg"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a1c144d3fa0740febc6f6b1b71f2d61d",
            "73af26aeda37421e9ec3e6fe4225dc5e",
            "916c3d41ee614a359d0deabf4ee4f5c1",
            "fdbcbdc76dcb43018462e5f36435861a",
            "a24262f7ecc94602b971c1b691c5fbf8",
            "26aa0af112f04548b8ff70ea52b3aa78"
          ]
        },
        "id": "Khs3DL5jS6s-",
        "outputId": "cd489162-40d8-432e-e2ba-f4718a6b9e70"
      },
      "source": [
        "model = pyclass.setup(data = df_train,      \n",
        "                      target = 'target',     \n",
        "                      train_size = 0.7,\n",
        "                      fix_imbalance = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>7118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>0: 0, 1: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(11033, 106)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(7723, 105)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(3310, 105)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>7f2d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id              7118\n",
              "1                                   Target            target\n",
              "2                              Target Type            Binary\n",
              "3                            Label Encoded        0: 0, 1: 1\n",
              "4                            Original Data      (11033, 106)\n",
              "5                           Missing Values             False\n",
              "6                         Numeric Features                89\n",
              "7                     Categorical Features                16\n",
              "8                         Ordinal Features             False\n",
              "9                High Cardinality Features             False\n",
              "10                 High Cardinality Method              None\n",
              "11                   Transformed Train Set       (7723, 105)\n",
              "12                    Transformed Test Set       (3310, 105)\n",
              "13                      Shuffle Train-Test              True\n",
              "14                     Stratify Train-Test             False\n",
              "15                          Fold Generator   StratifiedKFold\n",
              "16                             Fold Number                10\n",
              "17                                CPU Jobs                -1\n",
              "18                                 Use GPU             False\n",
              "19                          Log Experiment             False\n",
              "20                         Experiment Name  clf-default-name\n",
              "21                                     USI              7f2d\n",
              "22                         Imputation Type            simple\n",
              "23          Iterative Imputation Iteration              None\n",
              "24                         Numeric Imputer              mean\n",
              "25      Iterative Imputation Numeric Model              None\n",
              "26                     Categorical Imputer          constant\n",
              "27  Iterative Imputation Categorical Model              None\n",
              "28           Unknown Categoricals Handling    least_frequent\n",
              "29                               Normalize             False\n",
              "30                        Normalize Method              None\n",
              "31                          Transformation             False\n",
              "32                   Transformation Method              None\n",
              "33                                     PCA             False\n",
              "34                              PCA Method              None\n",
              "35                          PCA Components              None\n",
              "36                     Ignore Low Variance             False\n",
              "37                     Combine Rare Levels             False\n",
              "38                    Rare Level Threshold              None\n",
              "39                         Numeric Binning             False\n",
              "40                         Remove Outliers             False\n",
              "41                      Outliers Threshold              None\n",
              "42                Remove Multicollinearity             False\n",
              "43             Multicollinearity Threshold              None\n",
              "44                              Clustering             False\n",
              "45                    Clustering Iteration              None\n",
              "46                     Polynomial Features             False\n",
              "47                       Polynomial Degree              None\n",
              "48                    Trignometry Features             False\n",
              "49                    Polynomial Threshold              None\n",
              "50                          Group Features             False\n",
              "51                       Feature Selection             False\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                           Fix Imbalance              True\n",
              "57                    Fix Imbalance Method             SMOTE"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "occvZWxxTMEg"
      },
      "source": [
        "_# Treinar modelos\n",
        "best = pyclass.compare_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "11ec3663863c40109b937d0bb245cc28",
            "f5f5b667a20b4a76aa7ab3d8c5c69ac8",
            "885dfdfc70464b53bdff86833b79103a"
          ]
        },
        "id": "wzCG8d-in2ny",
        "outputId": "a14847be-511b-4b5a-ff36-4285b456c591"
      },
      "source": [
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/regression/#create-model\n",
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/classification/#create-model\n",
        "cb = pyclass.create_model('catboost')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7738</td>\n",
              "      <td>0.6981</td>\n",
              "      <td>0.1369</td>\n",
              "      <td>0.5227</td>\n",
              "      <td>0.2170</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.1766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7793</td>\n",
              "      <td>0.7175</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.5833</td>\n",
              "      <td>0.2059</td>\n",
              "      <td>0.1361</td>\n",
              "      <td>0.1916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7616</td>\n",
              "      <td>0.7150</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>0.4186</td>\n",
              "      <td>0.1706</td>\n",
              "      <td>0.0853</td>\n",
              "      <td>0.1127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7698</td>\n",
              "      <td>0.6827</td>\n",
              "      <td>0.1420</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.2212</td>\n",
              "      <td>0.1329</td>\n",
              "      <td>0.1695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7602</td>\n",
              "      <td>0.6698</td>\n",
              "      <td>0.1065</td>\n",
              "      <td>0.4186</td>\n",
              "      <td>0.1698</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.1116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7916</td>\n",
              "      <td>0.7463</td>\n",
              "      <td>0.1716</td>\n",
              "      <td>0.6905</td>\n",
              "      <td>0.2749</td>\n",
              "      <td>0.2017</td>\n",
              "      <td>0.2693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7817</td>\n",
              "      <td>0.7221</td>\n",
              "      <td>0.1131</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.1919</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.1986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7708</td>\n",
              "      <td>0.7371</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.1193</td>\n",
              "      <td>0.1588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7735</td>\n",
              "      <td>0.7135</td>\n",
              "      <td>0.1488</td>\n",
              "      <td>0.5208</td>\n",
              "      <td>0.2315</td>\n",
              "      <td>0.1443</td>\n",
              "      <td>0.1837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7722</td>\n",
              "      <td>0.6854</td>\n",
              "      <td>0.1190</td>\n",
              "      <td>0.5128</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7734</td>\n",
              "      <td>0.7088</td>\n",
              "      <td>0.1295</td>\n",
              "      <td>0.5301</td>\n",
              "      <td>0.2076</td>\n",
              "      <td>0.1287</td>\n",
              "      <td>0.1732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0088</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0814</td>\n",
              "      <td>0.0295</td>\n",
              "      <td>0.0313</td>\n",
              "      <td>0.0427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7738  0.6981  0.1369  0.5227  0.2170  0.1348  0.1766\n",
              "1       0.7793  0.7175  0.1250  0.5833  0.2059  0.1361  0.1916\n",
              "2       0.7616  0.7150  0.1071  0.4186  0.1706  0.0853  0.1127\n",
              "3       0.7698  0.6827  0.1420  0.5000  0.2212  0.1329  0.1695\n",
              "4       0.7602  0.6698  0.1065  0.4186  0.1698  0.0843  0.1116\n",
              "5       0.7916  0.7463  0.1716  0.6905  0.2749  0.2017  0.2693\n",
              "6       0.7817  0.7221  0.1131  0.6333  0.1919  0.1316  0.1986\n",
              "7       0.7708  0.7371  0.1250  0.5000  0.2000  0.1193  0.1588\n",
              "8       0.7735  0.7135  0.1488  0.5208  0.2315  0.1443  0.1837\n",
              "9       0.7722  0.6854  0.1190  0.5128  0.1932  0.1170  0.1600\n",
              "Mean    0.7734  0.7088  0.1295  0.5301  0.2076  0.1287  0.1732\n",
              "SD      0.0088  0.0232  0.0195  0.0814  0.0295  0.0313  0.0427"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "3vrIvLxRokBF",
        "outputId": "cf56fa9e-dda6-4fd4-b1b2-44abad9b2191"
      },
      "source": [
        "# Verificar importÃ¢ncia das variÃ¡veis\n",
        "pyclass.plot_model(lda, 'feature')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns0RTh9JnXXp"
      },
      "source": [
        "holdout = pyclass.predict_model(lda, data = df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQJrjf7zT6YN",
        "outputId": "00dbca40-e274-4f87-ef8e-3547d09ef6b0"
      },
      "source": [
        "holdout['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    907\n",
              "True      93\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTiFMeYqUCqS"
      },
      "source": [
        "# df_pycaret['NOME DO ALGORITMO'] = holdout['Label']\n",
        "df_pycaret['lda_setup'] = holdout['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1lVo4rCKVc0"
      },
      "source": [
        "df_pycaret['NOME DO ALGORITMO'] = holdout['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dY0kbA8Tp2D"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(holdout.index, holdout['Label']), columns=['id','Churn'])\n",
        "df_submit.to_csv('Churn_pycaret_catboost_setup.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHhDjV0cILKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c27fde-a966-459b-81f8-aa5066b70ce4"
      },
      "source": [
        "df_submit['Churn'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    844\n",
              "True     156\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-7gQgxOXUMk"
      },
      "source": [
        "### TUNED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "7aa9be73692247b2a271a24018b7bc6e",
            "becd48e0b3a44ce1b7914052e2a98573",
            "a85eebb67bbd4a51bca47cde6cac8177"
          ]
        },
        "id": "BT3QPZVeIa6-",
        "outputId": "e843f9e2-9cf4-4d84-ab54-abc81a18d0ab"
      },
      "source": [
        "tuned = pyclass.tune_model(lda, optimize = 'AUC')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5695</td>\n",
              "      <td>0.6025</td>\n",
              "      <td>0.5774</td>\n",
              "      <td>0.2836</td>\n",
              "      <td>0.3804</td>\n",
              "      <td>0.1059</td>\n",
              "      <td>0.1217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5586</td>\n",
              "      <td>0.5655</td>\n",
              "      <td>0.5119</td>\n",
              "      <td>0.2622</td>\n",
              "      <td>0.3468</td>\n",
              "      <td>0.0632</td>\n",
              "      <td>0.0713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5518</td>\n",
              "      <td>0.5634</td>\n",
              "      <td>0.5238</td>\n",
              "      <td>0.2611</td>\n",
              "      <td>0.3485</td>\n",
              "      <td>0.0620</td>\n",
              "      <td>0.0707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5627</td>\n",
              "      <td>0.5860</td>\n",
              "      <td>0.6154</td>\n",
              "      <td>0.2889</td>\n",
              "      <td>0.3932</td>\n",
              "      <td>0.1162</td>\n",
              "      <td>0.1367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5804</td>\n",
              "      <td>0.6071</td>\n",
              "      <td>0.5740</td>\n",
              "      <td>0.2913</td>\n",
              "      <td>0.3865</td>\n",
              "      <td>0.1166</td>\n",
              "      <td>0.1321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5422</td>\n",
              "      <td>0.5670</td>\n",
              "      <td>0.5740</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.3660</td>\n",
              "      <td>0.0763</td>\n",
              "      <td>0.0899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.5771</td>\n",
              "      <td>0.5864</td>\n",
              "      <td>0.5417</td>\n",
              "      <td>0.2809</td>\n",
              "      <td>0.3699</td>\n",
              "      <td>0.0975</td>\n",
              "      <td>0.1094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.5607</td>\n",
              "      <td>0.5874</td>\n",
              "      <td>0.5655</td>\n",
              "      <td>0.2762</td>\n",
              "      <td>0.3711</td>\n",
              "      <td>0.0912</td>\n",
              "      <td>0.1051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.5553</td>\n",
              "      <td>0.5780</td>\n",
              "      <td>0.5833</td>\n",
              "      <td>0.2768</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>0.0938</td>\n",
              "      <td>0.1095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.5662</td>\n",
              "      <td>0.5975</td>\n",
              "      <td>0.6429</td>\n",
              "      <td>0.2951</td>\n",
              "      <td>0.4045</td>\n",
              "      <td>0.1317</td>\n",
              "      <td>0.1565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.5624</td>\n",
              "      <td>0.5841</td>\n",
              "      <td>0.5710</td>\n",
              "      <td>0.2785</td>\n",
              "      <td>0.3742</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.1103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0109</td>\n",
              "      <td>0.0147</td>\n",
              "      <td>0.0374</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0220</td>\n",
              "      <td>0.0264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.5695  0.6025  0.5774  0.2836  0.3804  0.1059  0.1217\n",
              "1       0.5586  0.5655  0.5119  0.2622  0.3468  0.0632  0.0713\n",
              "2       0.5518  0.5634  0.5238  0.2611  0.3485  0.0620  0.0707\n",
              "3       0.5627  0.5860  0.6154  0.2889  0.3932  0.1162  0.1367\n",
              "4       0.5804  0.6071  0.5740  0.2913  0.3865  0.1166  0.1321\n",
              "5       0.5422  0.5670  0.5740  0.2687  0.3660  0.0763  0.0899\n",
              "6       0.5771  0.5864  0.5417  0.2809  0.3699  0.0975  0.1094\n",
              "7       0.5607  0.5874  0.5655  0.2762  0.3711  0.0912  0.1051\n",
              "8       0.5553  0.5780  0.5833  0.2768  0.3755  0.0938  0.1095\n",
              "9       0.5662  0.5975  0.6429  0.2951  0.4045  0.1317  0.1565\n",
              "Mean    0.5624  0.5841  0.5710  0.2785  0.3742  0.0954  0.1103\n",
              "SD      0.0109  0.0147  0.0374  0.0112  0.0172  0.0220  0.0264"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "hza1TggsKkRB",
        "outputId": "3d3eb459-c5a7-42a3-89e7-9becd30b906a"
      },
      "source": [
        "# Verificar importÃ¢ncia das variÃ¡veis\n",
        "pyclass.plot_model(tuned, 'feature')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Nm4pjwKL0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd39e92a-84aa-4506-d9be-ea17629fbc74"
      },
      "source": [
        "tuned_holdout = pyclass.predict_model(tuned, data = df_test)\n",
        "tuned_holdout['Label'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     513\n",
              "False    487\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQMbKRLjN4wM"
      },
      "source": [
        "df_pycaret['lda_setup_tuned_AUC'] = holdout['Label']\n",
        "df_pycaret.to_csv('df_pycaret_Label_modelos.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQwbdM_iL7b-"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(tuned_holdout.index, tuned_holdout['Label']), columns=['id','target'])\n",
        "df_submit.to_csv('Churn_pycaret_catboost_setup_tuned_AUC.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh22ZcfDHBTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4674478c-0152-4c08-b803-31cf8332cb1d"
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    847\n",
              "True     153\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrFn0j2jHBKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70b87a1-0e64-4f3b-8b60-db7abe8daf3a"
      },
      "source": [
        "df_pycaret['catboost_setup_tuned_F1'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    844\n",
              "True     156\n",
              "Name: catboost_setup_tuned_F1, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UXpoFdtP9kv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR0PHYn1XDsQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caXHz7EJXD1w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXjbsi1oXno1"
      },
      "source": [
        "### SIMULAR REGRESSÃƒO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "9360bc3f86c1477da3ff30dba8ba6a3a",
            "9e6212d909c2432ab15d469e9bf5bf90",
            "6a003050cc434f5596812a04fdc1c510"
          ]
        },
        "id": "tmJA8ZH7P-Lc",
        "outputId": "c02eef9e-eee4-4953-ef41-012f8a64dda7"
      },
      "source": [
        "_# Treinar modelos\n",
        "best_reg = pyreg.compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7755</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1206</td>\n",
              "      <td>0.5493</td>\n",
              "      <td>0.1971</td>\n",
              "      <td>0.1252</td>\n",
              "      <td>0.1746</td>\n",
              "      <td>0.082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.7734</td>\n",
              "      <td>0.7088</td>\n",
              "      <td>0.1295</td>\n",
              "      <td>0.5301</td>\n",
              "      <td>0.2076</td>\n",
              "      <td>0.1287</td>\n",
              "      <td>0.1732</td>\n",
              "      <td>0.179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Classifier</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>0.7383</td>\n",
              "      <td>0.2721</td>\n",
              "      <td>0.4862</td>\n",
              "      <td>0.3482</td>\n",
              "      <td>0.2193</td>\n",
              "      <td>0.2335</td>\n",
              "      <td>19.063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.7638</td>\n",
              "      <td>0.7403</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.4746</td>\n",
              "      <td>0.3263</td>\n",
              "      <td>0.1995</td>\n",
              "      <td>0.2151</td>\n",
              "      <td>0.602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.7612</td>\n",
              "      <td>0.7203</td>\n",
              "      <td>0.2252</td>\n",
              "      <td>0.4626</td>\n",
              "      <td>0.3017</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>0.1953</td>\n",
              "      <td>2.243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.7612</td>\n",
              "      <td>0.7125</td>\n",
              "      <td>0.2175</td>\n",
              "      <td>0.4615</td>\n",
              "      <td>0.2938</td>\n",
              "      <td>0.1721</td>\n",
              "      <td>0.1906</td>\n",
              "      <td>1.465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.7608</td>\n",
              "      <td>0.7367</td>\n",
              "      <td>0.2953</td>\n",
              "      <td>0.4701</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.2235</td>\n",
              "      <td>0.2335</td>\n",
              "      <td>4.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.7587</td>\n",
              "      <td>0.7240</td>\n",
              "      <td>0.2983</td>\n",
              "      <td>0.4597</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.2211</td>\n",
              "      <td>0.2291</td>\n",
              "      <td>3.837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.7463</td>\n",
              "      <td>0.7255</td>\n",
              "      <td>0.3369</td>\n",
              "      <td>0.4339</td>\n",
              "      <td>0.3779</td>\n",
              "      <td>0.2221</td>\n",
              "      <td>0.2256</td>\n",
              "      <td>1.138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.7146</td>\n",
              "      <td>0.6925</td>\n",
              "      <td>0.3689</td>\n",
              "      <td>0.3909</td>\n",
              "      <td>0.3540</td>\n",
              "      <td>0.1827</td>\n",
              "      <td>0.1950</td>\n",
              "      <td>0.712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.6771</td>\n",
              "      <td>0.5712</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>0.3238</td>\n",
              "      <td>0.3473</td>\n",
              "      <td>0.1345</td>\n",
              "      <td>0.1353</td>\n",
              "      <td>0.230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.6423</td>\n",
              "      <td>0.6630</td>\n",
              "      <td>0.5514</td>\n",
              "      <td>0.3322</td>\n",
              "      <td>0.4144</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.1913</td>\n",
              "      <td>0.085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.5576</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3958</td>\n",
              "      <td>0.3418</td>\n",
              "      <td>0.1524</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.0190</td>\n",
              "      <td>0.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.5522</td>\n",
              "      <td>0.5038</td>\n",
              "      <td>0.4159</td>\n",
              "      <td>0.2331</td>\n",
              "      <td>0.2987</td>\n",
              "      <td>0.0068</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.4870</td>\n",
              "      <td>0.6132</td>\n",
              "      <td>0.7393</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.4014</td>\n",
              "      <td>0.1049</td>\n",
              "      <td>0.1272</td>\n",
              "      <td>0.113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "ridge                    Ridge Classifier    0.7755  0.0000  0.1206  0.5493   \n",
              "lda          Linear Discriminant Analysis    0.7734  0.7088  0.1295  0.5301   \n",
              "catboost              CatBoost Classifier    0.7662  0.7383  0.2721  0.4862   \n",
              "lightgbm  Light Gradient Boosting Machine    0.7638  0.7403  0.2496  0.4746   \n",
              "rf               Random Forest Classifier    0.7612  0.7203  0.2252  0.4626   \n",
              "et                 Extra Trees Classifier    0.7612  0.7125  0.2175  0.4615   \n",
              "gbc          Gradient Boosting Classifier    0.7608  0.7367  0.2953  0.4701   \n",
              "xgboost         Extreme Gradient Boosting    0.7587  0.7240  0.2983  0.4597   \n",
              "ada                  Ada Boost Classifier    0.7463  0.7255  0.3369  0.4339   \n",
              "lr                    Logistic Regression    0.7146  0.6925  0.3689  0.3909   \n",
              "dt               Decision Tree Classifier    0.6771  0.5712  0.3755  0.3238   \n",
              "nb                            Naive Bayes    0.6423  0.6630  0.5514  0.3322   \n",
              "svm                   SVM - Linear Kernel    0.5576  0.0000  0.3958  0.3418   \n",
              "knn                K Neighbors Classifier    0.5522  0.5038  0.4159  0.2331   \n",
              "qda       Quadratic Discriminant Analysis    0.4870  0.6132  0.7393  0.2814   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "ridge     0.1971  0.1252  0.1746     0.082  \n",
              "lda       0.2076  0.1287  0.1732     0.179  \n",
              "catboost  0.3482  0.2193  0.2335    19.063  \n",
              "lightgbm  0.3263  0.1995  0.2151     0.602  \n",
              "rf        0.3017  0.1778  0.1953     2.243  \n",
              "et        0.2938  0.1721  0.1906     1.465  \n",
              "gbc       0.3612  0.2235  0.2335     4.700  \n",
              "xgboost   0.3613  0.2211  0.2291     3.837  \n",
              "ada       0.3779  0.2221  0.2256     1.138  \n",
              "lr        0.3540  0.1827  0.1950     0.712  \n",
              "dt        0.3473  0.1345  0.1353     0.230  \n",
              "nb        0.4144  0.1794  0.1913     0.085  \n",
              "svm       0.1524  0.0025  0.0190     0.468  \n",
              "knn       0.2987  0.0068  0.0075     0.250  \n",
              "qda       0.4014  0.1049  0.1272     0.113  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH09bBhcM80y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOaLYAnxFSDo"
      },
      "source": [
        "### PULAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypwM33UBpCw"
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_test.csv'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oDXHvVPustij",
        "outputId": "ec4b7355-4299-4add-87e7-6c1fa1c4a2f1"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}, \"df_total.shape:\": {df_total.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 63), \"df_test.shape:\": (1000, 62), \"df_total.shape:\": (12033, 80)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj2DFFRNt9uT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdc2ca6-c935-44f8-e614-a1018a61ed59"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11033 entries, 0 to 11032\n",
            "Data columns (total 63 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      11033 non-null  int64  \n",
            " 1   cnae2   11033 non-null  int64  \n",
            " 2   rf2     11033 non-null  object \n",
            " 3   md1     11033 non-null  float64\n",
            " 4   md2     11033 non-null  float64\n",
            " 5   md3     11033 non-null  float64\n",
            " 6   md4     11033 non-null  float64\n",
            " 7   md5     11033 non-null  float64\n",
            " 8   md6     11033 non-null  float64\n",
            " 9   md7     11033 non-null  float64\n",
            " 10  md8     11033 non-null  float64\n",
            " 11  md9     11033 non-null  float64\n",
            " 12  md10    11033 non-null  float64\n",
            " 13  md11    11033 non-null  float64\n",
            " 14  md12    11033 non-null  float64\n",
            " 15  mc1     10431 non-null  float64\n",
            " 16  mc2     10431 non-null  float64\n",
            " 17  mc3     10431 non-null  float64\n",
            " 18  mc4     11033 non-null  float64\n",
            " 19  ind01   10999 non-null  float64\n",
            " 20  ind02   10999 non-null  float64\n",
            " 21  ind03   10999 non-null  float64\n",
            " 22  ind04   10999 non-null  float64\n",
            " 23  ind05   10999 non-null  float64\n",
            " 24  ind06   10999 non-null  float64\n",
            " 25  ind07   10999 non-null  float64\n",
            " 26  ind08   10999 non-null  float64\n",
            " 27  ind09   10999 non-null  float64\n",
            " 28  ind10   10999 non-null  float64\n",
            " 29  ind11   10999 non-null  float64\n",
            " 30  ind12   10999 non-null  float64\n",
            " 31  ind13   10999 non-null  float64\n",
            " 32  ind14   10999 non-null  float64\n",
            " 33  ind15   10999 non-null  float64\n",
            " 34  ind16   10999 non-null  float64\n",
            " 35  ind17   10999 non-null  float64\n",
            " 36  ind18   10999 non-null  float64\n",
            " 37  ind19   10999 non-null  float64\n",
            " 38  ind20   10999 non-null  float64\n",
            " 39  ind21   10434 non-null  float64\n",
            " 40  ind22   10434 non-null  float64\n",
            " 41  ind23   10434 non-null  float64\n",
            " 42  ind24   10434 non-null  float64\n",
            " 43  ind25   10434 non-null  float64\n",
            " 44  ind26   10434 non-null  float64\n",
            " 45  ind27   10434 non-null  float64\n",
            " 46  ind28   10999 non-null  float64\n",
            " 47  ind29   10999 non-null  float64\n",
            " 48  ind30   10999 non-null  float64\n",
            " 49  ind31   10999 non-null  float64\n",
            " 50  ind32   10999 non-null  float64\n",
            " 51  ind33   10999 non-null  float64\n",
            " 52  ind34   10999 non-null  float64\n",
            " 53  ind35   10999 non-null  float64\n",
            " 54  ind36   10999 non-null  float64\n",
            " 55  ind37   10999 non-null  float64\n",
            " 56  ind38   10434 non-null  float64\n",
            " 57  ind39   10434 non-null  float64\n",
            " 58  ind40   10999 non-null  float64\n",
            " 59  ind41   10999 non-null  float64\n",
            " 60  ind42   10434 non-null  float64\n",
            " 61  ind43   10434 non-null  float64\n",
            " 62  target  11033 non-null  bool   \n",
            "dtypes: bool(1), float64(59), int64(2), object(1)\n",
            "memory usage: 5.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNVOd-U9uzXe",
        "outputId": "83a7dc81-5bef-454b-c91e-60ae74288ff5"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'cnae2', 'rf2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7',\n",
              "       'md8', 'md9', 'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4',\n",
              "       'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24',\n",
              "       'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32',\n",
              "       'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
              "       'ind41', 'ind42', 'ind43', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "mgT2KGJBt9ub",
        "outputId": "eea02333-d133-4a95-f54e-01d19e50b9e3"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6007.300462</td>\n",
              "      <td>53.105774</td>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106722</td>\n",
              "      <td>0.157427</td>\n",
              "      <td>0.346646</td>\n",
              "      <td>0.364934</td>\n",
              "      <td>0.378858</td>\n",
              "      <td>0.397906</td>\n",
              "      <td>0.305112</td>\n",
              "      <td>0.355596</td>\n",
              "      <td>0.007454</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.141280</td>\n",
              "      <td>0.170552</td>\n",
              "      <td>0.034556</td>\n",
              "      <td>0.019556</td>\n",
              "      <td>0.003789</td>\n",
              "      <td>0.014774</td>\n",
              "      <td>0.004045</td>\n",
              "      <td>0.694791</td>\n",
              "      <td>0.700189</td>\n",
              "      <td>0.544750</td>\n",
              "      <td>0.538172</td>\n",
              "      <td>0.339573</td>\n",
              "      <td>0.333567</td>\n",
              "      <td>0.099865</td>\n",
              "      <td>0.570295</td>\n",
              "      <td>0.550792</td>\n",
              "      <td>0.005119</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.331121</td>\n",
              "      <td>0.367397</td>\n",
              "      <td>0.999182</td>\n",
              "      <td>0.489044</td>\n",
              "      <td>0.910992</td>\n",
              "      <td>0.729703</td>\n",
              "      <td>0.659605</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>0.134177</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.170692</td>\n",
              "      <td>0.090905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3470.840481</td>\n",
              "      <td>19.885298</td>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305922</td>\n",
              "      <td>0.315114</td>\n",
              "      <td>0.470182</td>\n",
              "      <td>0.451587</td>\n",
              "      <td>0.449015</td>\n",
              "      <td>0.473002</td>\n",
              "      <td>0.430549</td>\n",
              "      <td>0.440732</td>\n",
              "      <td>0.069064</td>\n",
              "      <td>0.031814</td>\n",
              "      <td>0.029262</td>\n",
              "      <td>0.312289</td>\n",
              "      <td>0.322844</td>\n",
              "      <td>0.161135</td>\n",
              "      <td>0.129848</td>\n",
              "      <td>0.059799</td>\n",
              "      <td>0.118014</td>\n",
              "      <td>0.062567</td>\n",
              "      <td>0.452090</td>\n",
              "      <td>0.450725</td>\n",
              "      <td>0.455767</td>\n",
              "      <td>0.457155</td>\n",
              "      <td>0.433901</td>\n",
              "      <td>0.434164</td>\n",
              "      <td>0.221941</td>\n",
              "      <td>0.425365</td>\n",
              "      <td>0.412976</td>\n",
              "      <td>0.060052</td>\n",
              "      <td>0.013340</td>\n",
              "      <td>0.018207</td>\n",
              "      <td>0.470638</td>\n",
              "      <td>0.482118</td>\n",
              "      <td>0.028595</td>\n",
              "      <td>0.499903</td>\n",
              "      <td>0.284768</td>\n",
              "      <td>0.444134</td>\n",
              "      <td>0.473863</td>\n",
              "      <td>0.071093</td>\n",
              "      <td>0.340858</td>\n",
              "      <td>0.016514</td>\n",
              "      <td>0.009535</td>\n",
              "      <td>0.376258</td>\n",
              "      <td>0.206764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3018.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6016.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9003.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862600</td>\n",
              "      <td>0.932700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id         cnae2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  10434.000000  10434.000000\n",
              "mean    6007.300462     53.105774  ...      0.170692      0.090905\n",
              "std     3470.840481     19.885298  ...      0.376258      0.206764\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%     3018.000000     42.000000  ...      0.000000      0.000000\n",
              "50%     6016.000000     47.000000  ...      0.000000      0.000000\n",
              "75%     9003.000000     69.000000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7U16Y6SQ4Zs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "1bfaa59c-c8b3-44d4-b470-9f221cdd5cdf"
      },
      "source": [
        "l_train_unique = []\n",
        "for i in df_train.columns:\n",
        "  l_train_unique.append(len(df_train[i].unique()))\n",
        "  #print(\"coluna:\", i, \" - len(df_train[i].unique()):\", len(df_train[i].unique()))\n",
        "\n",
        "df_train_unique = pd.DataFrame(zip(df_train.columns,l_train_unique))\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>11033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cnae2</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rf2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>md1</td>\n",
              "      <td>8829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>md2</td>\n",
              "      <td>10968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>ind40</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>ind41</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>ind42</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>ind43</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>target</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0      1\n",
              "0       id  11033\n",
              "1    cnae2     80\n",
              "2      rf2     10\n",
              "3      md1   8829\n",
              "4      md2  10968\n",
              "..     ...    ...\n",
              "58   ind40      3\n",
              "59   ind41      3\n",
              "60   ind42      3\n",
              "61   ind43      4\n",
              "62  target      2\n",
              "\n",
              "[63 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2JdxJRJShUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "f24734e0-41ae-4153-c402-dbfef6a396a7"
      },
      "source": [
        "df_train_unique.rename(columns={0:'coluna',1:'qtde_unique'})\n",
        "df_train_unique = df_train_unique.set_index(0).T\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11033</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>8829</td>\n",
              "      <td>10968</td>\n",
              "      <td>10967</td>\n",
              "      <td>8168</td>\n",
              "      <td>5612</td>\n",
              "      <td>379</td>\n",
              "      <td>10970</td>\n",
              "      <td>10968</td>\n",
              "      <td>8282</td>\n",
              "      <td>5777</td>\n",
              "      <td>340</td>\n",
              "      <td>10967</td>\n",
              "      <td>9925</td>\n",
              "      <td>1484</td>\n",
              "      <td>8157</td>\n",
              "      <td>10451</td>\n",
              "      <td>14</td>\n",
              "      <td>1417</td>\n",
              "      <td>194</td>\n",
              "      <td>14</td>\n",
              "      <td>765</td>\n",
              "      <td>227</td>\n",
              "      <td>2101</td>\n",
              "      <td>2522</td>\n",
              "      <td>331</td>\n",
              "      <td>45</td>\n",
              "      <td>22</td>\n",
              "      <td>1554</td>\n",
              "      <td>2503</td>\n",
              "      <td>830</td>\n",
              "      <td>77</td>\n",
              "      <td>24</td>\n",
              "      <td>45</td>\n",
              "      <td>13</td>\n",
              "      <td>488</td>\n",
              "      <td>429</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>748</td>\n",
              "      <td>159</td>\n",
              "      <td>164</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0     id  cnae2  rf2   md1    md2  ...  ind40  ind41  ind42  ind43  target\n",
              "1  11033     80   10  8829  10968  ...      3      3      3      4       2\n",
              "\n",
              "[1 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yll7hKsUxWUK",
        "outputId": "22b004c4-e69a-4b96-b4ac-b14d83bb0602"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpnm_zhckXD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0293f89-1ee1-450d-cbf5-f1d686cfaf06"
      },
      "source": [
        "df_nan = df_train.isna().sum()\n",
        "df_nan[df_nan.values>0].sort_values()\n",
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy8hCEistGiR",
        "outputId": "f532aa00-480d-4eb9-e0d1-9096d0858f5b"
      },
      "source": [
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIaxV70rhhE-",
        "outputId": "f7e2eced-6a2d-4ec6-8ce2-3cbd338cfeac"
      },
      "source": [
        "df_nan[df_nan.values==34].index   \n",
        "\n",
        "# 32 colunas/variÃ¡veis que possuem 34 NaN cada\n",
        "#'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "#'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "#'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "#'ind40', 'ind41']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind28', 'ind29', 'ind30', 'ind31',\n",
              "       'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind40', 'ind41'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ERGm38u0oN",
        "outputId": "4f72eb49-82b0-4638-970d-04453d1c448d"
      },
      "source": [
        "len(df_nan[df_nan.values==34].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49eQZdrEpex6",
        "outputId": "eab85b83-a8e8-415d-e8b3-a23864d6ff33"
      },
      "source": [
        "df_nan[df_nan.values==599].index    \n",
        "\n",
        "# 11 colunas/variÃ¡veis que possuem 599 NaN cada:\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "# 'ind38', 'ind39',\n",
        "# 'ind42', 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind38',\n",
              "       'ind39', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o593PHygvLJ8",
        "outputId": "0e4aa74f-9572-4e25-9d89-5aa08cc581b1"
      },
      "source": [
        "len(df_nan[df_nan.values==599].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5mETHrgpe_I",
        "outputId": "4b37dbdb-ef2f-4d98-cfd1-534af3742742"
      },
      "source": [
        "df_nan[df_nan.values==602].index    \n",
        "\n",
        "# 3 colunas/variÃ¡veis que possuem 602 NaN cada\n",
        "# ['mc1', 'mc2', 'mc3']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHecZd8jfuGi",
        "outputId": "722fece4-a4fa-49e2-a0e8-cb209f74ac2d"
      },
      "source": [
        "linhas_602nan = df_train['mc1'][df_train['mc1'].isna()].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   26,    27,    32,    34,    47,    64,    76,    88,   100,\n",
              "              121,\n",
              "            ...\n",
              "            10848, 10891, 10911, 10921, 10935, 10941, 10979, 10986, 10991,\n",
              "            11007],\n",
              "           dtype='int64', length=602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EUky3VvxJH"
      },
      "source": [
        "linhas_599nan = df_train['ind21'][df_train['ind21'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI4pULl0wble",
        "outputId": "1fbcf7a7-e9f0-4d47-d135-2cd10f15172a"
      },
      "source": [
        "len(set(list(linhas_602nan)) & set(list(linhas_599nan)))  \n",
        "# 602nan e 599nan apresentam 596 linhas em comum\n",
        "# entÃ£o tem 3 linhas em 599nan que nÃ£o estÃ£o em 602 nan e\n",
        "# 6 linhas em 602nan que nÃ£o estÃ£o em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXs7y99OyUEG",
        "outputId": "a6e963f8-43b9-4e53-d3cd-73c036721f9b"
      },
      "source": [
        "set(list(linhas_602nan)) - set(list(linhas_599nan)) # 6 linhas {1213, 1224, 3233, 5346, 6101, 7297} em 602nan mas nÃ£o em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpep48R0N19",
        "outputId": "54405911-141a-480b-dd4b-57daf90b6354"
      },
      "source": [
        "set(list(linhas_599nan)) - set(list(linhas_602nan)) # 3 linhas {5788, 10284, 10965} em 599nan mas nÃ£o em 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5788, 10284, 10965}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VghwKgdRwF2Y"
      },
      "source": [
        "linhas_34nan = df_train['ind01'][df_train['ind01'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozi0Gw990yml",
        "outputId": "04e1e738-a686-462c-fcc0-5b3493479a69"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_599nan))  # 34nan e 599nan nÃ£o apresentam linhas nan em comum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFs38gIx0zIQ",
        "outputId": "ccb5b11a-512a-45df-b75a-fbae70a82fe6"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_602nan)) # linhas {1213, 1224, 3233, 5346, 6101, 7297} em comum em 34nan e 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g41VmVkq-_R",
        "outputId": "5dee64cb-b577-4005-9ccb-cc336e42ca62"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdaAew8P89Jn",
        "outputId": "067f5309-3973-4017-8fb3-e069c718d740"
      },
      "source": [
        "df_train[df_train['mc1'].notna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    7917\n",
              "True     2514\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Ly8LJv2_9J_x",
        "outputId": "fa8b025e-00fc-4ad8-aa29-17f3a08c7bb5"
      },
      "source": [
        "df_train[df_train['mc1'].notna()].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.00000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.00000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5998.586521</td>\n",
              "      <td>53.33851</td>\n",
              "      <td>0.011993</td>\n",
              "      <td>0.013208</td>\n",
              "      <td>0.118480</td>\n",
              "      <td>0.014551</td>\n",
              "      <td>0.009693</td>\n",
              "      <td>0.002250</td>\n",
              "      <td>0.016025</td>\n",
              "      <td>0.032519</td>\n",
              "      <td>0.017690</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.134538</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.079664</td>\n",
              "      <td>0.133032</td>\n",
              "      <td>0.311410</td>\n",
              "      <td>0.330905</td>\n",
              "      <td>0.345606</td>\n",
              "      <td>0.365514</td>\n",
              "      <td>0.321753</td>\n",
              "      <td>0.37509</td>\n",
              "      <td>0.007881</td>\n",
              "      <td>0.001454</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.149238</td>\n",
              "      <td>0.178966</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.020676</td>\n",
              "      <td>0.00391</td>\n",
              "      <td>0.014755</td>\n",
              "      <td>0.004276</td>\n",
              "      <td>0.677786</td>\n",
              "      <td>0.686280</td>\n",
              "      <td>0.544727</td>\n",
              "      <td>0.53817</td>\n",
              "      <td>0.339742</td>\n",
              "      <td>0.333741</td>\n",
              "      <td>0.099889</td>\n",
              "      <td>0.570311</td>\n",
              "      <td>0.550781</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.295011</td>\n",
              "      <td>0.333269</td>\n",
              "      <td>0.999135</td>\n",
              "      <td>0.460636</td>\n",
              "      <td>0.907238</td>\n",
              "      <td>0.714602</td>\n",
              "      <td>0.644526</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>0.134254</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.170790</td>\n",
              "      <td>0.090957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3467.890242</td>\n",
              "      <td>19.98793</td>\n",
              "      <td>0.042113</td>\n",
              "      <td>0.026769</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.040304</td>\n",
              "      <td>0.037191</td>\n",
              "      <td>0.025934</td>\n",
              "      <td>0.029294</td>\n",
              "      <td>0.027583</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>0.038919</td>\n",
              "      <td>0.022033</td>\n",
              "      <td>0.013933</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007199</td>\n",
              "      <td>0.267626</td>\n",
              "      <td>0.283498</td>\n",
              "      <td>0.456864</td>\n",
              "      <td>0.438529</td>\n",
              "      <td>0.436875</td>\n",
              "      <td>0.463864</td>\n",
              "      <td>0.435993</td>\n",
              "      <td>0.44446</td>\n",
              "      <td>0.070991</td>\n",
              "      <td>0.032711</td>\n",
              "      <td>0.030087</td>\n",
              "      <td>0.319113</td>\n",
              "      <td>0.328067</td>\n",
              "      <td>0.164659</td>\n",
              "      <td>0.133429</td>\n",
              "      <td>0.06070</td>\n",
              "      <td>0.117785</td>\n",
              "      <td>0.064327</td>\n",
              "      <td>0.458565</td>\n",
              "      <td>0.456224</td>\n",
              "      <td>0.455770</td>\n",
              "      <td>0.45715</td>\n",
              "      <td>0.433962</td>\n",
              "      <td>0.434225</td>\n",
              "      <td>0.221986</td>\n",
              "      <td>0.425340</td>\n",
              "      <td>0.412952</td>\n",
              "      <td>0.059627</td>\n",
              "      <td>0.012832</td>\n",
              "      <td>0.018721</td>\n",
              "      <td>0.456070</td>\n",
              "      <td>0.471405</td>\n",
              "      <td>0.029402</td>\n",
              "      <td>0.498472</td>\n",
              "      <td>0.290112</td>\n",
              "      <td>0.451626</td>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>0.340941</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.206812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3012.500000</td>\n",
              "      <td>42.00000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002518</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.020741</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130695</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6006.000000</td>\n",
              "      <td>47.00000</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.005624</td>\n",
              "      <td>0.112164</td>\n",
              "      <td>0.002776</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007169</td>\n",
              "      <td>0.024386</td>\n",
              "      <td>0.005072</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131472</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.58330</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8990.500000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>0.006366</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.118149</td>\n",
              "      <td>0.011908</td>\n",
              "      <td>0.004606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016753</td>\n",
              "      <td>0.033129</td>\n",
              "      <td>0.017071</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133913</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918500</td>\n",
              "      <td>0.95860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id        cnae2  ...         ind42         ind43\n",
              "count  10431.000000  10431.00000  ...  10428.000000  10428.000000\n",
              "mean    5998.586521     53.33851  ...      0.170790      0.090957\n",
              "std     3467.890242     19.98793  ...      0.376344      0.206812\n",
              "min        0.000000      0.00000  ...      0.000000      0.000000\n",
              "25%     3012.500000     42.00000  ...      0.000000      0.000000\n",
              "50%     6006.000000     47.00000  ...      0.000000      0.000000\n",
              "75%     8990.500000     69.00000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.00000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWABZ-yWrQH2",
        "outputId": "e5092897-4659-4d79-969e-cc54bd1c11c4"
      },
      "source": [
        "df_train['target'].value_counts()   22,84% True e 77,16% False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3hg6GGQt9us"
      },
      "source": [
        "# Total de 46 Colunas/variÃ¡veis que apresentam NaN:\n",
        "# 'mc1', 'mc2', 'mc3',\n",
        "# 'ind01', 'ind02', 'ind03', 'ind04', 'ind05','ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30',\n",
        "# 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
        "# 'ind41', 'ind42', 'ind43'\n",
        "sendo:\n",
        "  # 32 colunas/variÃ¡veis que possuem 34 NaN cada\n",
        "    #'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "    #'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "    #'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "    #'ind40', 'ind41'\n",
        "  # 11 colunas/variÃ¡veis que possuem 599 NaN cada:\n",
        "    # 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "    # 'ind38', 'ind39',\n",
        "    # 'ind42', 'ind43'\n",
        "  # 3 colunas/variÃ¡veis que possuem 602 NaN cada\n",
        "    # ['mc1', 'mc2', 'mc3']\n",
        "\n",
        "# 602nan e 599nan apresentam 596 linhas em comum, entÃ£o:\n",
        "# 3 linhas em 599nan que nÃ£o estÃ£o em 602 nan : {5788, 10284, 10965}\n",
        "# 6 linhas em 602nan que nÃ£o estÃ£o em 599nan : {1213, 1224, 3233, 5346, 6101, 7297}\n",
        "\n",
        "# 602nan e 34nan apresentam 6 linhas em comum {1213, 1224, 3233, 5346, 6101, 7297} , que sÃ£o as mesmas 6 linhas que nÃ£o estÃ£o em 599nan\n",
        "# 599nan e 34nan nÃ£o apresentam linhas em comum\n",
        "\n",
        "# Total de 633 linhas com NaN ( = 596 + 3 + 6 + 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUqmH2Bt9uz"
      },
      "source": [
        "s_coluna = pd.Series(list(df_train.columns))\n",
        "s_qtde = pd.Series(list(df_train.isna().sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOMEunK3U29"
      },
      "source": [
        "df_nan = pd.DataFrame(zip(s_coluna, s_qtde),columns = ['coluna','qtde_nan'])\n",
        "df_nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3rZDA3t3q2p"
      },
      "source": [
        "df_nan[df_nan['qtde_nan']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLD7DW9a3t-J",
        "outputId": "ac583888-6975-4f49-a1c1-c1d0ba843a64"
      },
      "source": [
        "len(df_nan[df_nan['qtde_nan']!=0])        # 46 variÃ¡veis/colunas apresentam NaN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKbN8oAZ6uRf",
        "outputId": "5d4a510a-76b9-4598-d86d-66b71d00973f"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PBBF4-719u",
        "outputId": "bd2e3929-89c5-4f4b-941b-61015797e002"
      },
      "source": [
        "df_train['ind06'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind32'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5441\n",
              "1.0000    4081\n",
              "0.1671      62\n",
              "0.1534      41\n",
              "0.1644      38\n",
              "Name: ind06, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyl-JR3y8B_9",
        "outputId": "5d1e8982-89c7-4a49-d77a-735e570da7da"
      },
      "source": [
        "df_train['ind32'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    6958\n",
              "1.0    4041\n",
              "Name: ind32, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyySiN6PK3iU",
        "outputId": "907b60c3-6ce4-4fd4-a96c-40b8cb143622"
      },
      "source": [
        "df_train['ind04'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind05'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5812\n",
              "1.0000    3151\n",
              "0.0833     532\n",
              "0.9167     258\n",
              "0.1667     224\n",
              "Name: ind04, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-2Obx4LK3xA",
        "outputId": "3d1043e4-60e6-406a-f734-ea7bb12f6d7f"
      },
      "source": [
        "df_train['ind05'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    4776\n",
              "1.0000    3161\n",
              "0.0833     434\n",
              "0.9167     250\n",
              "0.1667     179\n",
              "Name: ind05, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbhjyN3LUU2",
        "outputId": "baf93d03-285c-4688-d097-956ff3360fcf"
      },
      "source": [
        "df_train['ind03'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind31'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    6844\n",
              "1.0000    3642\n",
              "0.0027      21\n",
              "0.0055      12\n",
              "0.1671      11\n",
              "Name: ind03, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ZuDkAPLUgt",
        "outputId": "3e432775-b12a-41e4-fccd-f69eaabbcab3"
      },
      "source": [
        "df_train['ind31'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    7357\n",
              "1.0    3642\n",
              "Name: ind31, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrx-HSHHMyCq",
        "outputId": "55126dd1-48a4-43eb-900e-8f0db36de927"
      },
      "source": [
        "df_train['ind23'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind24'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5018\n",
              "1.0000    2847\n",
              "0.0833     833\n",
              "0.1667     400\n",
              "0.2500     218\n",
              "Name: ind23, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMjX8IY2MyNP",
        "outputId": "c53eb23f-5d06-435d-c8f8-92076a19f984"
      },
      "source": [
        "df_train['ind24'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5136\n",
              "1.0000    2837\n",
              "0.0833     835\n",
              "0.1667     377\n",
              "0.2500     208\n",
              "Name: ind24, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMeKN8lNUIt",
        "outputId": "cc01503e-5456-426f-ae20-6ce841716839"
      },
      "source": [
        "df_train['ind42'].value_counts().head()   #alta correlaÃ§Ã£o com 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "1.0    1781\n",
              "Name: ind42, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXgzAeTgNUSM",
        "outputId": "6a572209-11ab-4302-8ccb-662e0738f363"
      },
      "source": [
        "df_train['ind43'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "0.5    1665\n",
              "1.0     116\n",
              "Name: ind43, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-xtwpcNrad",
        "outputId": "9fe5fdf5-f4f2-4bf5-d673-e3ebdacc1719"
      },
      "source": [
        "df_train['md2'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015110    8\n",
              "0.001655    7\n",
              "0.004966    6\n",
              "0.001986    6\n",
              "0.001324    5\n",
              "Name: md2, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8QRBw3Nrnf",
        "outputId": "43c65572-3f64-46bb-caab-4dd7660ad0b9"
      },
      "source": [
        "df_train['md8'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.039463    8\n",
              "0.017749    7\n",
              "0.025066    6\n",
              "0.019375    5\n",
              "0.019700    5\n",
              "Name: md8, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltYMeW-N1wG",
        "outputId": "f916e55d-abb8-46ae-b123-250e71288746"
      },
      "source": [
        "df_train['md7'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022106    8\n",
              "0.001986    7\n",
              "0.001655    6\n",
              "0.007449    6\n",
              "0.003310    5\n",
              "Name: md7, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo_VW-5a_6hL",
        "outputId": "42af1401-fa12-4e09-ddcc-c5f507918878"
      },
      "source": [
        "df_train['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv5QEKyPl0iG",
        "outputId": "35a463c7-5c68-4265-d5cd-bfb87ee1fcfa"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "cnae2     0\n",
              "rf2       0\n",
              "md1       0\n",
              "md2       0\n",
              "         ..\n",
              "ind40     0\n",
              "ind41     0\n",
              "ind42     0\n",
              "ind43     0\n",
              "target    0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxu66h0D2ZuV"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJStLm07t9u_"
      },
      "source": [
        "Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vSe45kBt9vA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WirO9VPz6tR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrodOQuDsKpc"
      },
      "source": [
        "def calcula_outliers(df):\n",
        "    Q1 = []\n",
        "    Q3 = []\n",
        "    IQR = []\n",
        "    linf = []\n",
        "    lsup = []\n",
        "    qtde_inf = []\n",
        "    qtde_sup = []\n",
        "    col = []\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        Q1.append(q1)\n",
        "        Q3.append(q3)\n",
        "        IQR.append(iqr)\n",
        "        linf.append(lim_inf)\n",
        "        lsup.append(lim_sup)\n",
        "        qtde_inf.append(len(df[df[i]<lim_inf]))\n",
        "        qtde_sup.append(len(df[df[i]>lim_sup]))\n",
        "        col.append(i)\n",
        "    return (Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6MkPFtYu7x7"
      },
      "source": [
        "Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col = calcula_outliers(df_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9t9BOagvPXU"
      },
      "source": [
        "df_outliers = pd.DataFrame(np.array([Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup]), columns=[lcol] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "0EcHYgrfzoIN",
        "outputId": "7965cfb7-0685-46e1-e75e-97fffd0f714d"
      },
      "source": [
        "df_outliers.rename(index = {0:'q1', 1:'q3', 2:'iqr', 3:'lim_inf', 4:'lim_sup', 5:'abaixo_lim_inf', 6:'acima_lim_sup'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>q1</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>q3</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iqr</th>\n",
              "      <td>0.006032</td>\n",
              "      <td>0.010318</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013209</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.016188</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_inf</th>\n",
              "      <td>-0.009046</td>\n",
              "      <td>-0.013055</td>\n",
              "      <td>0.098338</td>\n",
              "      <td>-0.016855</td>\n",
              "      <td>-0.006283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.016656</td>\n",
              "      <td>0.002453</td>\n",
              "      <td>-0.024269</td>\n",
              "      <td>-0.010959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.001895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_sup</th>\n",
              "      <td>0.015083</td>\n",
              "      <td>0.028217</td>\n",
              "      <td>0.129641</td>\n",
              "      <td>0.028091</td>\n",
              "      <td>0.010472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036180</td>\n",
              "      <td>0.050965</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.018265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138690</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abaixo_lim_inf</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acima_lim_sup</th>\n",
              "      <td>1658.000000</td>\n",
              "      <td>1181.000000</td>\n",
              "      <td>1203.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1718.000000</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1110.000000</td>\n",
              "      <td>1098.000000</td>\n",
              "      <td>1129.000000</td>\n",
              "      <td>1578.000000</td>\n",
              "      <td>339.0</td>\n",
              "      <td>1297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1233.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        md1          md2          md3  ... ind41 ind42 ind43\n",
              "q1                 0.000003     0.002422     0.110077  ...   NaN   NaN   NaN\n",
              "q3                 0.006035     0.012740     0.117903  ...   NaN   NaN   NaN\n",
              "iqr                0.006032     0.010318     0.007826  ...   NaN   NaN   NaN\n",
              "lim_inf           -0.009046    -0.013055     0.098338  ...   NaN   NaN   NaN\n",
              "lim_sup            0.015083     0.028217     0.129641  ...   NaN   NaN   NaN\n",
              "abaixo_lim_inf     0.000000     0.000000     4.000000  ...   0.0   0.0   0.0\n",
              "acima_lim_sup   1658.000000  1181.000000  1203.000000  ...   0.0   0.0   0.0\n",
              "\n",
              "[7 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "j004R47yzwCU",
        "outputId": "03cf0785-03b9-4384-d70d-a2aa4ad79054"
      },
      "source": [
        "df_train.drop(['id','cnae2'],axis=1,inplace=False).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001607</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106393</td>\n",
              "      <td>0.156942</td>\n",
              "      <td>0.345577</td>\n",
              "      <td>0.363809</td>\n",
              "      <td>0.377947</td>\n",
              "      <td>0.396748</td>\n",
              "      <td>0.304172</td>\n",
              "      <td>0.354500</td>\n",
              "      <td>0.007431</td>\n",
              "      <td>0.001371</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.170026</td>\n",
              "      <td>0.034449</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.003777</td>\n",
              "      <td>0.014728</td>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.695732</td>\n",
              "      <td>0.701113</td>\n",
              "      <td>0.555893</td>\n",
              "      <td>0.540622</td>\n",
              "      <td>0.325660</td>\n",
              "      <td>0.319979</td>\n",
              "      <td>0.094443</td>\n",
              "      <td>0.573265</td>\n",
              "      <td>0.549543</td>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.330101</td>\n",
              "      <td>0.366265</td>\n",
              "      <td>0.999184</td>\n",
              "      <td>0.487537</td>\n",
              "      <td>0.911266</td>\n",
              "      <td>0.730536</td>\n",
              "      <td>0.660654</td>\n",
              "      <td>0.004804</td>\n",
              "      <td>0.126892</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.161425</td>\n",
              "      <td>0.085969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012535</td>\n",
              "      <td>0.012276</td>\n",
              "      <td>0.013302</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305507</td>\n",
              "      <td>0.314749</td>\n",
              "      <td>0.469850</td>\n",
              "      <td>0.451344</td>\n",
              "      <td>0.448622</td>\n",
              "      <td>0.472732</td>\n",
              "      <td>0.430218</td>\n",
              "      <td>0.440494</td>\n",
              "      <td>0.068959</td>\n",
              "      <td>0.031765</td>\n",
              "      <td>0.029217</td>\n",
              "      <td>0.311906</td>\n",
              "      <td>0.322485</td>\n",
              "      <td>0.160898</td>\n",
              "      <td>0.129652</td>\n",
              "      <td>0.059707</td>\n",
              "      <td>0.117835</td>\n",
              "      <td>0.062471</td>\n",
              "      <td>0.451710</td>\n",
              "      <td>0.450337</td>\n",
              "      <td>0.445655</td>\n",
              "      <td>0.444689</td>\n",
              "      <td>0.425934</td>\n",
              "      <td>0.426005</td>\n",
              "      <td>0.217015</td>\n",
              "      <td>0.413842</td>\n",
              "      <td>0.401642</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.013319</td>\n",
              "      <td>0.018179</td>\n",
              "      <td>0.470270</td>\n",
              "      <td>0.481805</td>\n",
              "      <td>0.028551</td>\n",
              "      <td>0.499867</td>\n",
              "      <td>0.284372</td>\n",
              "      <td>0.443702</td>\n",
              "      <td>0.473509</td>\n",
              "      <td>0.069146</td>\n",
              "      <td>0.332867</td>\n",
              "      <td>0.016488</td>\n",
              "      <td>0.009520</td>\n",
              "      <td>0.367939</td>\n",
              "      <td>0.202125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.138900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860800</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                md1           md2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  11033.000000  11033.000000\n",
              "mean       0.011670      0.012928  ...      0.161425      0.085969\n",
              "std        0.041618      0.026515  ...      0.367939      0.202125\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.000003      0.002422  ...      0.000000      0.000000\n",
              "50%        0.000316      0.005415  ...      0.000000      0.000000\n",
              "75%        0.006035      0.012740  ...      0.000000      0.000000\n",
              "max        1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJF8Q05rbSF",
        "outputId": "d9835c6f-551b-4605-ab2f-9ff7464e9c1b"
      },
      "source": [
        "df_test.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JWJ0Z3ZBT8x",
        "outputId": "82b334d4-5001-4a31-c9f8-914aeab58285"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqmeyNYfBUkz"
      },
      "source": [
        "def f_trata_outliers(df):\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        df[i][df[i] < lim_inf] = lim_inf\n",
        "        df[i][df[i] > lim_sup] = lim_sup\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN--_ZdBdAb"
      },
      "source": [
        "f_trata_outliers(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6RCkr7CSAO"
      },
      "source": [
        "f_trata_outliers(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Y2TJ-Gt9vE"
      },
      "source": [
        "# funÃ§Ã£o que trata NaN:\n",
        "def f_trata_NaN(df):\n",
        "    coluna_nan = df.isna().sum()[df.isna().sum().values>0].index\n",
        "    for col in coluna_nan:\n",
        "      df[col] = df[col].fillna(df[col].median())\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-4KOA0t9vK"
      },
      "source": [
        "# tratando NaN nos dataframes df_train e df_test:\n",
        "df_train = f_trata_NaN(df_train)\n",
        "df_test = f_trata_NaN(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0E1CSAYnch8"
      },
      "source": [
        "# criando dummies em df_train e df_test:\n",
        "df_train = pd.get_dummies(df_train, drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, drop_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Es33OXkQnyLc",
        "outputId": "0ea8aa72-ca3f-42fb-cd96-8ef1648ecbe8"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\":{df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 72), \"df_test.shape:\":(1000, 71)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWjvdF3F2Xs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU4mjAscF4Ge"
      },
      "source": [
        "### PULAR PARA PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3tEEKJF2pO"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfiez91PF20t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj5Nlm_iEggt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e32c74e-508b-4c85-bffb-13cdcc9e345e"
      },
      "source": [
        "df_train['target'].astype('category')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         True\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "11028    False\n",
              "11029    False\n",
              "11030     True\n",
              "11031    False\n",
              "11032     True\n",
              "Name: target, Length: 11033, dtype: category\n",
              "Categories (2, object): [False, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i57fUZmDt9vP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9098a979-065d-4cf5-90bd-977906908a55"
      },
      "source": [
        "# definindo X (sem 'id' e 'target'), y (variÃ¡vel target) e X_submit (sem 'id'): \n",
        "X = df_train.drop(columns= ['id','target'], axis= 1)\n",
        "y = df_train['target']\n",
        "X_submit = df_test.drop(columns='id',axis=1)\n",
        "\n",
        "f'\"X.shape:\":{X.shape}, \"y.shape:\":{y.shape}, \"X_submit.shape:\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X.shape:\":(11033, 70), \"y.shape:\":(11033,), \"X_submit.shape:\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsYMnSZXKogI",
        "outputId": "050ed15b-a6a2-48f3-e15e-f3250de8b219"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cnae2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8', 'md9',\n",
              "       'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4', 'ind01', 'ind02',\n",
              "       'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
              "       'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18',\n",
              "       'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26',\n",
              "       'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32', 'ind33', 'ind34',\n",
              "       'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40', 'ind41', 'ind42',\n",
              "       'ind43', 'rf2_d', 'rf2_i', 'rf2_k', 'rf2_p', 'rf2_q', 'rf2_r', 'rf2_s',\n",
              "       'rf2_v', 'rf2_y', 'rf2_z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8J8ej6t9vT"
      },
      "source": [
        "MODELO: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpaBkXMzmLwh"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsRI-rGxmnQC"
      },
      "source": [
        "# FunÃ§Ã£o para cross validation:\n",
        "def funcao_cross_val_score(modelo, X_treinamento, y_treinamento, CV):\n",
        "    #versÃ£o com cross_val_score::\n",
        "    a_scores_CV = cross_val_score(modelo, X_treinamento, y_treinamento, cv = CV)\n",
        "    print(f'MÃ©dia das AcurÃ¡cias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "    print(f'std mÃ©dio das AcurÃ¡cias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "    return a_scores_CV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaez67ksHsc0"
      },
      "source": [
        "# FunÃ§Ã£o para Confusion Matrix:\n",
        "from sklearn.metrics import confusion_matrix \n",
        "def mostra_confusion_matrix(cf, \n",
        "                            group_names = None, \n",
        "                            categories = 'auto', \n",
        "                            count = True, \n",
        "                            percent = True, \n",
        "                            cbar = True, \n",
        "                            xyticks = False, \n",
        "                            xyplotlabels = True, \n",
        "                            sum_stats = True, \n",
        "                            figsize = (8, 8), \n",
        "                            cmap = 'Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_8spMrGt9vU"
      },
      "source": [
        "i_CV = 10 # NÃºmero de Cross-Validations\n",
        "i_Seed = 22091980 # semente por questÃµes de reproducibilidade\n",
        "f_Test_Size = 0.3 # ProporÃ§Ã£o do dataframe de validaÃ§Ã£o (outros valores poderiam ser 0.15, 0.20 ou 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDY6msH0t9vY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "864288a8-1c95-4378-93a6-c0ace2604968"
      },
      "source": [
        "# Definindo dataframes de TREINAMENTO e TESTE a partir de X e y:\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = f_Test_Size, random_state = i_Seed)\n",
        "f'\"X_treinamento.shape:\" {X_treinamento.shape}, \"y_treinamento_shape:\"{y_treinamento.shape},\"X_teste.shape:\"{X_teste.shape},\"y_teste.shape:\"{y_teste.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento.shape:\" (7723, 70), \"y_treinamento_shape:\"(7723,),\"X_teste.shape:\"(3310, 70),\"y_teste.shape:\"(3310,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjUjFaykt9vf"
      },
      "source": [
        "# Instancia...\n",
        "ml_XGB= XGBClassifier(silent=False,\n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 1,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=1000, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth= 3, \n",
        "                      gamma=1, \n",
        "                      max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTFhHr6Ar4mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623d16c7-d681-46a3-f908-a035a9fc2c8b"
      },
      "source": [
        "# Modelo treinado sobre base \"train-split-test\"\n",
        "ml_XGB.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
              "              learning_rate=0.01, max_delta_step=5, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=False, subsample=0.8, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EH4l3lAt9vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6bc8da-8467-4c10-ceb3-4d79613a7dc6"
      },
      "source": [
        "# Chamando a funÃ§Ã£o do CROSS VALIDATION - Modelo treinado sobre base \"train-split-test\":\n",
        "\n",
        "a_scores_CV = funcao_cross_val_score(ml_XGB, X_treinamento, y_treinamento, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.39\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHujyPesnWF",
        "outputId": "9c5bcd70-b10e-46fd-bcc1-af15cf57f38d"
      },
      "source": [
        "y_pred = ml_XGB.predict(X_teste)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3185  125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TXeOdfIsPkp",
        "outputId": "2587031c-0e86-4569-eec6-6a4beb2d825f"
      },
      "source": [
        "y_submit_0 = ml_XGB.predict(X_submit)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_0, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Mr2xE0EMnQ"
      },
      "source": [
        "# CV com X_treinamento e y_treinamento:       # Modelo treinado sobre base \"train-split-test\"\n",
        "# AcurÃ¡cia MÃ©dia / STD mÃ©dio\n",
        "# 77,38 / 0,54  tirando outliers - 70% X\n",
        "# 77,39 / 0,51  sem tirar outliers - 70% X\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste)\n",
        "# 0: 3177, 1: 133 => tirando outliers de df_train - 30% X\n",
        "# 0: 3185, 1: 125 => sem tirar outliers de df_train - 30% X\n",
        "\n",
        "# y_submit = ml_XGB.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "#  ???????????  => tirando outliers de df_train (nÃ£o rodei)\n",
        "# 0: 952, 1: 48 => sem tirar outliers de df_train (70% X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "iQhLNFkyt9v5",
        "outputId": "5de1fb25-c83b-4706-c3e7-06fcabda7dbd"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "********* CONFUSION MATRIX - PARAMETER TUNNING ***********\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKFg_7V13qj"
      },
      "source": [
        "### Treinando o modelo sobre toda a base (100% de df_train, X_treinamento = 100% X, y_treinamento = 100% y)\n",
        "ml_XGB.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyMkW8EB-s1U"
      },
      "source": [
        "ml_XGB_1 = XGBClassifier(silent=False,\n",
        "                         scale_pos_weight=1,\n",
        "                         learning_rate=0.01,  \n",
        "                         colsample_bytree = 1,\n",
        "                         subsample = 0.8,\n",
        "                         objective='binary:logistic', \n",
        "                         n_estimators=1000, \n",
        "                         reg_alpha = 0.3,\n",
        "                         max_depth= 3, \n",
        "                         gamma=1, \n",
        "                         max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1AWis2Xt9v-"
      },
      "source": [
        "# treinando o modelo sobre toda a base X (100% de df_train)\n",
        "ml_XGB1.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsWDYOunJXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382f9662-bae4-4563-fbf8-1beae73a3be6"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.8\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTnHowjpQTQ"
      },
      "source": [
        "# ml_XGB_1                            # Modelo treinado sobre X e y (100% df_train)\n",
        "\n",
        "# CV com X e y:                                             # Modelo treinado sobre toda base X (100% df_train)\n",
        "# AcurÃ¡ciaMÃ©dia / STD mÃ©dio\n",
        "# ??????????? => tirando outliers\n",
        "# 77,80 / 0,559  => sem tirar outliers\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste) ====> X_teste (% sobre X)\n",
        "# 0: 3194, 1: 116 => tirando outliers de df_train\n",
        "# 0: 3199, 1: 111 => sem tirar outliers de df_train\n",
        "\n",
        "# y_submit calculado com modelo treinado sobre TODA A BASE 'X' (100% df_train):\n",
        "\n",
        "# y_submit = ml_XGB_1.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "# 0: 955, 1: 45 => tirando outliers de df_train ==> PyLadies.csv com pontuaÃ§Ã£o = 0,4610\n",
        "# 0: 956, 1: 44 => sem tirar outliers de df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uUSripHII-8",
        "outputId": "7257fa2c-54cd-41af-f7f5-32174e77b062"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.8\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzvFPvCuJNbG",
        "outputId": "84b321e3-02cd-4324-cf97-c46e948b13fd"
      },
      "source": [
        "y_pred_1 = ml_XGB_1.predict(X_teste)\n",
        "unique_elements, counts_elements = np.unique(y_pred_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3199  111]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53EqCaJgJsGg"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred_1)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bafMtn3IQzi",
        "outputId": "be823d3f-a9b3-42a9-a060-1d40a478b53c"
      },
      "source": [
        "y_submit_1 = ml_XGB_1.predict(X_submit)\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9LGBShGt9wQ"
      },
      "source": [
        "df_submit_1 = pd.DataFrame(zip(df_test['id'],y_submit_1), columns = ['id','target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "MzStMVKLt9wU",
        "outputId": "cd759c29-e9a3-496d-cd20-763741fdae63"
      },
      "source": [
        "df_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  target\n",
              "0  3411   False\n",
              "1  2177   False\n",
              "2  8400   False\n",
              "3   464   False\n",
              "4  6672   False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUM9gFa1t9wa"
      },
      "source": [
        "df_submit_1.to_csv('PyLadies.csv',index = False, sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3zYdWgrzaOg"
      },
      "source": [
        "### LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llWEkYjWzZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732a26e2-e18d-416c-eef9-4bbd8a658a30"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmo-OjUYzZl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892f8e50-78ea-4ec8-dcdb-2b9343f6d26f"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.3MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQmrMW_zpAi"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNuQMi0Lz9Gg"
      },
      "source": [
        "X_train = X\n",
        "y_train = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDTQPmLA2ANY"
      },
      "source": [
        "X_test = X_submit\n",
        "y_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-uejECUyItk"
      },
      "source": [
        "# Preprocessing our data\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#tfidf = TfidfVectorizer(max_features=2000)\n",
        "#X_train = tfidf.fit_transform(df_train).toarray()\n",
        "#X_test = tfidf.transform(df_test).toarray()\n",
        "#y_train, y_test = df_train, df_test\n",
        "X_train_sub, X_valid, y_train_sub, y_valid = train_test_split(X_train, y_train, test_size=0.5,random_state=1234)\n",
        "# Setting up our results dataframe\n",
        "df_results = pd.DataFrame(columns=['accuracy', 'run_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOVl-3DayIt6"
      },
      "source": [
        "lgbm = LGBMClassifier(n_estimators=2000,\n",
        "                      feature_fraction=0.06,\n",
        "                      bagging_fraction=0.67,\n",
        "                      bagging_freq=1,\n",
        "                      verbose=0,\n",
        "                      n_jobs=6,\n",
        "                      random_state=1234,\n",
        "                      force_row_wise=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kB4dRc2yIt6"
      },
      "source": [
        "cb = CatBoostClassifier(n_estimators=2000,\n",
        "                        colsample_bylevel=0.06,\n",
        "                        max_leaves=31,\n",
        "                        subsample=0.67,\n",
        "                        verbose=0,\n",
        "                        thread_count=6,\n",
        "                        random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-enhLnbPyIt6"
      },
      "source": [
        "models = [lgbm, cb]\n",
        "model_names = [i.__class__.__name__ for i in models]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIujmOn_yIt6"
      },
      "source": [
        "es_models = ['LGBMClassifier',\n",
        "             'CatBoostClassifier']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptnWWC5ByIt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a23ffe-8e1c-44e0-d156-d109f8b2fe66"
      },
      "source": [
        "for m, n in zip(models, model_names):\n",
        "    \n",
        "    start_time = time()\n",
        "    if n in es_models:\n",
        "        m.fit(X_train_sub,\n",
        "              y_train_sub,\n",
        "              eval_set = [(X_valid, y_valid)],\n",
        "              early_stopping_rounds=15,\n",
        "              verbose=0)\n",
        "    else:\n",
        "        m.fit(X_train, y_train)\n",
        "    \n",
        "    run_time = time() - start_time\n",
        "    accuracy = np.mean(m.predict(X_test) == y_test)\n",
        "        \n",
        "    df_results.loc[n] = [accuracy, run_time]\n",
        "    \n",
        "    del m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsoMfK1dyIt_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ffba49ac-bc08-48ee-958c-ce1693a63fd4"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.917237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoostClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.017664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  run_time\n",
              "LGBMClassifier           0.0  0.917237\n",
              "CatBoostClassifier       0.0  2.017664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAoPBG4WyIuA"
      },
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJO5N2i8yIuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc4f76f-d7c2-408a-e2ea-5e2ddb2a7adc"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_lgbm, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [961  39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wBQ5TByIuA"
      },
      "source": [
        "y_pred_cb = cb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjEtLNQKyIuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fa58f0-da53-4ba6-c995-d18d25182939"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_cb, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [965 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PsK2T-H7DZY"
      },
      "source": [
        "### ZENILSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lGpednyItU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c12_fw4I7TAt"
      },
      "source": [
        "i_Seed = 19961108\n",
        "\n",
        "preditoras = X\n",
        "target = y\n",
        "df_testeTratado = X_submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oACaNC2F9yD6"
      },
      "source": [
        "df_testeTratado.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbmI06k3yItY"
      },
      "source": [
        "## Aqui, como passo intermediÃ¡rio, executei o modelo usando o dataframe default (getDataFrameDefault) e analisei a importÃ¢ncia das features:\n",
        "## entÃ£o fui modificando o dataframe excluindo as features menos importantes...\n",
        "## OBS: para utilizar, carregar antes a funÃ§Ã£o treina_testa\n",
        "'''\n",
        "df_default = otdf_Treino.getDataFrameDefault()\n",
        "preditoras = df_default.copy()\n",
        "preditoras.drop(columns=[\"Churn\",\"id\"],inplace=True)\n",
        "target = df_treinoTratado[\"Churn\"]\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0] #considerei todas as features que nÃ£o sÃ£o do tipo \"flutuante\" como categÃ³ricas\n",
        "print(f\"Qtde de features categÃ³ricas: {len(categorical_features_indices)}\")\n",
        "print(f\"Colunas preditoras: {preditoras.columns}\")\n",
        "\n",
        "acc = treina_testa(mostrarFI=True)\n",
        "print(f\"acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5oQMioHz93b"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mew6XsGRyItW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4bb2f9-06ad-4394-9e8e-5d5cc292b8ba"
      },
      "source": [
        "#considerei todas as features que nÃ£o sÃ£o do tipo \"flutuante\" como categÃ³ricas\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0]\n",
        "len(categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0JVbdH89w1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "75e5259a-2030-4858-83f1-ea56124d2eaf"
      },
      "source": [
        "acc = treina_testa(mostrarFI=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-d21779ef0020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-648fed880d09>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'bool' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEf7qd9yItW"
      },
      "source": [
        "ts=0.30\n",
        "it=300\n",
        "lr=0.03\n",
        "depth=5\n",
        "gerarArquivo=False\n",
        "mostrarFI=False\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg1ZO8CoyItX"
      },
      "source": [
        "catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oer3P4jcyItX"
      },
      "source": [
        "catb_tuned = catb.fit(X_treinamento, y_treinamento) # cat_features=categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITg22JTLyItY"
      },
      "source": [
        "y_pred = catb_tuned.predict(X_submit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS_5F2K4yItY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3dccaa-29d4-4911-a30f-26f6661740bd"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [963 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNshKeM8qKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11aa5ab0-d619-4186-d397-8385c720a5fb"
      },
      "source": [
        "categorical_features_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1y8ZaNQyItZ"
      },
      "source": [
        "def treina_testa(ts=0.30,it=300, lr=0.03, depth=5, gerarArquivo=False, mostrarFI=False):\n",
        "   X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)#, random_state = i_Seed)\n",
        "   catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)\n",
        "   catb_tuned = catb.fit(  X_treinamento, y_treinamento, cat_features=categorical_features_indices)\n",
        "   y_pred = catb_tuned.predict(X_submit)\n",
        "   acc_catb = round(accuracy_score(y_pred, y_teste) * 100, 2)\n",
        "   #print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\n",
        "   if (mostrarFI == True):\n",
        "      l_fi = list(zip(catb_tuned.feature_importances_,X_treinamento.columns))\n",
        "      print(l_fi)\n",
        "\n",
        "   if gerarArquivo == True: \n",
        "      df_id = df_test[[\"id\"]]\n",
        "      df_teste3 = df_testeTratado #.drop(columns=[\"id\"],axis=1)\n",
        "      resposta = catb_tuned.predict(df_teste3)\n",
        "      resposta_df = pd.DataFrame(resposta, columns=['target'])\n",
        "      resultado_submissao = pd.concat([df_id, resposta_df],axis=1)\n",
        "      resultado_submissao.head().T\n",
        "      filename = 'submissao_kaggle_catb_fs_ts0{}_it{}_lr{}_depth{}_sc{}.csv'.format(round(ts*100,0),it, lr, depth,str(int(acc_catb*100)))\n",
        "      resultado_submissao.to_csv(filename, index=False)   \n",
        "      print(filename)\n",
        "   return acc_catb   \n",
        "   #result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHlX8NFSBDwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f84da2ec-226a-455d-e82c-8d2d5a7fb96a"
      },
      "source": [
        "f'\"X_treinamento=\" : {X_treinamento.shape}, \"y_treinamento=\" : {y_treinamento.shape}, \"X_teste=\":{X_teste.shape},\"y_teste=\":{y_teste.shape},\"X_submit=\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento=\" : (7723, 70), \"y_treinamento=\" : (7723,), \"X_teste=\":(3310, 70),\"y_teste=\":(3310,),\"X_submit=\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlK6ScvayItZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "2de6fc56-250a-42ac-9318-5121166b6373"
      },
      "source": [
        "#l_ts = [0.22, 0.24, 0.25, 0.26, 0.28, 0.30, 0.32]\n",
        "#l_it =  [300, 400, 500], \n",
        "#l_lr = [0.02, 0.03, 0.04]\n",
        "#l_depth = [2, 3, 4, 5]\n",
        "l_ts, l_it, l_lr, l_depth = [0.26], [400], [0.02], [3]\n",
        "resultado = {}\n",
        "\n",
        "for vez in range(1,11):\n",
        "   resultado[vez] = {\"ts\":[], \"it\":[], \"lr\":[],\"depth\":[],\"score\":[]}\n",
        "   for ts in l_ts:\n",
        "       print(f'execuÃ§Ã£o {vez}/ts {ts}...')\n",
        "       for it in l_it:\n",
        "           for lr in l_lr:\n",
        "               for depth in l_depth:\n",
        "                  res = treina_testa(ts=ts, it=it, lr=lr, depth=depth,gerarArquivo=False, mostrarFI=False) #nÃ£o vai salvar o arquivo e nem mostrar as melhores features\n",
        "                  resultado[vez][\"ts\"].append(ts)\n",
        "                  resultado[vez][\"it\"].append(it)\n",
        "                  resultado[vez][\"lr\"].append(lr)\n",
        "                  resultado[vez][\"depth\"].append(depth)\n",
        "                  resultado[vez][\"score\"].append(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execuÃ§Ã£o 1/ts 0.26...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-c7cedf244408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgerarArquivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#nÃ£o vai salvar o arquivo e nem mostrar as melhores features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"it\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-cd249ff4f9ff>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 2869]"
          ]
        }
      ]
    }
  ]
}