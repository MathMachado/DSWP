{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMMkG90jdnbOnNWGBio87WC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/DSWP/blob/master/XGBoost_Imbalanced_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost \"scale_pos_weight\" vs \"sample_weight\" for Imbalanced Classification\n",
        "* When working with imbalanced classification tasks, where the number of instances in each class is significantly different, XGBoost provides two main parameters to handle class imbalance: scale_pos_weight and sample_weight.\n",
        "\n",
        "This example demonstrates how to use both parameters and compares their performance using evaluation metrics on a synthetic imbalanced dataset."
      ],
      "metadata": {
        "id": "-qn8xnoQRp-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scale_pos_weight example:"
      ],
      "metadata": {
        "id": "m3M9C_zpRyzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzCgNg-YRhXe"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Generate an imbalanced synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute scale_pos_weight as ratio of negative to positive instances in train set\n",
        "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
        "\n",
        "# Initialize XGBClassifier with scale_pos_weight\n",
        "model_spw = XGBClassifier(n_estimators=100, scale_pos_weight=scale_pos_weight, random_state=42)\n",
        "\n",
        "# Train model and evaluate performance on test set\n",
        "model_spw.fit(X_train, y_train)\n",
        "pred_spw = model_spw.predict(X_test)\n",
        "print(\"scale_pos_weight model:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, pred_spw))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred_spw))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sample_weight example:"
      ],
      "metadata": {
        "id": "nRXETBUPR7lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Generate an imbalanced synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create sample_weight array mapping class weights to instances in train set\n",
        "class_weights = {0: 1, 1: 10}\n",
        "sample_weights = np.array([class_weights[class_id] for class_id in y_train])\n",
        "\n",
        "# Initialize XGBClassifier with default parameters\n",
        "model_sw = XGBClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train model using sample_weight and evaluate on test set\n",
        "model_sw.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "pred_sw = model_sw.predict(X_test)\n",
        "print(\"sample_weight model:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, pred_sw))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred_sw))"
      ],
      "metadata": {
        "id": "XNc1gfTvR_Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Configure \"class_weight\" Parameter for Imbalanced Classification\n",
        "* Class imbalance is a common issue in real-world classification problems, where the number of instances in one class significantly outweighs the other.\n",
        "\n",
        "XGBoost provides the scale_pos_weight parameter to effectively handle imbalanced datasets by adjusting the weights of the positive class.\n",
        "\n",
        "It’s important to note that while some other machine learning algorithms use the parameter name class_weight, XGBoost specifically uses scale_pos_weight to handle class imbalance.\n",
        "\n",
        "This example demonstrates how to compute and set the scale_pos_weight parameter when training an XGBoost model on imbalanced data.\n",
        "\n",
        "We’ll generate a synthetic imbalanced binary classification dataset using scikit-learn, train an XGBClassifier with scale_pos_weight, and evaluate the model’s performance using the confusion matrix and classification report."
      ],
      "metadata": {
        "id": "dqOrh64-SNbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Generate an imbalanced synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute the scale_pos_weight\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "print(f'pos weight: {scale_pos_weight}')\n",
        "\n",
        "# Initialize XGBClassifier with scale_pos_weight\n",
        "model = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "EabtxsQ8SShp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Configure \"max_delta_step\" Parameter for Imbalanced Classification\n",
        "* When working with imbalanced classification tasks in XGBoost, where the number of instances in each class differs significantly, the model may overfit on the majority class.\n",
        "\n",
        "The max_delta_step parameter can help mitigate this issue by limiting the maximum change in the predictions between iterations, effectively preventing the model from giving too much importance to the majority class.\n",
        "\n",
        "This example demonstrates how to use the max_delta_step parameter and evaluates its impact on model performance using a synthetic imbalanced dataset."
      ],
      "metadata": {
        "id": "_hkTEf9iScwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pmM0xKcMSiw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Generate an imbalanced synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBClassifier with default settings\n",
        "model_default = XGBClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize XGBClassifier with max_delta_step set to a non-default value\n",
        "model_mds = XGBClassifier(n_estimators=100, max_delta_step=1, random_state=42)\n",
        "\n",
        "# Fit the models\n",
        "model_default.fit(X_train, y_train)\n",
        "model_mds.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "pred_default = model_default.predict(X_test)\n",
        "pred_mds = model_mds.predict(X_test)\n",
        "\n",
        "# Evaluate the models\n",
        "print(\"Model with default settings:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, pred_default))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred_default))\n",
        "\n",
        "print(\"\\nModel with max_delta_step set to 1:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, pred_mds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred_mds))"
      ],
      "metadata": {
        "id": "GA6Z78MgS8CL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
