{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/Python_RFB/blob/DS_Python/Notebooks/3DP_4_Data%20Transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnd-3xouAPfU",
        "colab_type": "text"
      },
      "source": [
        "# 3DP_DATA TRANSFORMATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TdSY74U0XS9",
        "colab_type": "text"
      },
      "source": [
        "# Leitura Recomendada:\n",
        "* [Why, How and When to Scale your Features](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)\n",
        "* [Demonstrating the different strategies of KBinsDiscretizer](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py);\n",
        "* [Why do we need feature scaling in Machine Learning and how to do it using SciKit Learn?](https://medium.com/@contactsunny/why-do-we-need-feature-scaling-in-machine-learning-and-how-to-do-it-using-scikit-learn-d8314206fe73)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DGifbWSmW3",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning com Python (Scikit-Learn)\n",
        "\n",
        "![Scikit-Learn](https://github.com/MathMachado/Python_RFB/blob/master/Material/scikit-learn-1.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-chlATnKSza",
        "colab_type": "text"
      },
      "source": [
        "# Carregar as bibliotecas (genéricas) Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQGVQB18-tM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install category_encoders\n",
        "!pip install update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJxrZckYxk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "import category_encoders as ce # library para aplicação do WOE - Weight Of Evidence para avaliar importância dos atributos\n",
        "\n",
        "# remove warnings to keep notebook clean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0fuDyI8_UPf",
        "colab_type": "text"
      },
      "source": [
        "# Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oRWtarakgMY",
        "colab_type": "text"
      },
      "source": [
        "## Dataframe gerado aleatoriamente - variáveis com distribuição Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXPXo3k0VDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N= 1000\n",
        "df = pd.DataFrame({\n",
        "    'Variavel1': np.random.normal(0, 2, N),\n",
        "    'Variavel2': np.random.normal(5, 3, N),\n",
        "    'Variavel3': np.random.normal(-5, 5, N),\n",
        "    'Variavel4': np.random.normal(-10, 10, N)\n",
        "})\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8MZNLbUkp8R",
        "colab_type": "text"
      },
      "source": [
        "## Dataframe gerado aleatoriamente 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR-fDDujcTup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "classification_data, classification_class = make_classification(n_samples=100, n_features=4, n_informative=3, n_redundant=1, n_classes=3)\n",
        "\n",
        "df_classification = pd.DataFrame({'Feature 1':classification_data[:,0],\n",
        "                                  'Feature 2':classification_data[:,1],\n",
        "                                  'Feature 3':classification_data[:,2],\n",
        "                                  'Feature 4':classification_data[:,3],\n",
        "                                  'Class':classification_class})\n",
        "df_classification.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0v0uXFRl-yG",
        "colab_type": "text"
      },
      "source": [
        "# Transformações"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkzTO0fdz93b",
        "colab_type": "text"
      },
      "source": [
        "## StandardScaler\n",
        "* The StandardScaler assumes your data is normally distributed within each feature and will scale them such that the distribution is now centred around 0, with a standard deviation of 1.\n",
        "* If data is not normally distributed, this is not the best scaler to use.\n",
        "\n",
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/pp4.PNG?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1UOOWeQ0R_Y",
        "colab_type": "text"
      },
      "source": [
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Lzx3xN6wpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cPq_7Vu2HCS",
        "colab_type": "text"
      },
      "source": [
        "Histograma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYW9WwBC3hd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(df['Variavel3'], color = 'blue', edgecolor = 'black', bins = int(180/5))\n",
        "\n",
        "# Adiciona títulos e labels\n",
        "plt.title('Histograma da Variável3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrgxkESc-Uaq",
        "colab_type": "text"
      },
      "source": [
        "Considere o gráfico a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7dHTF1W-Xsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMS72n14-hDO",
        "colab_type": "text"
      },
      "source": [
        "Qual a interpretação para esse gráfico?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEkAqlZg-p0v",
        "colab_type": "text"
      },
      "source": [
        "A seguir, vamos aplicar a transformação StandardScaler as variáveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4u3T_BX-oc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "standardscaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPa4-SCt-ynX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_StandardScaler = standardscaler.fit_transform(df)\n",
        "df_StandardScaler = pd.DataFrame(df_StandardScaler, columns=['Variavel1','Variavel2','Variavel3', 'Variavel4'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmQp8wDO_E88",
        "colab_type": "text"
      },
      "source": [
        "Agora compare esse novo gráfico abaixo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2fTPWsm_Hq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_StandardScaler.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fuURrao_M0c",
        "colab_type": "text"
      },
      "source": [
        "Qual a conclusão?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxGsebtmcP4N",
        "colab_type": "text"
      },
      "source": [
        "## Normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiVI9bjYe0H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajUc0sAicV-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xml-2qLtc7XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Normalize = normalize(df, norm= 'l2')\n",
        "df_Normalize = pd.DataFrame(df_Normalize, columns=['Variavel1','Variavel2','Variavel3', 'Variavel4'])\n",
        "df_Normalize.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0jTGdepe5Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Normalize.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0A9U7rs_RAT",
        "colab_type": "text"
      },
      "source": [
        "## MinMaxScaler\n",
        "* Transformação popular.\n",
        "* Transforma os dados para o intervalo (0, 1);\n",
        "* Se StandardScaler não é aplicável, então essa transformação funciona bem.\n",
        "* Sensível aos outliers. Portanto, o ideal é que os outliers sejam tratados previamente.\n",
        "\n",
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/pp3.PNG?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0HbeuP-AU_p",
        "colab_type": "text"
      },
      "source": [
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgeLckzxAWaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_W9bTO2AbEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJRFbUpBAg5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minmax = MinMaxScaler()\n",
        "df_MinMaxScaler = minmax.fit_transform(df)\n",
        "df_MinMaxScaler = pd.DataFrame(df_MinMaxScaler,columns=['Variavel1','Variavel2','Variavel3', 'Variavel4'])\n",
        "df_MinMaxScaler.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g8GA4LTA40U",
        "colab_type": "text"
      },
      "source": [
        "Qual a conclusão?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z6D3vfnB9Nm",
        "colab_type": "text"
      },
      "source": [
        "## RobustScaler\n",
        "* Transformação ideal para dados com outliers;\n",
        "\n",
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/pp2.PNG?raw=true\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3oyuxLeCW1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeDF7-w_CcBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "robustscaler = RobustScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLoqSKijCf2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_RobustScaler = robustscaler.fit_transform(df)\n",
        "df_RobustScaler = pd.DataFrame(df_RobustScaler, columns=['Variavel1','Variavel2','Variavel3', 'Variavel4'])\n",
        "df_RobustScaler.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YVMgt-WEFif",
        "colab_type": "text"
      },
      "source": [
        "## Encoding Variáveis Categoricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHYvLc8T_jxQ",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Variáveis Ordinais\n",
        "* Exemplo: Variáveis com valores ordinais: Low, Medium ou High."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdVahfJAEkuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gera um dataframe como exemplo.\n",
        "# Aqui vou usar a função randint - Retorna números inteiros aleatórios incluindo o número inferior e excluindo o superior.\n",
        "\n",
        "lIdade= [np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40),\n",
        "         np.random.randint(20, 40), np.random.randint(20, 40),np.random.randint(20, 40),np.random.randint(20, 40),np.random.randint(20, 40)]\n",
        "\n",
        "lSalario= ['Low', 'Medium', 'High']\n",
        "lSalario2= np.random.choice(lSalario, 10, p=[0.6, 0.3, 0.1])\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Idade': lIdade,\n",
        "    'Salario': lSalario2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_15P2eUHSBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1g9pEuyHe2q",
        "colab_type": "text"
      },
      "source": [
        "Neste exemplo, vamos redefinir a variável categórical ordinal 'Salario' da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkwFuEa8HnMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Salario_Cat']= df.Salario.map({'Low':1,'Medium':2,'High':3})\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlaIFiWIIPAl",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Variáveis Nominais\n",
        "* Exemplo: Variáveis com valores nominais: Sexo (Feminino, masculino).\n",
        "\n",
        "* Use One-Hot Encoding ou pd.get.dummies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNoJQbgJRoY",
        "colab_type": "text"
      },
      "source": [
        "Vamos utilizar o dataframe criado no passo anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMCoUWZOI7c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Salario.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIEyBkaJeN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MwK4cUEKeK4",
        "colab_type": "text"
      },
      "source": [
        "#### Aplicar LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6VXDsHJiII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "df['Salario_le'] = le.fit_transform(df.Salario)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgv2Zz07Kqfj",
        "colab_type": "text"
      },
      "source": [
        "#### Aplicar pd.get.dummies()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSZRIEs6K5sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummies= pd.get_dummies(df['Salario'])\n",
        "df= pd.concat([df, dummies], axis= 1)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWKrLlxsMLaw",
        "colab_type": "text"
      },
      "source": [
        "O comando a seguir produz o mesmo resultado que o anterior:\n",
        "```\n",
        "df= df.merge(dummies, how= 'left')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwh0alhdgrE3",
        "colab_type": "text"
      },
      "source": [
        "# Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caFkC6oCmUKK",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 1 - Predict Breast Cancer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOM-Z9zmf-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X= cancer['data']\n",
        "y= cancer['target']\n",
        "\n",
        "df_cancer = pd.DataFrame(np.c_[X, y], columns= np.append(cancer['feature_names'], ['target']))\n",
        "df_cancer['target'] = df_cancer['target'].map({0: 'malign', 1: 'benign'})\n",
        "df_cancer.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qruqUDqnvMc",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 2 - Predict Boston Housing Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trxK8YXNnsam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "boston = load_boston()\n",
        "X= boston['data']\n",
        "y= boston['target']\n",
        "\n",
        "df_boston = pd.DataFrame(np.c_[X, y], columns= np.append(boston['feature_names'], ['target']))\n",
        "df_boston.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSTKrd992LtI",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 3 - Predict Iris\n",
        "* [Aqui](https://en.wikipedia.org/wiki/Iris_flower_data_set) você obterá mais informações sobre o dataframe iris. Confira."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mThqvGGr2Vuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X= iris['data']\n",
        "y= iris['target']\n",
        "\n",
        "df_iris = pd.DataFrame(np.c_[X, y], columns= np.append(iris['feature_names'], ['target']))\n",
        "df_iris['target'] = df_iris['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
        "df_iris.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzu0Dz33c8ds",
        "colab_type": "text"
      },
      "source": [
        "## Exercícios 4 - Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ahBZmqc_-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "X= diabetes['data']\n",
        "y= diabetes['target']\n",
        "\n",
        "df_diabetes = pd.DataFrame(np.c_[X, y], columns= np.append(diabetes['feature_names'], ['target']))\n",
        "df_diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5fDp1Ib_Dg8",
        "colab_type": "text"
      },
      "source": [
        "# WOE - Weight Of Evidence\n",
        "* As vantagens da transformação WOE são\n",
        "    * Lida bem com NaN's;\n",
        "    * Lida bem com outliers;\n",
        "    * A transformação é baseada no valor logarítmico das distribuições.\n",
        "    * Usando a técnica de binning apropriada, pode estabelecer uma relação monotônica (aumentar ou diminuir) entre a variável dependente e independente."
      ]
    }
  ]
}