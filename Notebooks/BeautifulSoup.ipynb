{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled21.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/DSWP/blob/master/Notebooks/BeautifulSoup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FrU46HlRit2",
        "colab_type": "text"
      },
      "source": [
        "# Webscrapping\n",
        "* Beautiful Soup provides a few simple methods and Pythonic idioms for navigating,\n",
        "searching, and modifying a parse tree: a toolkit for dissecting a document and\n",
        "extracting what you need. It doesn't take much code to write an application.\n",
        "\n",
        "*To extract data using web scraping with python, you need to follow these basic steps:\n",
        "\n",
        "1. Find the URL that you want to scrape\n",
        "2. Inspecting the Page\n",
        "3. Find the data you want to extract\n",
        "4. Write the code\n",
        "5. Run the code and extract the data\n",
        "6. Store the data in the required format "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV8GWLnIkwbD",
        "colab_type": "text"
      },
      "source": [
        "[Python Frameworks and Libraries for Web Scraping](https://www.scrapehero.com/python-web-scraping-frameworks/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYhoIF6yqR1k",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Find the URL that you want to scrape\n",
        "For this example, we are going scrape Flipkart website to extract the Price, Name, and Rating of Laptops.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kBbBqBZqcKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "source= requests.get('https://www.flipkart.com/laptops/~buyback-guarantee-on-laptops-/pr?sid=6bo%2Cb5g&uniqBStoreParam1=val1&wid=11.productCard.PMU_V2')\n",
        "if source.status_code == 200:\n",
        "    print('Requisição bem sucedida!')\n",
        "    content = source.content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSDJdSFRqkTR",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Inspecting the Page\n",
        "* The data is usually nested in tags. So, we inspect the page to see, under which tag the data we want to scrape is nested. To inspect the page, just right click on the element and click on “Inspect”.\n",
        "\n",
        "Para isso, posicione o mouse sobre a informação que você quer capturar e clique em 'Inspect'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpQdI31ErOd-",
        "colab_type": "text"
      },
      "source": [
        "# Step 3: Find the data you want to extract\n",
        "* Let’s extract the Price, Name, and Rating which is nested in the “div” tag respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piphzjW-rZAz",
        "colab_type": "text"
      },
      "source": [
        "# Step 4: Write the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFRcjOSXqV6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io0vTEM2szu7",
        "colab_type": "text"
      },
      "source": [
        "As mentioned earlier, the data we want to extract is nested in <div> tags. So, I will find the div tags with those respective class-names, extract the data and store the data in a variable. Refer the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMqUfXc-vMPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE2NvWkcxRRs",
        "colab_type": "text"
      },
      "source": [
        "[Python Regular Expressions](https://developers.google.com/edu/python/regular-expressions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu1rBbpNvWC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'a' --> ignore uppercase\n",
        "# \n",
        "\n",
        "products=[] #List to store name of the product\n",
        "prices=[] #List to store price of the product\n",
        "ratings=[] #List to store rating of the product\n",
        "\n",
        "# find_all() --> returns a list of all elements matching the criteria, \n",
        "# even if only one element is found, find_all will return a list of a single item.\n",
        "for a in soup.findAll('a', attrs= {'class':'_31qSD5'}):\n",
        "    # find() --> returns the first HTML element found\n",
        "    name= a.find('div', attrs={'class':'_3wU53n'})\n",
        "    print(name)\n",
        "    price= a.find('div', attrs={'class':'_1vC4OE _2rQ-NK'})\n",
        "    #print(price)\n",
        "    rating=a.find('div', attrs={'class':'hGSR34'})\n",
        "    #print(rating)\n",
        "    #type(rating)\n",
        "    products.append(name.text)\n",
        "    #print(products)\n",
        "    prices.append(price.text)\n",
        "    ratings.append(rating.text) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLLXSYAZRqwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Zoom: Varre o objeto soup em busca de todas as ocorrências de <a class=\"_31qSD5\"\n",
        "soup.findAll('a', attrs= {'class':'_31qSD5'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4N00f3xSN-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Busca todas as ocorrências de <a class=\"_31qSD5\", mas captura somente a linha 0.\n",
        "a= soup.findAll('a', attrs= {'class':'_31qSD5'})[0]\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w6SHBvVR3KK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Varre 'a' em busca de todas as ocorrências de ''_3wU53n'.\n",
        "a.find('div', attrs={'class':'_3wU53n'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viH9JBYPSje4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Varre 'a' em busca da primeira ocorrência de 'div' \n",
        "price= a.find('div', attrs={'class':'_1vC4OE _2rQ-NK'})\n",
        "price"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqTTsZqJSjiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finalmente, captura o valor desejado.\n",
        "price.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84qUAUKRTI7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3nunirmx-9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvL0VFLs2XK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY90uJNg2asw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZYKmod3zguh",
        "colab_type": "text"
      },
      "source": [
        "# Step 6: Store the data in a required format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7EBiYvtvfy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'Product Name':products,'Price':prices,'Rating':ratings}) \n",
        "df.to_csv('products.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W90F12qcA6tm",
        "colab_type": "text"
      },
      "source": [
        "# Exemplo 2\n",
        "Source: [https://medium.com/data-hackers/como-fazer-web-scraping-em-python-23c9d465a37f](https://medium.com/data-hackers/como-fazer-web-scraping-em-python-23c9d465a37f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljohJjp4A8m8",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Find the URL that you want to scrape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5ZxLWbcA82S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "source= requests.get('https://www.basketball-reference.com/leagues/NBA_2018_totals.html')\n",
        "if source.status_code == 200:\n",
        "    print('Requisição bem sucedida!')\n",
        "    content = source.content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf93axhBBG27",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Inspecting the Page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT6BUqYkBPAE",
        "colab_type": "text"
      },
      "source": [
        "# Step 3: Find the data you want to extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrLmi9tcBWQ8",
        "colab_type": "text"
      },
      "source": [
        "# Step 4: Write the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plCPR6JKB9Dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup= BeautifulSoup(content, 'html.parser')\n",
        "table= soup.find(name='table')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlhPFf8YCOMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table_str = str(table)\n",
        "df= pd.read_html(table_str)[0]\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkAhkzX3G3hU",
        "colab_type": "text"
      },
      "source": [
        "# Exemplo 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCHzr4j1G5Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "source= requests.get('http://books.toscrape.com/index.html')\n",
        "if source.status_code == 200:\n",
        "    print('Requisição bem sucedida!')\n",
        "    content = source.content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2eBLyx_KyW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "#print(soup.prettify())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p4k0XtKN-TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all(\"a\", href= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEZ4nawxWJB4",
        "colab_type": "text"
      },
      "source": [
        "# Exemplo 5\n",
        "[Tutorial: Web Scraping and BeautifulSoup](https://www.dataquest.io/blog/web-scraping-beautifulsoup/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gl3BjObWToh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "source= requests.get('https://www.imdb.com/search/title/?release_date=2017&sort=num_votes,desc&page=2&ref_=adv_nxt')\n",
        "if source.status_code == 200:\n",
        "    print('Requisição bem sucedida!')\n",
        "    content = source.content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEqBociYha9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "#print(soup.prettify())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlbCBSRAjK1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all('div')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmJ53uAokOl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}