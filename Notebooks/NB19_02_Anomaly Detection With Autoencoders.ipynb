{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB19_02_Anomaly Detection With Autoencoders.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPuYPWNr0scQFYHVkL3Z4PM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/DSWP/blob/master/Notebooks/NB19_02_Anomaly%20Detection%20With%20Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5j-iie_igdn"
      },
      "source": [
        "# Anomaly Detection with Autoencoders\n",
        "\n",
        "* Quando você vê um gato, você sabe que é um gato. Na terminologia da Rede Neural Artificial, é como se nossos cérebros tivessem sido treinados inúmeras vezes para distinguir um gato de um cachorro. Inspirada nas redes de um cérebro, uma RNA tem muitas camadas e neurônios com unidades de processamento simples. Um modelo de RNA treina nas imagens de gatos e cães (o valor de entrada X) e no rótulo/target “gato” e “cachorro” (o valor alvo Y). Assim, ele pode prever o “gato” (o valor Y) quando dada a imagem de um gato (os valores X).\n",
        "* Um **autoencoder é um tipo especial de rede neural que copia os valores de entrada para os valores de saída**. Não requer a variável de destino como o Y convencional, portanto, é categorizado como **aprendizado NÃO supervisionado**.\n",
        "* Em **Autoencoder, o número de neurônios das camadas de entrada e saída corresponde ao número de variáveis**, e o **número de neurônios das camadas ocultas é sempre menor do que o das camadas externas**.\n",
        "* **Não estamos muito interessados na camada de saída. Estamos interessados na camada escondida**.\n",
        "    * Se o número de neurônios nas camadas escondidas **for menor** que o número de neurônios das camadas de entrada --> as camadas escondidas extrairão as informações essenciais dos valores de entrada. \n",
        "    * Esta condição **força as camadas escondidas a aprender a maioria dos padrões dos dados e ignorar os “ruídos”**. \n",
        "        * Portanto, em um modelo de autoencoder, **as camadas escondidas devem ter menos dimensões do que as das camadas de entrada ou saída**. \n",
        "        * Se o número de neurônios nas camadas escondidas for maior que o das camadas de entrada, a rede neural terá capacidade demais para aprender os dados. Em um caso extremo, ele poderia simplesmente copiar a entrada para os valores de saída, incluindo ruídos, sem extrair nenhuma informação essencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IgmPZJoi7jt"
      },
      "source": [
        "### Referências\n",
        "* https://towardsdatascience.com/anomaly-detection-with-pyod-b523fc47db9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXLFV_LFkLj_"
      },
      "source": [
        "### Identificar outliers (Anomaly Detection)\n",
        "* Uma vez que os padrões principais são identificados, os outliers são revelados;\n",
        "* Curiosamente, durante **o processo de redução da dimensionalidade, outliers são identificados. Podemos dizer que a detecção de outliers é um subproduto da redução de dimensão**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rZqJarLki3a"
      },
      "source": [
        "## Porque autoencoders?\n",
        "* Já existem muitas ferramentas úteis, como Análise de Componentes Principais (PCA) para detectar outliers, por que precisamos dos autoencoders? Lembre-se de que o PCA usa álgebra linear para transformar;\n",
        "* Em contraste, as técnicas de autoencoder podem realizar transformações não lineares com sua função de ativação não linear e múltiplas camadas. É mais eficiente treinar várias camadas com um autoencoder, em vez de treinar uma grande transformação com PCA. As técnicas de autoencoder, portanto, mostram seus méritos quando os problemas de dados são complexos e não lineares por natureza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv4nSq6NlRHr"
      },
      "source": [
        "### Exemplo\n",
        "* Vamos gerar 25 variáveis, 500 observações e dez por cento de outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "himUG9v8lxSH"
      },
      "source": [
        "!pip install pyod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAaP_zVgrnsp"
      },
      "source": [
        "### Carregar as principais libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJP3GAPRid0z"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "from pyod.utils.data import generate_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rmfj2LnljJ0"
      },
      "source": [
        "perc_outliers = 0.1  # percentual de outliers que queremos gerar\n",
        "n_treinamento = 500  # número de pontos/observações para treinamento que serão geradas\n",
        "n_teste = 500  # número de pontos/observações para teste que serão geradas\n",
        "n_features = 25 # número de features\n",
        "\n",
        "X_treinamento, y_treinamento, X_teste, y_teste = generate_data(n_train = n_treinamento, \n",
        "                                                               n_test = n_teste, \n",
        "                                                               n_features = n_features, \n",
        "                                                               contamination = perc_outliers,                                                               \n",
        "                                                               random_state = 20111974)\n",
        "\n",
        "X_treinamento = pd.DataFrame(X_treinamento)\n",
        "X_teste = pd.DataFrame(X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKwdczdJVNct"
      },
      "source": [
        "X_treinamento.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXMh2hdgmF5A"
      },
      "source": [
        "**É boa prática sempre padronizar as preditoras**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdJLMbDLWFgN"
      },
      "source": [
        "# X_treinamento antes da transformação StandardScaler():\n",
        "X_treinamento.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ28_AjymJDx"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm2acLoBV3wx"
      },
      "source": [
        "X_treinamento = ss.fit_transform(X_treinamento)\n",
        "X_treinamento = pd.DataFrame(X_treinamento)\n",
        "X_treinamento.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee_v9QWaV5ko"
      },
      "source": [
        "X_teste = ss.fit_transform(X_teste)\n",
        "X_teste = pd.DataFrame(X_teste)\n",
        "X_teste.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ViTRZ7XmO2j"
      },
      "source": [
        "Para lhe dar uma boa noção de como os dados se parecem, vamos usar PCA para mostrar os dados usando 2 componentes principais:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4lXL_7mThk"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(2) # Número de componentes principais\n",
        "\n",
        "X_pca = pca.fit_transform(X_treinamento)\n",
        "X_pca = pd.DataFrame(X_pca)\n",
        "X_pca.columns=['PC1','PC2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kItbfcU4WsUM"
      },
      "source": [
        "# Gráfico\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.scatter(X_treinamento[0], X_treinamento[1], c = y_treinamento, alpha = 0.8)\n",
        "plt.title('Scatter plot')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbSjrDoAmYyI"
      },
      "source": [
        "**Comentários**: Os pontos roxos agrupados são as observações “normais” e os pontos amarelos são os outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IqujUyjmhMd"
      },
      "source": [
        "### Especificação do modelo\n",
        "* A seguir, 3 sugestões de modelos:\n",
        "    * **Modelo 1**: [$N_{I} = 25, N_{H_{1}} = 2, N_{H_{2}} = 2, N_{O}= 25$] --> $N_{I} = N_{O}$\n",
        "    * **Modelo 2**: [$N_{I} = 25, N_{H_{1}} = 10, N_{H_{2}} = 2, N_{H_{3}} = 10, N_{O}= 25$]  --> $N_{I} = N_{O}$;\n",
        "    * **Modelo 3**: [$N_{I} = 25, N_{H_{1}} = 15, N_{H_{2}} = 10, N_{H_{3}} = 2, N_{H_{4}} = 10, N_{H_{5}} = 15, N_{O}= 25$]  --> $N_{I} = N_{O}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF5ahxuHoBxq"
      },
      "source": [
        "### Steps para construção dos modelos:\n",
        "* Step 1 — Construir o modelo\n",
        "* Step 2 — Determinar o ponto de corte\n",
        "* Step 3 — Estatísticas e resumo para cada cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpqwnLbsm8s3"
      },
      "source": [
        "## Modelo 1: [$N_{I} = 25, N_{H_{1}} = 2, N_{H_{2}} = 2, N_{O}= 25$]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRogMP2YnAX9"
      },
      "source": [
        "### Step 1: Construir o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApY8LC8Om99g"
      },
      "source": [
        "ml_modelo1 = AutoEncoder(hidden_neurons = [25, 4, 4, 25], epochs = 100)\n",
        "ml_modelo1.fit(X_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO9NwQognFR-"
      },
      "source": [
        "### Step 2: Determinar o ponto de corte\n",
        "* Vamos aplicar o modelo treinado ml_modelo1 para prever o score de anomalia para cada observação nos dados de teste. \n",
        "\n",
        "* Como definimos/identificamos um outlier? \n",
        "    * Um outlier é um ponto que está distante de outros pontos. Então o score de anomalia é definida pela distância. A função PyOD.decision_function() calcula a distância ou o score de anomalia para cada ponto dos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0NHpyzBnSeY"
      },
      "source": [
        "y_treinamento_scores = ml_modelo1.decision_scores_  \n",
        "y_treinamento_scores[:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqPWZgJ4asQ2"
      },
      "source": [
        "# Estimar o score de anomalia:\n",
        "y_teste_scores = ml_modelo1.decision_function(X_teste)  # score dos outliers\n",
        "y_teste_scores = pd.Series(y_teste_scores)\n",
        "\n",
        "# Gráfico\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(y_teste_scores, bins = 'auto')  \n",
        "plt.title(\"Histograma para o modelo ml_modelo1 - Anomaly Scores\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCNPpDQSnVGc"
      },
      "source": [
        "No histograma acima, veremos que os scores altos correspondem à frequência baixa - a evidência de outliers. Portanto, definimos o ponto de corte = 2.5 --> qualquer observação com score de anomalia > 2.5 será considerado um outlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycKRRzYOnZPw"
      },
      "source": [
        "### Step 3: Estatísticas e resumo para cada cluster\n",
        "* Vamos atribuir essas observações com score de anomalia < 2.5 ao cluster 'Normal' e ao cluster 'Outlier' para aqueles acima de 2.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWcq5xH3yYGK"
      },
      "source": [
        "outlier_cut_point = 2.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ztdqPOKnhrh"
      },
      "source": [
        "df_teste = X_teste.copy()\n",
        "df_teste['score'] = y_teste_scores\n",
        "df_teste['cluster'] = np.where(df_teste['score'] < outlier_cut_point, 'Normal', 'Outlier')\n",
        "df_teste['cluster'].value_counts()\n",
        "\n",
        "df_teste.groupby('cluster').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSi8Lj6D2aXR"
      },
      "source": [
        "* Quantos outliers foram identificados?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-f44wGde7xh"
      },
      "source": [
        "df_teste['cluster'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuMI_FfWnkoR"
      },
      "source": [
        "O output acima mostra os valores médios das variáveis em cada cluster. Os valores do cluster ‘1’ (o cluster anormal) são bastante diferentes daqueles do cluster ‘0’ (o cluster normal). Os scorees de anomalia mostram a distância média dessas observações às outras. Um score alto significa que a observação está longe do \"normal\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgjcRStgfOXi"
      },
      "source": [
        "Observe acima que o modelo ml_modelo3 identifica 50 outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPiyGykEno3X"
      },
      "source": [
        "## Modelo 2: [$N_{I} = 25, N_{H_{1}} = 10, N_{H_{2}} = 2, N_{H_{3}} = 10, N_{O}= 25$]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O-DrNSunsd_"
      },
      "source": [
        "### Step 1&2: Construir o modelo & Determinar o ponto de corte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhKAn9RSnv1T"
      },
      "source": [
        "ml_modelo2 = AutoEncoder(hidden_neurons = [25, 10, 2, 10, 25])\n",
        "ml_modelo2.fit(X_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaUckwdEd-Ig"
      },
      "source": [
        "# Estimar os scores de anomalia\n",
        "y_teste_scores = ml_modelo2.decision_function(X_teste)  \n",
        "y_teste_scores = pd.Series(y_teste_scores)\n",
        "y_teste_scores[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6-WKCsZd_rU"
      },
      "source": [
        "# Histograma\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(y_teste_scores, bins = 'auto')  \n",
        "plt.title(\"Histograma para o modelo ml_modelo2 - Anomaly Scores\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MN1uJ_Enzno"
      },
      "source": [
        "Novamente, vamos usar um histograma para contar a frequência pdo score de anomalia. Novamente, o ponto de corte será 2.5. Desta forma, qualquer score de anomalia > 2.5 será considerado outlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjgX5g0sn2Hg"
      },
      "source": [
        "### Step 3: Estatísticas e resumo para cada cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p0K_4Q-zY_6"
      },
      "source": [
        "outlier_cut_point = 2.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mepbfQUOpPOA"
      },
      "source": [
        "df_teste = X_teste.copy()\n",
        "df_teste['score'] = y_teste_scores\n",
        "df_teste['cluster'] = np.where(df_teste['score'] < outlier_cut_point, 'Normal', 'Outlier')\n",
        "df_teste['cluster'].value_counts()\n",
        "df_teste.groupby('cluster').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwQgPJFYpNlI"
      },
      "source": [
        "A estatística resumida do Cluster '1' (o cluster anormal) é diferente das do Cluster '0' (o cluster normal). As observações no cluster 'Outlier' são outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUtbsxJa4WrB"
      },
      "source": [
        "### Outliers identificados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb4dExFwe5Nr"
      },
      "source": [
        "df_teste['cluster'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs76q0AhfKn_"
      },
      "source": [
        "Observe acima que o modelo ml_modelo2 identifica 50 outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3eZyukjpfh6"
      },
      "source": [
        "## Modelo 3: [$N_{I} = 25, N_{H_{1}} = 15, N_{H_{2}} = 10, N_{H_{3}} = 2, N_{H_{4}} = 10, N_{H_{5}} = 15, N_{O}= 25$]\n",
        "* Steps 1, 2 & 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhkfHbAYZtAz"
      },
      "source": [
        "### Step 1: Construir o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n46Wvx_plbx"
      },
      "source": [
        "ml_modelo3 = AutoEncoder(hidden_neurons = [25, 15, 10, 2, 10,15, 25])\n",
        "ml_modelo3.fit(X_treinamento)\n",
        "\n",
        "# Estimar o score de anomalia:\n",
        "y_teste_scores = ml_modelo3.decision_function(X_teste)  \n",
        "y_teste_scores = pd.Series(y_teste_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAu9C3N1Z3gc"
      },
      "source": [
        "### Step 2: Determinar o ponto de corte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3iMcAWfZ7KW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(y_teste_scores, bins='auto')  \n",
        "plt.title(\"Histograma para o modelo ml_modelo3 - Anomaly Scores\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQLujtNpzcDv"
      },
      "source": [
        "outlier_cut_point = 2.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LELyjq1Sel3g"
      },
      "source": [
        "df_teste = X_teste.copy()\n",
        "df_teste['score'] = y_teste_scores\n",
        "df_teste['cluster'] = np.where(df_teste['score'] < outlier_cut_point, 'Normal', 'Outlier')\n",
        "df_teste['cluster'].value_counts()\n",
        "df_teste.groupby('cluster').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDyME2T_fDpk"
      },
      "source": [
        "Observe acima que o modelo ml_modelo3 identifica 50 outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmPG8bZCZ-gj"
      },
      "source": [
        "### Step 3: Estatísticas e resumo para cada cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1y7531JZ-qy"
      },
      "source": [
        "df_teste.groupby('cluster').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAtwrd5bps44"
      },
      "source": [
        "Como no Módulo 1 e 2, a estatística resumida do Cluster '1' (o cluster anormal) é diferente das do Cluster '0' (o cluster normal). As observações no cluster 'Outlier' são outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmX3_XjSpzNa"
      },
      "source": [
        "## Estabilidade do Modelo final\n",
        "* Desenvolvemos 3 modelos para detectar outliers (anomaly detection). Mas porque desenvolvemos 3 modelos?\n",
        "\n",
        "**Resposta**: Sabemos que as **técnicas de aprendizagem NÃO supervisionadas são poderosas na detecção de outliers. No entanto, estão sujeitas a overfitting e resultados instáveis**. A solução é treinar vários modelos e, em seguida, agregar os scores. No processo de agregação, você ainda seguirá as etapas 2 e 3 como antes. Existem quatro métodos para agregar o resultado conforme abaixo:\n",
        "* Maximum of Maximum (MOM)\n",
        "* Average of Maximum (AOM)\n",
        "* Maximum of Average (MOA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqeDJEj1qeMF"
      },
      "source": [
        "Primeiro, colocarei todas as previsões dos três modelos acima em um quadro de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxqvT2roqgcN"
      },
      "source": [
        "from pyod.models.combination import aom, moa, average, maximization\n",
        "\n",
        "# Armazena todas as predições em dataframes:\n",
        "treinamento_scores = pd.DataFrame({'ml_modelo1': ml_modelo1.decision_scores_,\n",
        "                             'ml_modelo2': ml_modelo2.decision_scores_,\n",
        "                             'ml_modelo3': ml_modelo3.decision_scores_\n",
        "                            })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHo5AFgVafWz"
      },
      "source": [
        "teste_scores  = pd.DataFrame({'ml_modelo1': ml_modelo1.decision_function(X_teste),\n",
        "                             'ml_modelo2': ml_modelo2.decision_function(X_teste),\n",
        "                             'ml_modelo3': ml_modelo3.decision_function(X_teste) \n",
        "                            })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCwaEZpgqkFL"
      },
      "source": [
        "Ao agregar as pontuações, você precisa padronizar as pontuações de diferentes modelos. Não fizemos a padronização antes? Lembre-se de que a padronização antes era padronizar as variáveis de entrada. Aqui está a padronização para as pontuações de saída."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz9VKzCSqmdC"
      },
      "source": [
        "treinamento_scores_norm = ss.fit_transform(treinamento_scores)\n",
        "teste_scores_norm = ss.fit_transform(teste_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj6D4qSLqodr"
      },
      "source": [
        "### Modelo - Average Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxOKwNH_quaS"
      },
      "source": [
        "### Step 2 — Determinar o ponto de corte\n",
        "* A função average () calcula a média dos scores de outliers de vários modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "die8Eg7Rq2Xa"
      },
      "source": [
        "# Combination by average\n",
        "y_AOM = average(teste_scores_norm)\n",
        "             \n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(y_AOM, bins='auto')\n",
        "plt.title(\"Combination by average\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaOtuYWiq4pE"
      },
      "source": [
        "Parece que podemos identificar outlires quando anomaly score > 0. Nosso exemplo identifica 50 outliers (não mostrados)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrx5pv4IzeaB"
      },
      "source": [
        "outlier_cut_point = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb7zUoYTq8zt"
      },
      "source": [
        "df_teste = pd.DataFrame(X_teste)\n",
        "df_teste['y_AOM_score'] = y_AOM\n",
        "df_teste['y_AOM_cluster'] = np.where(df_teste['y_AOM_score'] < outlier_cut_point, 'Normal', 'Outlier')\n",
        "df_teste['y_AOM_cluster'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC6RAqhrq-xe"
      },
      "source": [
        "### Step 3 — Estatísticas e resumo para cada cluster\n",
        "* O código a seguir e os resultados mostram que as estatísticas resumidas do Cluster '1' (o cluster anormal) são diferentes daquelas do Cluster '0' (o cluster normal). As observações no cluster 'Outlier' são outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6KYogs7g07t"
      },
      "source": [
        "df_teste.groupby('y_AOM_cluster').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T64VHMiYrHeT"
      },
      "source": [
        "### Modelo - Maximum of Maximum Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d61rg_7rLH5"
      },
      "source": [
        "#### Step 2 — Determinar o ponto de corte\n",
        "Obtenha as pontuações atípicas de vários modelos calculando o máximo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zx49nDSrQJz"
      },
      "source": [
        "y_MOM = maximization(teste_scores_norm)\n",
        "             \n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.hist(y_MOM, bins = 'auto')\n",
        "plt.title(\"Combination by max\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-WjagUArTJp"
      },
      "source": [
        "Da mesma forma, parece que podemos identificar aqueles> = 0,0 como outliers. Existem 50 outliers (não mostrados)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCvLzSJU7BYu"
      },
      "source": [
        "outlier_cut_point = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX9mcurjrVkX"
      },
      "source": [
        "df_teste = pd.DataFrame(X_teste)\n",
        "df_teste['y_MOM_score'] = y_MOM\n",
        "df_teste['y_MOM_cluster'] = np.where(df_teste['y_MOM_score'] < outlier_cut_point, 'Normal', 'Outlier')\n",
        "df_teste['y_MOM_cluster'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP8ro3f7rXRO"
      },
      "source": [
        "### Step 3 — Estatísticas e resumo para cada cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSnWN8M_rZis"
      },
      "source": [
        "df_teste.groupby('y_MOM_cluster').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BzqiBXsrhfr"
      },
      "source": [
        "### Conclusões\n",
        "* O procedimento para aplicar os algoritmos parece muito viável, não é? Mais uma vez, deixe-me lembrá-lo de que variáveis criteriosas e cuidadosamente elaboradas são a base para o sucesso de um modelo de detecção de anomalias. Muitas aplicações industriais requerem engenharia de recursos complexos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdZtqN1dBF31"
      },
      "source": [
        "## Exercício\n",
        "1. Analisar o dataframe creditcard.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAhBhNLLrqOs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}