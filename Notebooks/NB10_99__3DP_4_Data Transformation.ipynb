{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/massaoHigaskino/DSWP/blob/2019_10_26_lecture/Notebooks/NB10_99__3DP_4_Data%20Transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNiuYCCxGe8v",
        "colab_type": "text"
      },
      "source": [
        "# **Melhorias da sessão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TdSY74U0XS9",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **Referências**\n",
        "* [Why, How and When to Scale your Features](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)\n",
        "* [Demonstrating the different strategies of KBinsDiscretizer](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py);\n",
        "* [Why do we need feature scaling in Machine Learning and how to do it using SciKit Learn?](https://medium.com/@contactsunny/why-do-we-need-feature-scaling-in-machine-learning-and-how-to-do-it-using-scikit-learn-d8314206fe73)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZsS2ntmGgFi",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **Agenda**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnd-3xouAPfU",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **3DP_DATA TRANSFORMATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DGifbWSmW3",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **Machine Learning com Python (Scikit-Learn)**\n",
        "\n",
        "![Scikit-Learn](https://github.com/MathMachado/Python_RFB/blob/master/Material/scikit-learn-1.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-chlATnKSza",
        "colab_type": "text"
      },
      "source": [
        "## Carregar as bibliotecas (genéricas) Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQGVQB18-tM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install category_encoders\n",
        "!pip install update\n",
        "!pip install bamboolib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJxrZckYxk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#from pandas import Series, DataFrame\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "import category_encoders as ce # library para aplicação do WOE - Weight Of Evidence para avaliar importância dos atributos\n",
        "\n",
        "# remove warnings to keep notebook clean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0fuDyI8_UPf",
        "colab_type": "text"
      },
      "source": [
        "## Carregar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oRWtarakgMY",
        "colab_type": "text"
      },
      "source": [
        "### Dataframe gerado aleatoriamente - variáveis com distribuição Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXPXo3k0VDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N= 1000\n",
        "df_A1 = pd.DataFrame({\n",
        "    'coluna1': np.random.normal(0, 2, N),\n",
        "    'coluna2': np.random.normal(50, 3, N),\n",
        "    'coluna3': np.random.normal(-5, 5, N),\n",
        "    'coluna4': np.random.normal(-10, 10, N)\n",
        "})\n",
        "df_A1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUqjo5QcQH99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N= 1000\n",
        "df_A1 = pd.DataFrame({\n",
        "    'coluna1': np.random.normal(0, 2, N),\n",
        "    'coluna2': np.random.normal(50, 3, N),\n",
        "    'coluna3': np.random.exponential(1, N),\n",
        "    'coluna4': np.random.normal(-10, 10, N)\n",
        "})\n",
        "df_A1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5ablqHqmsyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8MZNLbUkp8R",
        "colab_type": "text"
      },
      "source": [
        "### Dataframe gerado aleatoriamente 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR-fDDujcTup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "classification_data, classification_class = make_classification(n_samples=N, n_features=4, n_informative=3, n_redundant=1, n_classes=3)\n",
        "\n",
        "df_A2 = pd.DataFrame({'coluna1':classification_data[:,0],\n",
        "                                  'coluna2':classification_data[:,1],\n",
        "                                  'coluna3':classification_data[:,2],\n",
        "                                  'coluna4':classification_data[:,3],\n",
        "                                  'coluna5':classification_class})\n",
        "df_A2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_jKNcuQKhl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0v0uXFRl-yG",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **Transformações**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkzTO0fdz93b",
        "colab_type": "text"
      },
      "source": [
        "## StandardScaler\n",
        "* Assume que os dados (as colunas a serem transformadas) são normalmente distribuidos ;\n",
        "* Se os dados não possuem distribuição Normal, então esta não é uma boa transformação a se aplicar.\n",
        "\n",
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/pp4.PNG?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1UOOWeQ0R_Y",
        "colab_type": "text"
      },
      "source": [
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Lzx3xN6wpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cPq_7Vu2HCS",
        "colab_type": "text"
      },
      "source": [
        "Histograma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYW9WwBC3hd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(df_A1['coluna3'], color = 'blue', edgecolor = 'black', bins = int(180/5))\n",
        "\n",
        "# Adiciona títulos e labels\n",
        "plt.title('Histograma da Variável3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrgxkESc-Uaq",
        "colab_type": "text"
      },
      "source": [
        "Considere o gráfico a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7dHTF1W-Xsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMS72n14-hDO",
        "colab_type": "text"
      },
      "source": [
        "Qual a interpretação para esse gráfico?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEkAqlZg-p0v",
        "colab_type": "text"
      },
      "source": [
        "A seguir, vamos aplicar a transformação StandardScaler as variáveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4u3T_BX-oc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPa4-SCt-ynX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_StandardScaler = StandardScaler().fit_transform(df_A1)\n",
        "df_A1_StandardScaler = pd.DataFrame(df_A1_StandardScaler, columns=['Coluna1','Coluna2','Coluna3', 'Coluna4'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmQp8wDO_E88",
        "colab_type": "text"
      },
      "source": [
        "Agora compare esse novo gráfico abaixo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2fTPWsm_Hq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_StandardScaler.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fuURrao_M0c",
        "colab_type": "text"
      },
      "source": [
        "Qual a conclusão?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0A9U7rs_RAT",
        "colab_type": "text"
      },
      "source": [
        "## MinMaxScaler\n",
        "* **Transformação muito popular e utilizada**.\n",
        "* Transforma os dados para o intervalo (0, 1);\n",
        "* Se StandardScaler não é aplicável, então essa transformação funciona bem.\n",
        "* Sensível aos outliers. Portanto, o ideal é que os outliers sejam tratados previamente.\n",
        "\n",
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/pp3.PNG?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0HbeuP-AU_p",
        "colab_type": "text"
      },
      "source": [
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgeLckzxAWaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_W9bTO2AbEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJRFbUpBAg5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#minmax = MinMaxScaler()\n",
        "df_A1_MinMaxScaler = MinMaxScaler().fit_transform(df_A1)\n",
        "df_A1_MinMaxScaler = pd.DataFrame(df_A1_MinMaxScaler,columns=['Coluna1','Coluna2','Coluna3', 'Coluna4'])\n",
        "df_A1_MinMaxScaler.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g8GA4LTA40U",
        "colab_type": "text"
      },
      "source": [
        "Qual a conclusão?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z6D3vfnB9Nm",
        "colab_type": "text"
      },
      "source": [
        "## RobustScaler\n",
        "* Transformação ideal para dados com outliers;\n",
        "\n",
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/pp2.PNG?raw=true\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3oyuxLeCW1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeDF7-w_CcBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLoqSKijCf2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_RobustScaler = RobustScaler().fit_transform(df_A1)\n",
        "df_A1_RobustScaler = pd.DataFrame(df_A1_RobustScaler, columns=['Coluna1','Coluna2','Coluna3', 'Coluna4'])\n",
        "df_A1_RobustScaler.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YVMgt-WEFif",
        "colab_type": "text"
      },
      "source": [
        "## Encoding Variáveis Categoricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHYvLc8T_jxQ",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Variáveis Ordinais\n",
        "* Exemplo: Variáveis com valores ordinais: Low, Medium ou High."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1BgGiGdSTcG",
        "colab_type": "text"
      },
      "source": [
        "#### Gera um dataframe como exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdVahfJAEkuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aqui vou usar a função randint - Retorna números inteiros aleatórios incluindo o número inferior e excluindo o superior.\n",
        "\n",
        "l_Idade= [np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40), np.random.randint(20, 40),\n",
        "         np.random.randint(20, 40), np.random.randint(20, 40),np.random.randint(20, 40),np.random.randint(20, 40),np.random.randint(20, 40)]\n",
        "\n",
        "l_Salario= ['Low', 'Medium', 'High']\n",
        "l_Salario2= np.random.choice(l_Salario, 10, p=[0.6, 0.3, 0.1])\n",
        "\n",
        "df_A3 = pd.DataFrame({\n",
        "    'Idade': l_Idade,\n",
        "    'Salario': l_Salario2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_15P2eUHSBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1g9pEuyHe2q",
        "colab_type": "text"
      },
      "source": [
        "Neste exemplo, vamos redefinir a variável categórical ordinal 'Salario' da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkwFuEa8HnMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A3['Salario_Cat']= df_A3.Salario.map({'Low':1,'Medium':2,'High':3})\n",
        "df_A3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlaIFiWIIPAl",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Variáveis Nominais\n",
        "* Exemplo: Variáveis com valores nominais: Sexo (Feminino, masculino).\n",
        "\n",
        "* Use One-Hot Encoding ou pd.get.dummies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNoJQbgJRoY",
        "colab_type": "text"
      },
      "source": [
        "Vamos utilizar o dataframe criado no passo anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMCoUWZOI7c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A3['Salario'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIEyBkaJeN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MwK4cUEKeK4",
        "colab_type": "text"
      },
      "source": [
        "#### Aplicar LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6VXDsHJiII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "df_A3['Salario_le'] = le.fit_transform(df_A3['Salario'])\n",
        "df_A3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgv2Zz07Kqfj",
        "colab_type": "text"
      },
      "source": [
        "#### Aplicar pd.get.dummies()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSZRIEs6K5sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummies= pd.get_dummies(df_A3['Salario'])\n",
        "df_A3= pd.concat([df_A3, dummies], axis= 1)\n",
        "df_A3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWKrLlxsMLaw",
        "colab_type": "text"
      },
      "source": [
        "O comando a seguir produz o mesmo resultado que o anterior:\n",
        "```\n",
        "df_A3= df_A3.merge(dummies, how= 'left')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwh0alhdgrE3",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **Exercícios**\n",
        "> Para cada um dos dataframes a seguir, aplique os seguintes steps:\n",
        "\n",
        "* Padronizar o nome das colunas\n",
        "    * Eliminar espaços entre os nomes das colunas;\n",
        "    * Eliminar caracteres especiais dos nomes das colunas;\n",
        "    * Renomear as colunas com lower() (ou upper());\n",
        "* Aplicar a trasformação StandardScaler e MinMaxScaler em cada uma das colunas do dataframe;\n",
        "* DataViz - Mostrar a distribuição das colunas antes e depois das transformações num mesmo gráfico para que sejamos capazes de comparar o comportamento das colunas;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caFkC6oCmUKK",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 1 - Breast Cancer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOM-Z9zmf-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X= cancer['data']\n",
        "y= cancer['target']\n",
        "\n",
        "df_A1_cancer = pd.DataFrame(np.c_[X, y], columns= np.append(cancer['feature_names'], ['target']))\n",
        "df_A1_cancer['target'] = df_A1_cancer['target'].map({0: 'malign', 1: 'benign'})\n",
        "df_A1_cancer.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qruqUDqnvMc",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 2 - Boston Housing Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trxK8YXNnsam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "boston = load_boston()\n",
        "X= boston['data']\n",
        "y= boston['target']\n",
        "\n",
        "df_A1_boston = pd.DataFrame(np.c_[X, y], columns= np.append(boston['feature_names'], ['target']))\n",
        "df_A1_boston.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSTKrd992LtI",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 3 - Iris\n",
        "* [Aqui](https://en.wikipedia.org/wiki/Iris_flower_data_set) você obterá mais informações sobre o dataframe iris. Confira."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mThqvGGr2Vuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X= iris['data']\n",
        "y= iris['target']\n",
        "\n",
        "df_iris = pd.DataFrame(np.c_[X, y], columns= np.append(iris['feature_names'], ['target']))\n",
        "df_iris['target2'] = df_iris['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
        "df_iris.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU5FaJhdYblP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_iris.columns = [c.replace(' ', '_') for c in df_iris.columns]\n",
        "df_iris.columns = [c.replace('_(cm)', '') for c in df_iris.columns]\n",
        "df_iris.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9DPAakJZQHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_iris.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYYmVq68Y8bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_iris_MinMaxScaler = MinMaxScaler().fit_transform(df_iris[['sepal_length','sepal_width','petal_length', 'petal_width']])\n",
        "df_iris_MinMaxScaler = pd.DataFrame(df_iris_MinMaxScaler, columns=['sepal_length','sepal_width','petal_length', 'petal_width'])\n",
        "df_iris_MinMaxScaler.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am_mgOPcaPBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.get_dummies(pd.DataFrame(df_A1_iris['target']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUThnRMoT_i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_iris.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuN0ZovZXW4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list comprehension\n",
        "df_A1_iris_rename = df_A1_iris.copy()\n",
        "df_A1_iris_rename.columns = [col.replace(' ','_').replace('_length_(cm)','_l').replace('_width_(cm)','_w') for col in df_A1_iris.columns]\n",
        "df_A1_iris_rename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC_NzaFZTtOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# manual\n",
        "df_A1_iris_2 = df_A1_iris.rename(columns={'sepal length (cm)':'sepal_l', 'sepal width (cm)':'sepal_w', 'petal length (cm)':'petal_l',\n",
        "       'petal width (cm)':'petal_w'})\n",
        "df_A1_iris_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBCDMhnUUoEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_iris_2_MinMaxScaler = MinMaxScaler().fit_transform(df_A1_iris_2[['sepal_l', 'sepal_w', 'petal_l','petal_w']])\n",
        "df_A1_iris_2_MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttMZ7uqYWUZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_iris_2_MinMaxScaler_pd = pd.DataFrame(df_A1_iris_2_MinMaxScaler,columns=['sepal_l', 'sepal_w', 'petal_l','petal_w'])\n",
        "df_A1_iris_2_MinMaxScaler_pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOP1wUKDVCK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_iris_2.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKDOScokVH20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_A1_iris_2_MinMaxScaler_pd.plot.kde()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzu0Dz33c8ds",
        "colab_type": "text"
      },
      "source": [
        "## Exercícios 4 - Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ahBZmqc_-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "X= diabetes['data']\n",
        "y= diabetes['target']\n",
        "\n",
        "df_A1_diabetes = pd.DataFrame(np.c_[X, y], columns= np.append(diabetes['feature_names'], ['target']))\n",
        "df_A1_diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5fDp1Ib_Dg8",
        "colab_type": "text"
      },
      "source": [
        "# WOE - Weight Of Evidence\n",
        "* As vantagens da transformação WOE são\n",
        "    * Lida bem com NaN's;\n",
        "    * Lida bem com outliers;\n",
        "    * A transformação é baseada no valor logarítmico das distribuições.\n",
        "    * Usando a técnica de binning apropriada, pode estabelecer uma relação monotônica (aumentar ou diminuir) entre a variável dependente e independente."
      ]
    }
  ]
}