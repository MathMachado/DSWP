{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB22_Pipelines.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/DSWP/blob/master/Notebooks/NB22_Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnd-3xouAPfU"
      },
      "source": [
        "# PIPELINES\n",
        "* Nesta seção vamos estudar Pipelines.\n",
        "* Pipelines consitem de uma combinação de transformadores (Data Preparation) e estimadores;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TdSY74U0XS9"
      },
      "source": [
        "## Leitura Recomendada:\n",
        "* [Why, How and When to Scale your Features](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)\n",
        "* [Demonstrating the different strategies of KBinsDiscretizer](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py);\n",
        "* [Why do we need feature scaling in Machine Learning and how to do it using SciKit Learn?](https://medium.com/@contactsunny/why-do-we-need-feature-scaling-in-machine-learning-and-how-to-do-it-using-scikit-learn-d8314206fe73)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DGifbWSmW3"
      },
      "source": [
        "## Machine Learning com Python (Scikit-Learn)\n",
        "\n",
        "![Scikit-Learn](https://github.com/MathMachado/Materials/blob/master/scikit-learn-1.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLDoLK5xs-_v"
      },
      "source": [
        "## Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuENIuJtj6_g"
      },
      "source": [
        "A seguir, as variáveis/atributos do dataframe:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Th-GN_YkBo0"
      },
      "source": [
        "* Dicionário de dados do dataframe Titanic:\n",
        "    * **PassengerID**: ID do passageiro;\n",
        "    * **Survived**: Indicador, sendo 1= Passageiro sobreviveu e 0= Passageiro morreu;\n",
        "    * **Pclass**: Classe em que o passageiro viaja (1 classe, 2 classe, 3 classe, etc);\n",
        "    * **Age**: Idade do Passageiro;\n",
        "    * **SibSp**: Número de parentes a bordo (esposa, irmãos, pais e etc);\n",
        "    * **Parch**: Número de pais/crianças a bordo;\n",
        "    * **Fare**: Valor pago pela viagem;\n",
        "    * **Cabin**: Cabine do Passageiro;\n",
        "    * **Embarked**: A porta pelo qual o Passageiro embarcou.\n",
        "    * **Name**: Nome do Passageiro;\n",
        "    * **Sex**: Sexo do Passageiro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-chlATnKSza"
      },
      "source": [
        "## Carregar as bibliotecas (genéricas) Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJxrZckYxk6"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "# remove warnings to keep notebook clean\n",
        "import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wq6Y3eFZCTE"
      },
      "source": [
        "## Carregar Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9QWCCrLZFfW"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/MathMachado/DataFrames/master/df_Tratado.csv'\n",
        "url2 = 'https://raw.githubusercontent.com/MathMachado/DataFrames/master/Titanic_Original.csv'\n",
        "\n",
        "# Carrega os dataframes de treinamento e teste e define 'PassengerId' como chave\n",
        "df = pd.read_csv(url, index_col = 'PassengerId')\n",
        "df_original = pd.read_csv(url2, index_col = 'PassengerId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zkeZgHYAIHS"
      },
      "source": [
        "A seguir, nosso Dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97JLzdV1v8Mc"
      },
      "source": [
        "df_original.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wReGB9zXAL2B"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcclsETvorXS"
      },
      "source": [
        "df.columns = [cols.lower() for cols in df.columns]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHOul6L8uWPx"
      },
      "source": [
        "df2 = df.copy()\n",
        "df2 = df.drop(columns= ['survived2'], axis= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biEUjwD8Ip_r"
      },
      "source": [
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G-A1PryavVE"
      },
      "source": [
        "def mostra_missing_value(df):\n",
        "    total = df.isnull().sum().sort_values(ascending=False)\n",
        "    percent = 100*round((df.isnull().sum()/df.isnull().count()).sort_values(ascending=False),2)\n",
        "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percentual'])\n",
        "    print(missing_data.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NeqVpTMaNFo"
      },
      "source": [
        "mostra_missing_value(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwq46X9da132"
      },
      "source": [
        "Nenhum NaN porque fizemos todo o tratamento no projeto Titanic. Vamos adiante..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3pWRb6IOTt"
      },
      "source": [
        "**OBSERVAÇÃO**: Não há nenhum tratamento a ser feito neste capítulo 3DP porque o fizemos antes. Ok?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDG7-VKoOos9"
      },
      "source": [
        "# Pipelines\n",
        "* O Pipeline engloba as fases: 3DP + 4M + 5MSE de uma única vez!\n",
        "\n",
        "![CRISP-DM](https://github.com/MathMachado/Materials/blob/master/CRISP-DM.png?raw=true)\n",
        "[Fonte](https://www.sv-europe.com/crisp-dm-methodology/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE_xQPdZOyz8"
      },
      "source": [
        "df3 = df2.copy()\n",
        "df3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpZOkXK-CFcj"
      },
      "source": [
        "Definindo as variáveis numéricas e categóricas que serão transformadas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T68i5MZacNLq"
      },
      "source": [
        "# Listas das variáveis numéricas e objetos\n",
        "features_numericas = ['fare','seat','age2','age3', 'age_inf','age2_outlier_zs',\n",
        "                   'age3_outlier_zs','age_inf_outlier_zs',\n",
        "                   'fare_outlier_zs','age2_outlier_iqr',\n",
        "                   'age3_outlier_iqr','age_inf_outlier_iqr',\n",
        "                   'fare_outlier_iqr']\n",
        "\n",
        "features_categoricas = ['sex','deck','embarked','age_category']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnfxY9S2luvC"
      },
      "source": [
        "## Transformers\n",
        "* OneHotEncoder faz a mesma coisa que pd.get_dummies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp4iglH1by4T"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8h6DWZCb2Cx"
      },
      "source": [
        "numeric_transformer_ss = Pipeline(steps = [('StandardScaler', StandardScaler())])\n",
        "#numeric_transformer_mms = Pipeline(steps = [('MinMaxScaler', MinMaxScaler())])\n",
        "categorical_transformer = Pipeline(steps = [('onehot', OneHotEncoder(handle_unknown = 'ignore'))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbS21rW8d9kR"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, features_numericas),\n",
        "        ('cat', categorical_transformer, features_categoricas)])\n",
        "\n",
        "preprocessor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDnNH1Yfd132"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Adicionar o Classificador (RandomForestClassifier) ao Pipeline:\n",
        "rf = Pipeline([\n",
        "               ('preprocessor', preprocessor), \n",
        "               ('reduce_dim', PCA()),\n",
        "               ('classifier', RandomForestClassifier())\n",
        "               ]\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXG2lbFNbXTc"
      },
      "source": [
        "Definindo as amostras de treinamento e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAhTz9y7e226"
      },
      "source": [
        "X = df3[df3['survived'].notna()]\n",
        "X = X.drop(columns = ['survived'], axis= 1)\n",
        "\n",
        "y = df3[df3['survived'].notna()]\n",
        "y = y['survived']\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnmpvFO3zjDO"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHE_GKjAbaYE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbnhBANxGZXu"
      },
      "source": [
        "X_treinamento.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCJZSx7PGfQU"
      },
      "source": [
        "Observe que as colunas/variáveis de X_treinamento não estão transformadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIs6UAPUl1VZ"
      },
      "source": [
        "## 4M - Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P3vFXQmeFKH"
      },
      "source": [
        "rf.fit(X_treinamento, y_treinamento)\n",
        "print(\"Training: model score: %.3f\" % rf.score(X_treinamento, y_treinamento))\n",
        "print(\"Test....: model score: %.3f\" % rf.score(X_teste, y_teste))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIEzZ-Qofjvz"
      },
      "source": [
        "y_pred = rf.predict(X_teste)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmXiW5IbEH7R"
      },
      "source": [
        "## 5MSE - Model Selection and Evaluation\n",
        "* Aqui vamos usar Ensemble (vários classificadores)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDJ9l1OMftl2"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn.linear_model import RidgeClassifier, PassiveAggressiveClassifier, SGDClassifier, LogisticRegressionCV, LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier # Multi-Layer Perceptron Classifier\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.linear_model import Perceptron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWtP3XKjl9Fw"
      },
      "source": [
        "Definir lista de todos os classificadores que desejo aplicar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99LBeLVvgMXS"
      },
      "source": [
        "classifiers = [KNeighborsClassifier(5),\n",
        "               SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
        "               NuSVC(probability=True),\n",
        "               DecisionTreeClassifier(),\n",
        "               RandomForestClassifier(),\n",
        "               GradientBoostingClassifier(),\n",
        "               RidgeClassifier(),\n",
        "               AdaBoostClassifier(),\n",
        "               GaussianNB(),\n",
        "               BernoulliNB(),\n",
        "               PassiveAggressiveClassifier(),\n",
        "               LinearSVC(),\n",
        "               SGDClassifier(loss='log', penalty='elasticnet'),\n",
        "               LogisticRegression(),\n",
        "               NearestCentroid(),\n",
        "               Perceptron(),\n",
        "               MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000),\n",
        "               LGBMClassifier(),\n",
        "               BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5),\n",
        "               GaussianProcessClassifier(),\n",
        "               XGBClassifier(n_estimators= 2000,max_depth= 4,min_child_weight= 2,gamma=0.9,subsample=0.8,colsample_bytree=0.8,objective='reg:logistic',scale_pos_weight=1),\n",
        "               ExtraTreesClassifier(n_estimators = 750, max_features = 'sqrt', max_depth = 35,  criterion = 'entropy', random_state = 42)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boIQqAqxEXKj"
      },
      "source": [
        "for classifier in classifiers:\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor), \n",
        "                           ('reduce_dim', PCA()), \n",
        "                           ('classifier', classifier)])\n",
        "    \n",
        "    scores = cross_val_score(pipe, X_treinamento, y_treinamento, cv = 10)\n",
        "    pipe.fit(X_treinamento, y_treinamento)   \n",
        "    print(classifier)\n",
        "    print(\"Training Sample: model score: %.3f\" % pipe.score(X_treinamento, y_treinamento))\n",
        "    print(\"Test Sample....: model score: %.3f\" % pipe.score(X_teste, y_teste))\n",
        "    print(\"****************************************************************************************\\n\")\n",
        "    print(classifier, \":\", round(scores.mean(),2))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Npu_5cAmDmC"
      },
      "source": [
        "## Fine Tuning\n",
        "* A seguir, fazemos o fine tuning do XGBClassifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ_z1DsTECVB"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDRIJgYTF16T"
      },
      "source": [
        "# Adicionando o Classificador (RandomForestClassifier) ao Pipeline:\n",
        "xg = Pipeline([('preprocessor', preprocessor), \n",
        "               ('reduce_dim', PCA()), # PCA está a ser aplicado em tudo!\n",
        "               ('classifier', XGBClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFDCTQOZHJIz"
      },
      "source": [
        "Os principais parâmetros para fine tuning:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tMhQ_cMH9vW"
      },
      "source": [
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3L-zW22Mzyx"
      },
      "source": [
        "Versão simplificada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr0HwnnOLxt7"
      },
      "source": [
        "start = timeit.timeit()\n",
        "param_grid = { \n",
        "    'classifier__n_estimators': [100, 300, 500, 700, 900],\n",
        "    'classifier__max_features': ['auto', 'log2'],\n",
        "    'classifier__max_depth' : [3,5,7,9],\n",
        "    'classifier__criterion' :['entropy'],\n",
        "    'classifier__learning_rate':[0.0001, 0.001, 0.01, 0.1],\n",
        "    'classifier__gamma':[0,1,5]}\n",
        "\n",
        "CV = GridSearchCV(xg, param_grid, cv = 10, n_jobs = 50, scoring = 'accuracy', verbose = 10)\n",
        "                  \n",
        "CV.fit(X_treinamento, y_treinamento)  \n",
        "print(CV.best_params_)    \n",
        "print(CV.best_score_)\n",
        "\n",
        "end = timeit.timeit()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge64PeFA5HKp"
      },
      "source": [
        "Output do processo de fine tuning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQq-UIx14YYm"
      },
      "source": [
        "```\n",
        "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
        "[Parallel(n_jobs=50)]: Using backend LokyBackend with 50 concurrent workers.\n",
        "[Parallel(n_jobs=50)]: Done  13 tasks      | elapsed:   59.6s\n",
        "[Parallel(n_jobs=50)]: Done  28 tasks      | elapsed:  1.2min\n",
        "[Parallel(n_jobs=50)]: Done  45 tasks      | elapsed:  1.5min\n",
        "[Parallel(n_jobs=50)]: Done  62 tasks      | elapsed:  1.8min\n",
        "[Parallel(n_jobs=50)]: Done  81 tasks      | elapsed:  2.0min\n",
        "[Parallel(n_jobs=50)]: Done 100 tasks      | elapsed:  2.5min\n",
        "[Parallel(n_jobs=50)]: Done 121 tasks      | elapsed:  2.7min\n",
        "[Parallel(n_jobs=50)]: Done 142 tasks      | elapsed:  3.3min\n",
        "[Parallel(n_jobs=50)]: Done 165 tasks      | elapsed:  3.8min\n",
        "[Parallel(n_jobs=50)]: Done 188 tasks      | elapsed:  4.2min\n",
        "[Parallel(n_jobs=50)]: Done 213 tasks      | elapsed:  4.8min\n",
        "[Parallel(n_jobs=50)]: Done 238 tasks      | elapsed:  5.2min\n",
        "[Parallel(n_jobs=50)]: Done 265 tasks      | elapsed:  6.3min\n",
        "[Parallel(n_jobs=50)]: Done 292 tasks      | elapsed:  6.9min\n",
        "[Parallel(n_jobs=50)]: Done 321 tasks      | elapsed:  7.6min\n",
        "[Parallel(n_jobs=50)]: Done 350 tasks      | elapsed:  8.4min\n",
        "[Parallel(n_jobs=50)]: Done 381 tasks      | elapsed:  9.2min\n",
        "[Parallel(n_jobs=50)]: Done 412 tasks      | elapsed:  9.9min\n",
        "[Parallel(n_jobs=50)]: Done 445 tasks      | elapsed: 10.3min\n",
        "[Parallel(n_jobs=50)]: Done 478 tasks      | elapsed: 10.8min\n",
        "[Parallel(n_jobs=50)]: Done 513 tasks      | elapsed: 11.4min\n",
        "[Parallel(n_jobs=50)]: Done 548 tasks      | elapsed: 12.1min\n",
        "[Parallel(n_jobs=50)]: Done 585 tasks      | elapsed: 12.9min\n",
        "[Parallel(n_jobs=50)]: Done 622 tasks      | elapsed: 13.9min\n",
        "[Parallel(n_jobs=50)]: Done 661 tasks      | elapsed: 14.9min\n",
        "[Parallel(n_jobs=50)]: Done 700 tasks      | elapsed: 15.8min\n",
        "[Parallel(n_jobs=50)]: Done 741 tasks      | elapsed: 17.0min\n",
        "[Parallel(n_jobs=50)]: Done 782 tasks      | elapsed: 18.2min\n",
        "[Parallel(n_jobs=50)]: Done 825 tasks      | elapsed: 18.9min\n",
        "[Parallel(n_jobs=50)]: Done 868 tasks      | elapsed: 19.7min\n",
        "[Parallel(n_jobs=50)]: Done 913 tasks      | elapsed: 20.4min\n",
        "[Parallel(n_jobs=50)]: Done 958 tasks      | elapsed: 21.4min\n",
        "[Parallel(n_jobs=50)]: Done 1005 tasks      | elapsed: 22.3min\n",
        "[Parallel(n_jobs=50)]: Done 1052 tasks      | elapsed: 23.5min\n",
        "[Parallel(n_jobs=50)]: Done 1101 tasks      | elapsed: 24.8min\n",
        "[Parallel(n_jobs=50)]: Done 1150 tasks      | elapsed: 26.2min\n",
        "[Parallel(n_jobs=50)]: Done 1201 tasks      | elapsed: 27.4min\n",
        "[Parallel(n_jobs=50)]: Done 1252 tasks      | elapsed: 28.1min\n",
        "[Parallel(n_jobs=50)]: Done 1305 tasks      | elapsed: 28.8min\n",
        "[Parallel(n_jobs=50)]: Done 1358 tasks      | elapsed: 29.8min\n",
        "[Parallel(n_jobs=50)]: Done 1413 tasks      | elapsed: 30.8min\n",
        "[Parallel(n_jobs=50)]: Done 1468 tasks      | elapsed: 31.7min\n",
        "[Parallel(n_jobs=50)]: Done 1525 tasks      | elapsed: 33.0min\n",
        "[Parallel(n_jobs=50)]: Done 1582 tasks      | elapsed: 34.1min\n",
        "[Parallel(n_jobs=50)]: Done 1641 tasks      | elapsed: 35.0min\n",
        "[Parallel(n_jobs=50)]: Done 1700 tasks      | elapsed: 35.9min\n",
        "[Parallel(n_jobs=50)]: Done 1761 tasks      | elapsed: 37.0min\n",
        "[Parallel(n_jobs=50)]: Done 1822 tasks      | elapsed: 38.4min\n",
        "[Parallel(n_jobs=50)]: Done 1885 tasks      | elapsed: 40.0min\n",
        "[Parallel(n_jobs=50)]: Done 1948 tasks      | elapsed: 41.8min\n",
        "[Parallel(n_jobs=50)]: Done 2013 tasks      | elapsed: 43.3min\n",
        "[Parallel(n_jobs=50)]: Done 2078 tasks      | elapsed: 44.2min\n",
        "[Parallel(n_jobs=50)]: Done 2145 tasks      | elapsed: 45.5min\n",
        "[Parallel(n_jobs=50)]: Done 2212 tasks      | elapsed: 47.0min\n",
        "[Parallel(n_jobs=50)]: Done 2281 tasks      | elapsed: 49.0min\n",
        "[Parallel(n_jobs=50)]: Done 2350 tasks      | elapsed: 50.8min\n",
        "[Parallel(n_jobs=50)]: Done 2421 tasks      | elapsed: 52.4min\n",
        "[Parallel(n_jobs=50)]: Done 2492 tasks      | elapsed: 53.5min\n",
        "[Parallel(n_jobs=50)]: Done 2565 tasks      | elapsed: 55.0min\n",
        "[Parallel(n_jobs=50)]: Done 2638 tasks      | elapsed: 56.4min\n",
        "[Parallel(n_jobs=50)]: Done 2713 tasks      | elapsed: 58.6min\n",
        "[Parallel(n_jobs=50)]: Done 2788 tasks      | elapsed: 60.6min\n",
        "[Parallel(n_jobs=50)]: Done 2865 tasks      | elapsed: 61.9min\n",
        "[Parallel(n_jobs=50)]: Done 2942 tasks      | elapsed: 63.2min\n",
        "[Parallel(n_jobs=50)]: Done 3021 tasks      | elapsed: 64.9min\n",
        "[Parallel(n_jobs=50)]: Done 3100 tasks      | elapsed: 66.8min\n",
        "[Parallel(n_jobs=50)]: Done 3181 tasks      | elapsed: 69.0min\n",
        "[Parallel(n_jobs=50)]: Done 3262 tasks      | elapsed: 70.3min\n",
        "[Parallel(n_jobs=50)]: Done 3345 tasks      | elapsed: 71.7min\n",
        "[Parallel(n_jobs=50)]: Done 3428 tasks      | elapsed: 73.4min\n",
        "[Parallel(n_jobs=50)]: Done 3513 tasks      | elapsed: 75.5min\n",
        "[Parallel(n_jobs=50)]: Done 3598 tasks      | elapsed: 77.5min\n",
        "[Parallel(n_jobs=50)]: Done 3685 tasks      | elapsed: 78.7min\n",
        "[Parallel(n_jobs=50)]: Done 3772 tasks      | elapsed: 80.3min\n",
        "[Parallel(n_jobs=50)]: Done 3861 tasks      | elapsed: 82.5min\n",
        "[Parallel(n_jobs=50)]: Done 3950 tasks      | elapsed: 84.8min\n",
        "[Parallel(n_jobs=50)]: Done 4041 tasks      | elapsed: 86.5min\n",
        "[Parallel(n_jobs=50)]: Done 4132 tasks      | elapsed: 88.1min\n",
        "[Parallel(n_jobs=50)]: Done 4225 tasks      | elapsed: 90.0min\n",
        "[Parallel(n_jobs=50)]: Done 4318 tasks      | elapsed: 92.5min\n",
        "[Parallel(n_jobs=50)]: Done 4413 tasks      | elapsed: 94.9min\n",
        "[Parallel(n_jobs=50)]: Done 4508 tasks      | elapsed: 96.3min\n",
        "[Parallel(n_jobs=50)]: Done 4605 tasks      | elapsed: 98.3min\n",
        "[Parallel(n_jobs=50)]: Done 4800 out of 4800 | elapsed: 103.5min finished\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
        "  DeprecationWarning)\n",
        "{'classifier__criterion': 'entropy', 'classifier__gamma': 1, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 9, 'classifier__max_features': 'auto', 'classifier__n_estimators': 100}\n",
        "0.7991573033707865\n",
        "0.0019175359993823804\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXh632Su2sSj"
      },
      "source": [
        "Depois de 103.5 minutos de processamento usando 12GB de RAM, temos o seguinte resultado:\n",
        "\n",
        "{'classifier__criterion': 'entropy', 'classifier__gamma': 1, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 9, 'classifier__max_features': 'auto', 'classifier__n_estimators': 100}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snp3cImM3JbQ"
      },
      "source": [
        "Então, por fim, aplicamos esses parâmetros no classificador:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCb3vfvodTyC"
      },
      "source": [
        "xg2= Pipeline([('preprocessor', preprocessor), \n",
        "               ('reduce_dim', PCA()),\n",
        "               ('classifier', XGBClassifier(criterion= 'entropy', gamma= 1, learning_rate= 0.1, max_depth= 9, max_features= 'auto', n_estimators= 100))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YdJG4PeeLVV"
      },
      "source": [
        "xg2.fit(X_treinamento, y_treinamento)\n",
        "print(\"Training Sample: model score: %.3f\" % xg2.score(X_treinamento, y_treinamento))\n",
        "print(\"Test Sample....: model score: %.3f\" % xg2.score(X_teste, y_teste))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVQbNNXsOrp9"
      },
      "source": [
        "Sabem explicar porque serão ajustados 480 modelos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyVLctfH5epR"
      },
      "source": [
        "Qual a conclusão? O fine tuning obteve ou não um modelo melhor do que o modelo-padrão?\n",
        "\n",
        "* Qual é a acurácia do XGBClassifier antes do fine tuning?\n",
        "* Qual é a acurácia do XGBClassifier depois do fine tuning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQoIV5HQ60XA"
      },
      "source": [
        "Mais métricas para avaliação da acurácia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL763eRq7RFs"
      },
      "source": [
        "y_pred_antes1 = xg.fit(X_treinamento, y_treinamento).predict(X_treinamento)\n",
        "y_pred_depois1 = xg2.fit(X_treinamento, y_treinamento).predict(X_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I_0-DYJ8Nwv"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"treinamento - Antes do Fine tuning.:\", accuracy_score(y_treinamento, y_pred_antes1))\n",
        "print(\"treinamento - Depois do Fine tuning:\", accuracy_score(y_treinamento, y_pred_depois1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvdSuQMLAVtB"
      },
      "source": [
        "y_pred_antes2 = xg.fit(X_teste, y_teste).predict(X_teste)\n",
        "y_pred_depois2 = xg2.fit(X_teste, y_teste).predict(X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJe-cN-gAkY3"
      },
      "source": [
        "print(\"teste - Antes do Fine tuning.:\", accuracy_score(y_teste, y_pred_antes2))\n",
        "print(\"teste - Depois do Fine tuning:\", accuracy_score(y_teste, y_pred_depois2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xjhs1YbNBY4"
      },
      "source": [
        "Versão mais completa:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRHYpBLZMCnV"
      },
      "source": [
        "```\n",
        "start = timeit.timeit()\n",
        "param_grid = { \n",
        "    'classifier__n_estimators': [50, 100, 200, 300, 400, 500, 600, 700, 800, 900],\n",
        "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'classifier__max_depth' : [3,4,5,6,7,8,9],\n",
        "    'classifier__criterion' :['gini', 'entropy'],\n",
        "    'classifier__learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
        "    'classifier__subsample':[0.8,0.85,0.9,0.95,1],\n",
        "    'classifier__colsample_bytree':[0.3,0.5,0.7,0.9,1],\n",
        "    'classifier__gamma':[0,1,5]}\n",
        "\n",
        "CV = GridSearchCV(xg, param_grid, cv= 10, n_jobs= 100, scoring='accuracy', verbose=10)\n",
        "                  \n",
        "CV.fit(X_treinamento, y_treinamento)  \n",
        "print(CV.best_params_)    \n",
        "print(CV.best_score_)\n",
        "\n",
        "end = timeit.timeit()\n",
        "print(end - start)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDpn7AbFOXn6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}