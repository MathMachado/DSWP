{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio_RFB _total9_21nov_16h55.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f3b28d27cc24e0096b279c4ef0d8dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e401a374227241dbb8d19bd4186c6fed",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3450330b191c4319930df00077144ee5"
          }
        },
        "e401a374227241dbb8d19bd4186c6fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3450330b191c4319930df00077144ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7593a0379c0940199e78c743f6cd48aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_dac0dc11e19b4f738d27ca6f1ad93523",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db8e4338619043a3a147e5b122024963"
          }
        },
        "dac0dc11e19b4f738d27ca6f1ad93523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db8e4338619043a3a147e5b122024963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "030ed8ab1bdc4009bb5e528c67882edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a728da7a887a4aa19e496bf80a15b49f",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 79,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 79,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a59d9eccd29413e8218a2999f64c8c5"
          }
        },
        "a728da7a887a4aa19e496bf80a15b49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a59d9eccd29413e8218a2999f64c8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78c0f2e49d1d4911bef0ff45ea729c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_adc9351255db4e27bc3c03834ef383aa",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_918a6b1a4c734cc9996518b56fc02eef"
          }
        },
        "adc9351255db4e27bc3c03834ef383aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "918a6b1a4c734cc9996518b56fc02eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25990028f9324742bcf23ba0997e5e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a10824738054eff99a083b1c1c4fa3d",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 7,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7e7fb531d564a198c110b6be374e05f"
          }
        },
        "8a10824738054eff99a083b1c1c4fa3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7e7fb531d564a198c110b6be374e05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryssoga/DSWP/blob/master/Desafio_RFB__total9_21nov_18h18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOPOEiuuXb-"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0klE9on9bLm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5acc980-e2ff-487f-ed48-36244e8ac3d2"
      },
      "source": [
        "url_total_9 = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Dataframes/total_9.csv'\n",
        "df_total = pd.read_csv(url_total_9)\n",
        "f'\"df_total.shape:\":{df_total.shape}'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_total.shape:\":(12033, 80)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7m_dYQrBdrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f73d241-38bd-460c-81be-8f7d11a7681a"
      },
      "source": [
        "df_total['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8513\n",
              "1    2520\n",
              "2    1000\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoSXzkV1BlfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7833a2-d9ab-493f-b231-1909c3aa4659"
      },
      "source": [
        "df_total[df_total['target'] == 2].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([11033, 11034, 11035, 11036, 11037, 11038, 11039, 11040, 11041,\n",
              "            11042,\n",
              "            ...\n",
              "            12023, 12024, 12025, 12026, 12027, 12028, 12029, 12030, 12031,\n",
              "            12032],\n",
              "           dtype='int64', length=1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arpXjjKmewYf",
        "outputId": "e28794ae-7dab-4da7-f607-044f76597e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_total = pd.get_dummies(df_total, drop_first=False)\n",
        "f'\"df_total.shape:\":{df_total.shape}'\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_total.shape:\":(12033, 107)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg0y_ylqAweG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3bb749c3-bf6b-4a00-8a94-ddfd95757a63"
      },
      "source": [
        "df_train = df_total[0:11033].copy()\n",
        "df_test = df_total[11033:].copy()\n",
        "\n",
        "df_test.drop(['target'],axis=1,inplace=True)\n",
        "\n",
        "df_train.set_index('id', inplace=True)\n",
        "df_test.set_index('id',inplace=True)\n",
        "\n",
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 106), \"df_test.shape:\": (1000, 105)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pa1o4_kd5Op",
        "outputId": "057fa73a-dcba-4c1b-8c8f-3cdbe2c06996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cnae2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8', 'md9',\n",
              "       ...\n",
              "       'cnae_secao_I', 'cnae_secao_J', 'cnae_secao_K', 'cnae_secao_L',\n",
              "       'cnae_secao_M', 'cnae_secao_N', 'cnae_secao_P', 'cnae_secao_Q',\n",
              "       'cnae_secao_R', 'cnae_secao_S'],\n",
              "      dtype='object', length=106)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp3lzZ3KMQYW"
      },
      "source": [
        "## PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F9_sJ10M9-G",
        "outputId": "b2f2dfa6-34ff-4cc0-b803-d40313c7c84f"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycaret\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/d0/390ff0f120c05795d45b353cedc81120f9c6558aae285a73e8fab62f322d/pycaret-2.2.1-py3-none-any.whl (248kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20kB 24.1MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 40kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 51kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 71kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 81kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 92kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 102kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 112kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 122kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 133kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 143kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 153kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 163kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 174kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 184kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 194kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 204kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 215kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 225kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 235kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 245kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.18.5)\n",
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/69/c6b3911ccb421adc779390ca2ea54cb888a54e282d50e8d20ce751b5c7ab/mlflow-1.12.1-py3-none-any.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 317kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.0)\n",
            "Collecting pandas-profiling>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/79/5d03ed1172e3e67a997a6a795bcdd2ab58f84851969d01a91455383795b6/pandas_profiling-2.9.0-py2.py3-none-any.whl (258kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 52.7MB/s \n",
            "\u001b[?25hCollecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/1d/22a6c4e796fff1066bf80bf59b4494d6e3582e22012a61721f4cb730b3c3/pyod-0.8.4.tar.gz (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.5)\n",
            "Collecting scikit-learn>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.14.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.2.4)\n",
            "Collecting imbalanced-learn>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl (167kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 54.8MB/s \n",
            "\u001b[?25hCollecting kmodes>=0.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/55/d8ec1ae1f7e1e202a8a4184c6852a3ee993b202b0459672c699d0ac18fc8/kmodes-0.10.2-py2.py3-none-any.whl\n",
            "Collecting yellowbrick>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/ad/ae6744ddb9c7053916bed95430152b9a41b7d410e16a1cc7cd744a611d90/yellowbrick-1.2-py3-none-any.whl (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 65.6MB/s \n",
            "\u001b[?25hCollecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret) (7.5.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.4.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.1.4)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.3)\n",
            "Collecting xgboost>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/cc/fd3d5fc6b6616a03385a0f6492cc77a253940d1026406ecc07597095e381/xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9MB)\n",
            "\u001b[K     |████████████████████████████████| 148.9MB 98kB/s \n",
            "\u001b[?25hCollecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.3)\n",
            "Collecting catboost>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |████████████████████████████████| 66.3MB 112kB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting lightgbm>=2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/4d/99073804bd31f15678f24a79e96981dcbaa840bc9926dfd132e9638d51bb/lightgbm-3.1.0-py2.py3-none-manylinux1_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 49.9MB/s \n",
            "\u001b[?25hCollecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/88/ae1f78cf582b707c605c77df49b4c8786a4465edc51adb25d2f98ef4c4de/databricks-cli-0.14.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.12.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (2.8.1)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Collecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[?25hCollecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Collecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.20)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (2.23.0)\n",
            "Collecting azure-storage-blob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/5d/0bb4ed37da2523c393789b1d8ecbf56b1d35fa344af30fe423da2c06cbe9/azure_storage_blob-12.6.0-py2.py3-none-any.whl (328kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.15.0)\n",
            "Collecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.4.2)\n",
            "Collecting visions[type_image_path]==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e3/9416e94e767d59a86edcbcb8e1c8f42874d272c3b343676074879e9db0e0/visions-0.5.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n",
            "\u001b[?25hCollecting tangled-up-in-unicode>=0.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/e2/e588ab9298d4989ce7fdb2b97d18aac878d99dbdc379a4476a09d9271b68/tangled_up_in_unicode-0.0.6-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 31.8MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.43.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/bc/857fff709f7ce9eabdc502d6fa71f4b7e964200b1bcd00f0a2f59667d1bf/tqdm-4.53.0-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hCollecting phik>=0.9.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/5a/7ef1c04ce62cd72f900c06298dc2385840550d5c653a0dbc19109a5477e6/phik-0.10.0-py3-none-any.whl (599kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.2)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (20.2.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.4.1)\n",
            "Collecting confuse>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/55/b4726d81e5d6509fa3441f770f8a9524612627dc1b2a7d6209d1d20083fe/confuse-1.4.0-py2.py3-none-any.whl\n",
            "Collecting combo\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/2a/61b6ac584e75d8df16dc27962aa5fe99d76b09da5b6710e83d4862c84001/combo-0.1.1.tar.gz\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.48.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Collecting suod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/87/9170cabe1b5e10a7d095c0e28f2e30e7c1886a13f063de85d3cfacc06f4b/suod-0.0.4.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 25.5MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (3.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend->pycaret) (50.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.4.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from yellowbrick>=1.0.1->pycaret) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.35.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret) (7.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (5.0.8)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (0.10.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.7)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.8.0)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (1.24.3)\n",
            "Collecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a2/6565c5271a79e3c96d7a079053b4d8408a740d4bf365f0f5f244a807bd09/cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 39.1MB/s \n",
            "\u001b[?25hCollecting msrest>=0.6.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/f5/9e315fe8cb985b0ce052b34bcb767883dc739f46fadb62f05a7e6d6eedbe/msrest-0.6.19-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 497kB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/4b/ea7faaafac956a168ab9a95a7ebe583f9d308e8332a68af0ed3128ef520c/azure_core-1.9.0-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 51.2MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (2.5)\n",
            "Collecting imagehash; extra == \"type_image_path\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/9dbb772b5ef73a3069c66bb5bf29b9fb4dd57af0d5790c781c3f559bcca6/ImageHash-4.2.0-py2.py3-none-any.whl (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod->pycaret) (0.31.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (2.0.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (8.6.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.6.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.6.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (1.14.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (1.3.0)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.4.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.9.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (19.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.2.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Building wheels for collected packages: pyod, pyLDAvis, databricks-cli, prometheus-flask-exporter, alembic, htmlmin, combo, suod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.4-cp36-none-any.whl size=112083 sha256=eec67a0036aaf83bb8e974adb00351cc7406029729987ccb25d3cc634b45b303\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/31/0a/c2d4ba2d066145c55f0cb2846e59b18d874cb59c5d9adc81cf\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=6a7bcfb0376e07e2c40d7b5990a60933e3ad889756b963a0ef79afec09ecfa97\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.1-cp36-none-any.whl size=100579 sha256=af135d7b8633ef6e2248f0f5f344e4aeb856c9534c92b507d98d4244d01950c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/91/ac/5d417ee5ccbb76c8cca096cf4cfb9ed9d49d889d1d1ca0fc39\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp36-none-any.whl size=17157 sha256=27390d0f935014b924ff68cbfea255674fb0039faf9fde1c81550e553cbb83f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=0b55fd634442d43366c9ddeb357872bdeb3bf592afffbf0a070310f10b326544\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=14755542aaaa4bcd6b3bd532c3f570d9ad91373aca8b44fcb45ac00d4af35e76\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.1-cp36-none-any.whl size=42113 sha256=1b55f18712f5722e929f9fdd071a43464d067ad196a193f015072827a6604835\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/ec/e5/a2331372c676c467e70c6646e646edf6997d5c4905b8c0f5e6\n",
            "  Building wheel for suod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suod: filename=suod-0.0.4-cp36-none-any.whl size=2167158 sha256=db59d3184601d2eaf92cb8fe48cb859b0bb726e907c512230d1e8be3b98b44ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/55/e5/a4fca65bba231f6d0115059b589148774b41faea25b3f2aa27\n",
            "Successfully built pyod pyLDAvis databricks-cli prometheus-flask-exporter alembic htmlmin combo suod\n",
            "Installing collected packages: databricks-cli, prometheus-flask-exporter, gunicorn, Mako, python-editor, alembic, querystring-parser, smmap, gitdb, gitpython, cryptography, isodate, msrest, azure-core, azure-storage-blob, websocket-client, docker, mlflow, tangled-up-in-unicode, imagehash, visions, tqdm, phik, htmlmin, confuse, pandas-profiling, threadpoolctl, scikit-learn, combo, suod, pyod, imbalanced-learn, kmodes, yellowbrick, funcy, pyLDAvis, xgboost, scikit-plot, catboost, lightgbm, pycaret\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "  Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.1 azure-core-1.9.0 azure-storage-blob-12.6.0 catboost-0.24.3 combo-0.1.1 confuse-1.4.0 cryptography-3.2.1 databricks-cli-0.14.1 docker-4.3.1 funcy-1.15 gitdb-4.0.5 gitpython-3.1.11 gunicorn-20.0.4 htmlmin-0.1.12 imagehash-4.2.0 imbalanced-learn-0.7.0 isodate-0.6.0 kmodes-0.10.2 lightgbm-3.1.0 mlflow-1.12.1 msrest-0.6.19 pandas-profiling-2.9.0 phik-0.10.0 prometheus-flask-exporter-0.18.1 pyLDAvis-2.1.2 pycaret-2.2.1 pyod-0.8.4 python-editor-1.0.4 querystring-parser-1.2.4 scikit-learn-0.23.2 scikit-plot-0.3.7 smmap-3.0.4 suod-0.0.4 tangled-up-in-unicode-0.0.6 threadpoolctl-2.1.0 tqdm-4.53.0 visions-0.5.0 websocket-client-0.57.0 xgboost-1.2.1 yellowbrick-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAjtbymSkJ2"
      },
      "source": [
        "# Carregar bibliotecas\n",
        "import pycaret\n",
        "from pycaret.classification import *                                       \n",
        "from pycaret.regression import *                      \n",
        "from pycaret.utils import enable_colab                # Para executar gráficos no Colab\n",
        "from pycaret import classification as pyclass \n",
        "from pycaret import regression as pyreg\n",
        "from sklearn.model_selection import train_test_split  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f3b28d27cc24e0096b279c4ef0d8dde",
            "e401a374227241dbb8d19bd4186c6fed",
            "3450330b191c4319930df00077144ee5",
            "7593a0379c0940199e78c743f6cd48aa",
            "dac0dc11e19b4f738d27ca6f1ad93523",
            "db8e4338619043a3a147e5b122024963"
          ]
        },
        "id": "Khs3DL5jS6s-",
        "outputId": "4fbf9971-7a89-4fad-8cb8-570cad9fe88c"
      },
      "source": [
        "model = pyclass.setup(data = df_train,      \n",
        "                      target = 'target',     \n",
        "                      train_size = 0.7,\n",
        "                      fix_imbalance = True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>6395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>0: 0, 1: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(11033, 106)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(7723, 105)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(3310, 105)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>316a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id              6395\n",
              "1                                   Target            target\n",
              "2                              Target Type            Binary\n",
              "3                            Label Encoded        0: 0, 1: 1\n",
              "4                            Original Data      (11033, 106)\n",
              "5                           Missing Values             False\n",
              "6                         Numeric Features                89\n",
              "7                     Categorical Features                16\n",
              "8                         Ordinal Features             False\n",
              "9                High Cardinality Features             False\n",
              "10                 High Cardinality Method              None\n",
              "11                   Transformed Train Set       (7723, 105)\n",
              "12                    Transformed Test Set       (3310, 105)\n",
              "13                      Shuffle Train-Test              True\n",
              "14                     Stratify Train-Test             False\n",
              "15                          Fold Generator   StratifiedKFold\n",
              "16                             Fold Number                10\n",
              "17                                CPU Jobs                -1\n",
              "18                                 Use GPU             False\n",
              "19                          Log Experiment             False\n",
              "20                         Experiment Name  clf-default-name\n",
              "21                                     USI              316a\n",
              "22                         Imputation Type            simple\n",
              "23          Iterative Imputation Iteration              None\n",
              "24                         Numeric Imputer              mean\n",
              "25      Iterative Imputation Numeric Model              None\n",
              "26                     Categorical Imputer          constant\n",
              "27  Iterative Imputation Categorical Model              None\n",
              "28           Unknown Categoricals Handling    least_frequent\n",
              "29                               Normalize             False\n",
              "30                        Normalize Method              None\n",
              "31                          Transformation             False\n",
              "32                   Transformation Method              None\n",
              "33                                     PCA             False\n",
              "34                              PCA Method              None\n",
              "35                          PCA Components              None\n",
              "36                     Ignore Low Variance             False\n",
              "37                     Combine Rare Levels             False\n",
              "38                    Rare Level Threshold              None\n",
              "39                         Numeric Binning             False\n",
              "40                         Remove Outliers             False\n",
              "41                      Outliers Threshold              None\n",
              "42                Remove Multicollinearity             False\n",
              "43             Multicollinearity Threshold              None\n",
              "44                              Clustering             False\n",
              "45                    Clustering Iteration              None\n",
              "46                     Polynomial Features             False\n",
              "47                       Polynomial Degree              None\n",
              "48                    Trignometry Features             False\n",
              "49                    Polynomial Threshold              None\n",
              "50                          Group Features             False\n",
              "51                       Feature Selection             False\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                           Fix Imbalance              True\n",
              "57                    Fix Imbalance Method             SMOTE"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "occvZWxxTMEg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "030ed8ab1bdc4009bb5e528c67882edf",
            "a728da7a887a4aa19e496bf80a15b49f",
            "0a59d9eccd29413e8218a2999f64c8c5"
          ]
        },
        "outputId": "85542a75-6014-4550-fa54-a00223f0290f"
      },
      "source": [
        "_# Treinar modelos\n",
        "best = pyclass.compare_models()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Classifier</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7292</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>0.4395</td>\n",
              "      <td>0.3419</td>\n",
              "      <td>0.1998</td>\n",
              "      <td>0.2078</td>\n",
              "      <td>23.488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.7533</td>\n",
              "      <td>0.7237</td>\n",
              "      <td>0.2818</td>\n",
              "      <td>0.4359</td>\n",
              "      <td>0.3414</td>\n",
              "      <td>0.1985</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.7532</td>\n",
              "      <td>0.7086</td>\n",
              "      <td>0.2698</td>\n",
              "      <td>0.4325</td>\n",
              "      <td>0.3315</td>\n",
              "      <td>0.1904</td>\n",
              "      <td>0.1986</td>\n",
              "      <td>2.129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.7495</td>\n",
              "      <td>0.7124</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.4304</td>\n",
              "      <td>0.3510</td>\n",
              "      <td>0.2022</td>\n",
              "      <td>0.2080</td>\n",
              "      <td>6.409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.7403</td>\n",
              "      <td>0.7146</td>\n",
              "      <td>0.3284</td>\n",
              "      <td>0.4117</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.2043</td>\n",
              "      <td>0.2067</td>\n",
              "      <td>3.402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.7334</td>\n",
              "      <td>0.7111</td>\n",
              "      <td>0.3659</td>\n",
              "      <td>0.4053</td>\n",
              "      <td>0.3841</td>\n",
              "      <td>0.2148</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>0.334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7326</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3676</td>\n",
              "      <td>0.4040</td>\n",
              "      <td>0.3846</td>\n",
              "      <td>0.2144</td>\n",
              "      <td>0.2150</td>\n",
              "      <td>0.158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.7298</td>\n",
              "      <td>0.7128</td>\n",
              "      <td>0.3978</td>\n",
              "      <td>0.4058</td>\n",
              "      <td>0.4011</td>\n",
              "      <td>0.2269</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>9.781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3207</td>\n",
              "      <td>0.4201</td>\n",
              "      <td>0.3058</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.1881</td>\n",
              "      <td>0.544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.7256</td>\n",
              "      <td>0.7168</td>\n",
              "      <td>0.4331</td>\n",
              "      <td>0.4043</td>\n",
              "      <td>0.4178</td>\n",
              "      <td>0.2387</td>\n",
              "      <td>0.2392</td>\n",
              "      <td>3.146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.7034</td>\n",
              "      <td>0.6943</td>\n",
              "      <td>0.4269</td>\n",
              "      <td>0.3698</td>\n",
              "      <td>0.3958</td>\n",
              "      <td>0.2008</td>\n",
              "      <td>0.2019</td>\n",
              "      <td>2.139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.6652</td>\n",
              "      <td>0.5689</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>0.3121</td>\n",
              "      <td>0.3474</td>\n",
              "      <td>0.1262</td>\n",
              "      <td>0.1278</td>\n",
              "      <td>0.587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.5503</td>\n",
              "      <td>0.6391</td>\n",
              "      <td>0.7177</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.4208</td>\n",
              "      <td>0.1461</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.4733</td>\n",
              "      <td>0.6490</td>\n",
              "      <td>0.8087</td>\n",
              "      <td>0.2763</td>\n",
              "      <td>0.4116</td>\n",
              "      <td>0.1096</td>\n",
              "      <td>0.1632</td>\n",
              "      <td>0.158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.2284</td>\n",
              "      <td>0.4998</td>\n",
              "      <td>0.9977</td>\n",
              "      <td>0.2274</td>\n",
              "      <td>0.3704</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "catboost              CatBoost Classifier    0.7541  0.7292  0.2812  0.4395   \n",
              "lightgbm  Light Gradient Boosting Machine    0.7533  0.7237  0.2818  0.4359   \n",
              "et                 Extra Trees Classifier    0.7532  0.7086  0.2698  0.4325   \n",
              "xgboost         Extreme Gradient Boosting    0.7495  0.7124  0.2977  0.4304   \n",
              "rf               Random Forest Classifier    0.7403  0.7146  0.3284  0.4117   \n",
              "lda          Linear Discriminant Analysis    0.7334  0.7111  0.3659  0.4053   \n",
              "ridge                    Ridge Classifier    0.7326  0.0000  0.3676  0.4040   \n",
              "gbc          Gradient Boosting Classifier    0.7298  0.7128  0.3978  0.4058   \n",
              "svm                   SVM - Linear Kernel    0.7260  0.0000  0.3207  0.4201   \n",
              "lr                    Logistic Regression    0.7256  0.7168  0.4331  0.4043   \n",
              "ada                  Ada Boost Classifier    0.7034  0.6943  0.4269  0.3698   \n",
              "dt               Decision Tree Classifier    0.6652  0.5689  0.3922  0.3121   \n",
              "knn                K Neighbors Classifier    0.5503  0.6391  0.7177  0.2977   \n",
              "nb                            Naive Bayes    0.4733  0.6490  0.8087  0.2763   \n",
              "qda       Quadratic Discriminant Analysis    0.2284  0.4998  0.9977  0.2274   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "catboost  0.3419  0.1998  0.2078    23.488  \n",
              "lightgbm  0.3414  0.1985  0.2060     0.851  \n",
              "et        0.3315  0.1904  0.1986     2.129  \n",
              "xgboost   0.3510  0.2022  0.2080     6.409  \n",
              "rf        0.3648  0.2043  0.2067     3.402  \n",
              "lda       0.3841  0.2148  0.2154     0.334  \n",
              "ridge     0.3846  0.2144  0.2150     0.158  \n",
              "gbc       0.4011  0.2269  0.2273     9.781  \n",
              "svm       0.3058  0.1667  0.1881     0.544  \n",
              "lr        0.4178  0.2387  0.2392     3.146  \n",
              "ada       0.3958  0.2008  0.2019     2.139  \n",
              "dt        0.3474  0.1262  0.1278     0.587  \n",
              "knn       0.4208  0.1461  0.1843     0.613  \n",
              "nb        0.4116  0.1096  0.1632     0.158  \n",
              "qda       0.3704 -0.0002  0.0003     0.206  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JlTd1lNjgQB"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "78c0f2e49d1d4911bef0ff45ea729c4a",
            "adc9351255db4e27bc3c03834ef383aa",
            "918a6b1a4c734cc9996518b56fc02eef"
          ]
        },
        "id": "wzCG8d-in2ny",
        "outputId": "da991605-8af4-4684-85a9-0c1b605e6989"
      },
      "source": [
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/regression/#create-model\n",
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/classification/#create-model\n",
        "cb = pyclass.create_model('catboost')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7387</td>\n",
              "      <td>0.7103</td>\n",
              "      <td>0.2443</td>\n",
              "      <td>0.3839</td>\n",
              "      <td>0.2986</td>\n",
              "      <td>0.1477</td>\n",
              "      <td>0.1534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7529</td>\n",
              "      <td>0.7412</td>\n",
              "      <td>0.3068</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>0.2192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.7289</td>\n",
              "      <td>0.3295</td>\n",
              "      <td>0.4113</td>\n",
              "      <td>0.3659</td>\n",
              "      <td>0.2049</td>\n",
              "      <td>0.2069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7526</td>\n",
              "      <td>0.7320</td>\n",
              "      <td>0.2686</td>\n",
              "      <td>0.4273</td>\n",
              "      <td>0.3298</td>\n",
              "      <td>0.1877</td>\n",
              "      <td>0.1953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7811</td>\n",
              "      <td>0.7661</td>\n",
              "      <td>0.3143</td>\n",
              "      <td>0.5288</td>\n",
              "      <td>0.3943</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.2848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7707</td>\n",
              "      <td>0.7265</td>\n",
              "      <td>0.2686</td>\n",
              "      <td>0.4896</td>\n",
              "      <td>0.3469</td>\n",
              "      <td>0.2219</td>\n",
              "      <td>0.2366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7681</td>\n",
              "      <td>0.7358</td>\n",
              "      <td>0.3068</td>\n",
              "      <td>0.4865</td>\n",
              "      <td>0.3763</td>\n",
              "      <td>0.2428</td>\n",
              "      <td>0.2525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7409</td>\n",
              "      <td>0.7328</td>\n",
              "      <td>0.2557</td>\n",
              "      <td>0.3947</td>\n",
              "      <td>0.3103</td>\n",
              "      <td>0.1597</td>\n",
              "      <td>0.1654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7422</td>\n",
              "      <td>0.7084</td>\n",
              "      <td>0.2841</td>\n",
              "      <td>0.4065</td>\n",
              "      <td>0.3344</td>\n",
              "      <td>0.1808</td>\n",
              "      <td>0.1853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7539</td>\n",
              "      <td>0.7098</td>\n",
              "      <td>0.2330</td>\n",
              "      <td>0.4271</td>\n",
              "      <td>0.3015</td>\n",
              "      <td>0.1675</td>\n",
              "      <td>0.1788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7292</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>0.4395</td>\n",
              "      <td>0.3419</td>\n",
              "      <td>0.1998</td>\n",
              "      <td>0.2078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0307</td>\n",
              "      <td>0.0447</td>\n",
              "      <td>0.0310</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.0389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7387  0.7103  0.2443  0.3839  0.2986  0.1477  0.1534\n",
              "1       0.7529  0.7412  0.3068  0.4390  0.3612  0.2140  0.2192\n",
              "2       0.7400  0.7289  0.3295  0.4113  0.3659  0.2049  0.2069\n",
              "3       0.7526  0.7320  0.2686  0.4273  0.3298  0.1877  0.1953\n",
              "4       0.7811  0.7661  0.3143  0.5288  0.3943  0.2711  0.2848\n",
              "5       0.7707  0.7265  0.2686  0.4896  0.3469  0.2219  0.2366\n",
              "6       0.7681  0.7358  0.3068  0.4865  0.3763  0.2428  0.2525\n",
              "7       0.7409  0.7328  0.2557  0.3947  0.3103  0.1597  0.1654\n",
              "8       0.7422  0.7084  0.2841  0.4065  0.3344  0.1808  0.1853\n",
              "9       0.7539  0.7098  0.2330  0.4271  0.3015  0.1675  0.1788\n",
              "Mean    0.7541  0.7292  0.2812  0.4395  0.3419  0.1998  0.2078\n",
              "SD      0.0140  0.0166  0.0307  0.0447  0.0310  0.0368  0.0389"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "3vrIvLxRokBF",
        "outputId": "7eebdf04-4322-4c04-cecb-89fe35198d49"
      },
      "source": [
        "# Verificar importância das variáveis\n",
        "modelo = cb\n",
        "pyclass.plot_model(modelo, 'feature')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns0RTh9JnXXp"
      },
      "source": [
        "holdout = pyclass.predict_model(modelo, data = df_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQJrjf7zT6YN",
        "outputId": "1b86da61-bad6-4760-850f-90e134f0ca6e"
      },
      "source": [
        "holdout['Label'].value_counts()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    830\n",
              "1    170\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp3F471Sk7I5",
        "outputId": "11be76b6-0660-4039-c2ec-4cbf47f74797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "holdout.head(1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>...</th>\n",
              "      <th>md5_o</th>\n",
              "      <th>md7_o</th>\n",
              "      <th>md8_o</th>\n",
              "      <th>md9_o</th>\n",
              "      <th>md10_o</th>\n",
              "      <th>md12_o</th>\n",
              "      <th>mc1_o</th>\n",
              "      <th>mc3_o</th>\n",
              "      <th>mc4_o</th>\n",
              "      <th>rf2_d</th>\n",
              "      <th>rf2_i</th>\n",
              "      <th>rf2_k</th>\n",
              "      <th>rf2_p</th>\n",
              "      <th>rf2_q</th>\n",
              "      <th>rf2_r</th>\n",
              "      <th>rf2_s</th>\n",
              "      <th>rf2_v</th>\n",
              "      <th>rf2_y</th>\n",
              "      <th>rf2_z</th>\n",
              "      <th>cnae_secao_0</th>\n",
              "      <th>cnae_secao_A</th>\n",
              "      <th>cnae_secao_B</th>\n",
              "      <th>cnae_secao_C</th>\n",
              "      <th>cnae_secao_D</th>\n",
              "      <th>cnae_secao_E</th>\n",
              "      <th>cnae_secao_F</th>\n",
              "      <th>cnae_secao_G</th>\n",
              "      <th>cnae_secao_H</th>\n",
              "      <th>cnae_secao_I</th>\n",
              "      <th>cnae_secao_J</th>\n",
              "      <th>cnae_secao_K</th>\n",
              "      <th>cnae_secao_L</th>\n",
              "      <th>cnae_secao_M</th>\n",
              "      <th>cnae_secao_N</th>\n",
              "      <th>cnae_secao_P</th>\n",
              "      <th>cnae_secao_Q</th>\n",
              "      <th>cnae_secao_R</th>\n",
              "      <th>cnae_secao_S</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3411</th>\n",
              "      <td>71</td>\n",
              "      <td>0.017485</td>\n",
              "      <td>0.004743</td>\n",
              "      <td>0.111771</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005432</td>\n",
              "      <td>0.023085</td>\n",
              "      <td>0.00989</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.13132</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.442161e-09</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297611</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.425478</td>\n",
              "      <td>0.243343</td>\n",
              "      <td>0.623462</td>\n",
              "      <td>0.424363</td>\n",
              "      <td>0.04456</td>\n",
              "      <td>4.620425e-07</td>\n",
              "      <td>0.273459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 107 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cnae2       md1       md2  ...  cnae_secao_S  Label   Score\n",
              "id                               ...                             \n",
              "3411     71  0.017485  0.004743  ...             0      0  0.7239\n",
              "\n",
              "[1 rows x 107 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1lVo4rCKVc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb0b203-9272-4389-e791-4c82bf34e50a"
      },
      "source": [
        "pycaret_cb = pd.DataFrame(zip(holdout.index, holdout['Label'], holdout['Score']), columns=['id','Label','Score'])\n",
        "pycaret_cb['Label'].value_counts()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    830\n",
              "1    170\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dY0kbA8Tp2D"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(holdout.index, holdout['Label']), columns=['id','target'])\n",
        "df_submit.to_csv('PyLadies.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHhDjV0cILKv"
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-7gQgxOXUMk"
      },
      "source": [
        "### TUNED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532,
          "referenced_widgets": [
            "25990028f9324742bcf23ba0997e5e34",
            "8a10824738054eff99a083b1c1c4fa3d",
            "d7e7fb531d564a198c110b6be374e05f"
          ]
        },
        "id": "BT3QPZVeIa6-",
        "outputId": "9a8e0e0c-64d5-4923-e12b-58100cfda5c0"
      },
      "source": [
        "tuned = pyclass.tune_model(modelo, optimize = 'F1')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25990028f9324742bcf23ba0997e5e34",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntProgress(value=0, description='Processing: ', max=7)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Initiated</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>21:03:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Status</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>Searching Hyperparameters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Estimator</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>CatBoost Classifier</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         \n",
              "                                                                         \n",
              "Initiated  . . . . . . . . . . . . . . . . . .                   21:03:55\n",
              "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
              "Estimator  . . . . . . . . . . . . . . . . . .        CatBoost Classifier"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Accuracy, AUC, Recall, Prec., F1, Kappa, MCC]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-7947b0856a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'F1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/classification.py\u001b[0m in \u001b[0;36mtune_model\u001b[0;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mtuner_verbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner_verbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m     )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mtune_model_supervised\u001b[0;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, display, **kwargs)\u001b[0m\n\u001b[1;32m   4447\u001b[0m                     \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mp_ParameterGrid_getitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4448\u001b[0m                 ):\n\u001b[0;32m-> 4449\u001b[0;31m                     \u001b[0mmodel_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4451\u001b[0m             \u001b[0mmodel_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1529\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "hza1TggsKkRB",
        "outputId": "3d3eb459-c5a7-42a3-89e7-9becd30b906a"
      },
      "source": [
        "# Verificar importância das variáveis\n",
        "pyclass.plot_model(tuned, 'feature')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Nm4pjwKL0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd39e92a-84aa-4506-d9be-ea17629fbc74"
      },
      "source": [
        "tuned_holdout = pyclass.predict_model(tuned, data = df_test)\n",
        "tuned_holdout['Label'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     513\n",
              "False    487\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQMbKRLjN4wM"
      },
      "source": [
        "df_pycaret['lda_setup_tuned_AUC'] = holdout['Label']\n",
        "df_pycaret.to_csv('df_pycaret_Label_modelos.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQwbdM_iL7b-"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(tuned_holdout.index, tuned_holdout['Label']), columns=['id','target'])\n",
        "df_submit.to_csv('Churn_pycaret_catboost_setup_tuned_AUC.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh22ZcfDHBTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4674478c-0152-4c08-b803-31cf8332cb1d"
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    847\n",
              "True     153\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrFn0j2jHBKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70b87a1-0e64-4f3b-8b60-db7abe8daf3a"
      },
      "source": [
        "df_pycaret['catboost_setup_tuned_F1'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    844\n",
              "True     156\n",
              "Name: catboost_setup_tuned_F1, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UXpoFdtP9kv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR0PHYn1XDsQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caXHz7EJXD1w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXjbsi1oXno1"
      },
      "source": [
        "### SIMULAR REGRESSÃO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "9360bc3f86c1477da3ff30dba8ba6a3a",
            "9e6212d909c2432ab15d469e9bf5bf90",
            "6a003050cc434f5596812a04fdc1c510"
          ]
        },
        "id": "tmJA8ZH7P-Lc",
        "outputId": "c02eef9e-eee4-4953-ef41-012f8a64dda7"
      },
      "source": [
        "_# Treinar modelos\n",
        "best_reg = pyreg.compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7755</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1206</td>\n",
              "      <td>0.5493</td>\n",
              "      <td>0.1971</td>\n",
              "      <td>0.1252</td>\n",
              "      <td>0.1746</td>\n",
              "      <td>0.082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.7734</td>\n",
              "      <td>0.7088</td>\n",
              "      <td>0.1295</td>\n",
              "      <td>0.5301</td>\n",
              "      <td>0.2076</td>\n",
              "      <td>0.1287</td>\n",
              "      <td>0.1732</td>\n",
              "      <td>0.179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Classifier</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>0.7383</td>\n",
              "      <td>0.2721</td>\n",
              "      <td>0.4862</td>\n",
              "      <td>0.3482</td>\n",
              "      <td>0.2193</td>\n",
              "      <td>0.2335</td>\n",
              "      <td>19.063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.7638</td>\n",
              "      <td>0.7403</td>\n",
              "      <td>0.2496</td>\n",
              "      <td>0.4746</td>\n",
              "      <td>0.3263</td>\n",
              "      <td>0.1995</td>\n",
              "      <td>0.2151</td>\n",
              "      <td>0.602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.7612</td>\n",
              "      <td>0.7203</td>\n",
              "      <td>0.2252</td>\n",
              "      <td>0.4626</td>\n",
              "      <td>0.3017</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>0.1953</td>\n",
              "      <td>2.243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.7612</td>\n",
              "      <td>0.7125</td>\n",
              "      <td>0.2175</td>\n",
              "      <td>0.4615</td>\n",
              "      <td>0.2938</td>\n",
              "      <td>0.1721</td>\n",
              "      <td>0.1906</td>\n",
              "      <td>1.465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.7608</td>\n",
              "      <td>0.7367</td>\n",
              "      <td>0.2953</td>\n",
              "      <td>0.4701</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.2235</td>\n",
              "      <td>0.2335</td>\n",
              "      <td>4.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.7587</td>\n",
              "      <td>0.7240</td>\n",
              "      <td>0.2983</td>\n",
              "      <td>0.4597</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.2211</td>\n",
              "      <td>0.2291</td>\n",
              "      <td>3.837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.7463</td>\n",
              "      <td>0.7255</td>\n",
              "      <td>0.3369</td>\n",
              "      <td>0.4339</td>\n",
              "      <td>0.3779</td>\n",
              "      <td>0.2221</td>\n",
              "      <td>0.2256</td>\n",
              "      <td>1.138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.7146</td>\n",
              "      <td>0.6925</td>\n",
              "      <td>0.3689</td>\n",
              "      <td>0.3909</td>\n",
              "      <td>0.3540</td>\n",
              "      <td>0.1827</td>\n",
              "      <td>0.1950</td>\n",
              "      <td>0.712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.6771</td>\n",
              "      <td>0.5712</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>0.3238</td>\n",
              "      <td>0.3473</td>\n",
              "      <td>0.1345</td>\n",
              "      <td>0.1353</td>\n",
              "      <td>0.230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.6423</td>\n",
              "      <td>0.6630</td>\n",
              "      <td>0.5514</td>\n",
              "      <td>0.3322</td>\n",
              "      <td>0.4144</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.1913</td>\n",
              "      <td>0.085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.5576</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3958</td>\n",
              "      <td>0.3418</td>\n",
              "      <td>0.1524</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.0190</td>\n",
              "      <td>0.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.5522</td>\n",
              "      <td>0.5038</td>\n",
              "      <td>0.4159</td>\n",
              "      <td>0.2331</td>\n",
              "      <td>0.2987</td>\n",
              "      <td>0.0068</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.4870</td>\n",
              "      <td>0.6132</td>\n",
              "      <td>0.7393</td>\n",
              "      <td>0.2814</td>\n",
              "      <td>0.4014</td>\n",
              "      <td>0.1049</td>\n",
              "      <td>0.1272</td>\n",
              "      <td>0.113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "ridge                    Ridge Classifier    0.7755  0.0000  0.1206  0.5493   \n",
              "lda          Linear Discriminant Analysis    0.7734  0.7088  0.1295  0.5301   \n",
              "catboost              CatBoost Classifier    0.7662  0.7383  0.2721  0.4862   \n",
              "lightgbm  Light Gradient Boosting Machine    0.7638  0.7403  0.2496  0.4746   \n",
              "rf               Random Forest Classifier    0.7612  0.7203  0.2252  0.4626   \n",
              "et                 Extra Trees Classifier    0.7612  0.7125  0.2175  0.4615   \n",
              "gbc          Gradient Boosting Classifier    0.7608  0.7367  0.2953  0.4701   \n",
              "xgboost         Extreme Gradient Boosting    0.7587  0.7240  0.2983  0.4597   \n",
              "ada                  Ada Boost Classifier    0.7463  0.7255  0.3369  0.4339   \n",
              "lr                    Logistic Regression    0.7146  0.6925  0.3689  0.3909   \n",
              "dt               Decision Tree Classifier    0.6771  0.5712  0.3755  0.3238   \n",
              "nb                            Naive Bayes    0.6423  0.6630  0.5514  0.3322   \n",
              "svm                   SVM - Linear Kernel    0.5576  0.0000  0.3958  0.3418   \n",
              "knn                K Neighbors Classifier    0.5522  0.5038  0.4159  0.2331   \n",
              "qda       Quadratic Discriminant Analysis    0.4870  0.6132  0.7393  0.2814   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "ridge     0.1971  0.1252  0.1746     0.082  \n",
              "lda       0.2076  0.1287  0.1732     0.179  \n",
              "catboost  0.3482  0.2193  0.2335    19.063  \n",
              "lightgbm  0.3263  0.1995  0.2151     0.602  \n",
              "rf        0.3017  0.1778  0.1953     2.243  \n",
              "et        0.2938  0.1721  0.1906     1.465  \n",
              "gbc       0.3612  0.2235  0.2335     4.700  \n",
              "xgboost   0.3613  0.2211  0.2291     3.837  \n",
              "ada       0.3779  0.2221  0.2256     1.138  \n",
              "lr        0.3540  0.1827  0.1950     0.712  \n",
              "dt        0.3473  0.1345  0.1353     0.230  \n",
              "nb        0.4144  0.1794  0.1913     0.085  \n",
              "svm       0.1524  0.0025  0.0190     0.468  \n",
              "knn       0.2987  0.0068  0.0075     0.250  \n",
              "qda       0.4014  0.1049  0.1272     0.113  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH09bBhcM80y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOaLYAnxFSDo"
      },
      "source": [
        "### PULAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypwM33UBpCw"
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_test.csv'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oDXHvVPustij",
        "outputId": "ec4b7355-4299-4add-87e7-6c1fa1c4a2f1"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}, \"df_total.shape:\": {df_total.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 63), \"df_test.shape:\": (1000, 62), \"df_total.shape:\": (12033, 80)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj2DFFRNt9uT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdc2ca6-c935-44f8-e614-a1018a61ed59"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11033 entries, 0 to 11032\n",
            "Data columns (total 63 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      11033 non-null  int64  \n",
            " 1   cnae2   11033 non-null  int64  \n",
            " 2   rf2     11033 non-null  object \n",
            " 3   md1     11033 non-null  float64\n",
            " 4   md2     11033 non-null  float64\n",
            " 5   md3     11033 non-null  float64\n",
            " 6   md4     11033 non-null  float64\n",
            " 7   md5     11033 non-null  float64\n",
            " 8   md6     11033 non-null  float64\n",
            " 9   md7     11033 non-null  float64\n",
            " 10  md8     11033 non-null  float64\n",
            " 11  md9     11033 non-null  float64\n",
            " 12  md10    11033 non-null  float64\n",
            " 13  md11    11033 non-null  float64\n",
            " 14  md12    11033 non-null  float64\n",
            " 15  mc1     10431 non-null  float64\n",
            " 16  mc2     10431 non-null  float64\n",
            " 17  mc3     10431 non-null  float64\n",
            " 18  mc4     11033 non-null  float64\n",
            " 19  ind01   10999 non-null  float64\n",
            " 20  ind02   10999 non-null  float64\n",
            " 21  ind03   10999 non-null  float64\n",
            " 22  ind04   10999 non-null  float64\n",
            " 23  ind05   10999 non-null  float64\n",
            " 24  ind06   10999 non-null  float64\n",
            " 25  ind07   10999 non-null  float64\n",
            " 26  ind08   10999 non-null  float64\n",
            " 27  ind09   10999 non-null  float64\n",
            " 28  ind10   10999 non-null  float64\n",
            " 29  ind11   10999 non-null  float64\n",
            " 30  ind12   10999 non-null  float64\n",
            " 31  ind13   10999 non-null  float64\n",
            " 32  ind14   10999 non-null  float64\n",
            " 33  ind15   10999 non-null  float64\n",
            " 34  ind16   10999 non-null  float64\n",
            " 35  ind17   10999 non-null  float64\n",
            " 36  ind18   10999 non-null  float64\n",
            " 37  ind19   10999 non-null  float64\n",
            " 38  ind20   10999 non-null  float64\n",
            " 39  ind21   10434 non-null  float64\n",
            " 40  ind22   10434 non-null  float64\n",
            " 41  ind23   10434 non-null  float64\n",
            " 42  ind24   10434 non-null  float64\n",
            " 43  ind25   10434 non-null  float64\n",
            " 44  ind26   10434 non-null  float64\n",
            " 45  ind27   10434 non-null  float64\n",
            " 46  ind28   10999 non-null  float64\n",
            " 47  ind29   10999 non-null  float64\n",
            " 48  ind30   10999 non-null  float64\n",
            " 49  ind31   10999 non-null  float64\n",
            " 50  ind32   10999 non-null  float64\n",
            " 51  ind33   10999 non-null  float64\n",
            " 52  ind34   10999 non-null  float64\n",
            " 53  ind35   10999 non-null  float64\n",
            " 54  ind36   10999 non-null  float64\n",
            " 55  ind37   10999 non-null  float64\n",
            " 56  ind38   10434 non-null  float64\n",
            " 57  ind39   10434 non-null  float64\n",
            " 58  ind40   10999 non-null  float64\n",
            " 59  ind41   10999 non-null  float64\n",
            " 60  ind42   10434 non-null  float64\n",
            " 61  ind43   10434 non-null  float64\n",
            " 62  target  11033 non-null  bool   \n",
            "dtypes: bool(1), float64(59), int64(2), object(1)\n",
            "memory usage: 5.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNVOd-U9uzXe",
        "outputId": "83a7dc81-5bef-454b-c91e-60ae74288ff5"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'cnae2', 'rf2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7',\n",
              "       'md8', 'md9', 'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4',\n",
              "       'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24',\n",
              "       'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32',\n",
              "       'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
              "       'ind41', 'ind42', 'ind43', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "mgT2KGJBt9ub",
        "outputId": "eea02333-d133-4a95-f54e-01d19e50b9e3"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6007.300462</td>\n",
              "      <td>53.105774</td>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106722</td>\n",
              "      <td>0.157427</td>\n",
              "      <td>0.346646</td>\n",
              "      <td>0.364934</td>\n",
              "      <td>0.378858</td>\n",
              "      <td>0.397906</td>\n",
              "      <td>0.305112</td>\n",
              "      <td>0.355596</td>\n",
              "      <td>0.007454</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.141280</td>\n",
              "      <td>0.170552</td>\n",
              "      <td>0.034556</td>\n",
              "      <td>0.019556</td>\n",
              "      <td>0.003789</td>\n",
              "      <td>0.014774</td>\n",
              "      <td>0.004045</td>\n",
              "      <td>0.694791</td>\n",
              "      <td>0.700189</td>\n",
              "      <td>0.544750</td>\n",
              "      <td>0.538172</td>\n",
              "      <td>0.339573</td>\n",
              "      <td>0.333567</td>\n",
              "      <td>0.099865</td>\n",
              "      <td>0.570295</td>\n",
              "      <td>0.550792</td>\n",
              "      <td>0.005119</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.331121</td>\n",
              "      <td>0.367397</td>\n",
              "      <td>0.999182</td>\n",
              "      <td>0.489044</td>\n",
              "      <td>0.910992</td>\n",
              "      <td>0.729703</td>\n",
              "      <td>0.659605</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>0.134177</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.170692</td>\n",
              "      <td>0.090905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3470.840481</td>\n",
              "      <td>19.885298</td>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305922</td>\n",
              "      <td>0.315114</td>\n",
              "      <td>0.470182</td>\n",
              "      <td>0.451587</td>\n",
              "      <td>0.449015</td>\n",
              "      <td>0.473002</td>\n",
              "      <td>0.430549</td>\n",
              "      <td>0.440732</td>\n",
              "      <td>0.069064</td>\n",
              "      <td>0.031814</td>\n",
              "      <td>0.029262</td>\n",
              "      <td>0.312289</td>\n",
              "      <td>0.322844</td>\n",
              "      <td>0.161135</td>\n",
              "      <td>0.129848</td>\n",
              "      <td>0.059799</td>\n",
              "      <td>0.118014</td>\n",
              "      <td>0.062567</td>\n",
              "      <td>0.452090</td>\n",
              "      <td>0.450725</td>\n",
              "      <td>0.455767</td>\n",
              "      <td>0.457155</td>\n",
              "      <td>0.433901</td>\n",
              "      <td>0.434164</td>\n",
              "      <td>0.221941</td>\n",
              "      <td>0.425365</td>\n",
              "      <td>0.412976</td>\n",
              "      <td>0.060052</td>\n",
              "      <td>0.013340</td>\n",
              "      <td>0.018207</td>\n",
              "      <td>0.470638</td>\n",
              "      <td>0.482118</td>\n",
              "      <td>0.028595</td>\n",
              "      <td>0.499903</td>\n",
              "      <td>0.284768</td>\n",
              "      <td>0.444134</td>\n",
              "      <td>0.473863</td>\n",
              "      <td>0.071093</td>\n",
              "      <td>0.340858</td>\n",
              "      <td>0.016514</td>\n",
              "      <td>0.009535</td>\n",
              "      <td>0.376258</td>\n",
              "      <td>0.206764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3018.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6016.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9003.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862600</td>\n",
              "      <td>0.932700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id         cnae2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  10434.000000  10434.000000\n",
              "mean    6007.300462     53.105774  ...      0.170692      0.090905\n",
              "std     3470.840481     19.885298  ...      0.376258      0.206764\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%     3018.000000     42.000000  ...      0.000000      0.000000\n",
              "50%     6016.000000     47.000000  ...      0.000000      0.000000\n",
              "75%     9003.000000     69.000000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7U16Y6SQ4Zs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "1bfaa59c-c8b3-44d4-b470-9f221cdd5cdf"
      },
      "source": [
        "l_train_unique = []\n",
        "for i in df_train.columns:\n",
        "  l_train_unique.append(len(df_train[i].unique()))\n",
        "  #print(\"coluna:\", i, \" - len(df_train[i].unique()):\", len(df_train[i].unique()))\n",
        "\n",
        "df_train_unique = pd.DataFrame(zip(df_train.columns,l_train_unique))\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>11033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cnae2</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rf2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>md1</td>\n",
              "      <td>8829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>md2</td>\n",
              "      <td>10968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>ind40</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>ind41</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>ind42</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>ind43</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>target</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0      1\n",
              "0       id  11033\n",
              "1    cnae2     80\n",
              "2      rf2     10\n",
              "3      md1   8829\n",
              "4      md2  10968\n",
              "..     ...    ...\n",
              "58   ind40      3\n",
              "59   ind41      3\n",
              "60   ind42      3\n",
              "61   ind43      4\n",
              "62  target      2\n",
              "\n",
              "[63 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2JdxJRJShUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "f24734e0-41ae-4153-c402-dbfef6a396a7"
      },
      "source": [
        "df_train_unique.rename(columns={0:'coluna',1:'qtde_unique'})\n",
        "df_train_unique = df_train_unique.set_index(0).T\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11033</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>8829</td>\n",
              "      <td>10968</td>\n",
              "      <td>10967</td>\n",
              "      <td>8168</td>\n",
              "      <td>5612</td>\n",
              "      <td>379</td>\n",
              "      <td>10970</td>\n",
              "      <td>10968</td>\n",
              "      <td>8282</td>\n",
              "      <td>5777</td>\n",
              "      <td>340</td>\n",
              "      <td>10967</td>\n",
              "      <td>9925</td>\n",
              "      <td>1484</td>\n",
              "      <td>8157</td>\n",
              "      <td>10451</td>\n",
              "      <td>14</td>\n",
              "      <td>1417</td>\n",
              "      <td>194</td>\n",
              "      <td>14</td>\n",
              "      <td>765</td>\n",
              "      <td>227</td>\n",
              "      <td>2101</td>\n",
              "      <td>2522</td>\n",
              "      <td>331</td>\n",
              "      <td>45</td>\n",
              "      <td>22</td>\n",
              "      <td>1554</td>\n",
              "      <td>2503</td>\n",
              "      <td>830</td>\n",
              "      <td>77</td>\n",
              "      <td>24</td>\n",
              "      <td>45</td>\n",
              "      <td>13</td>\n",
              "      <td>488</td>\n",
              "      <td>429</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>748</td>\n",
              "      <td>159</td>\n",
              "      <td>164</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0     id  cnae2  rf2   md1    md2  ...  ind40  ind41  ind42  ind43  target\n",
              "1  11033     80   10  8829  10968  ...      3      3      3      4       2\n",
              "\n",
              "[1 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yll7hKsUxWUK",
        "outputId": "22b004c4-e69a-4b96-b4ac-b14d83bb0602"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpnm_zhckXD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0293f89-1ee1-450d-cbf5-f1d686cfaf06"
      },
      "source": [
        "df_nan = df_train.isna().sum()\n",
        "df_nan[df_nan.values>0].sort_values()\n",
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy8hCEistGiR",
        "outputId": "f532aa00-480d-4eb9-e0d1-9096d0858f5b"
      },
      "source": [
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIaxV70rhhE-",
        "outputId": "f7e2eced-6a2d-4ec6-8ce2-3cbd338cfeac"
      },
      "source": [
        "df_nan[df_nan.values==34].index   \n",
        "\n",
        "# 32 colunas/variáveis que possuem 34 NaN cada\n",
        "#'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "#'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "#'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "#'ind40', 'ind41']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind28', 'ind29', 'ind30', 'ind31',\n",
              "       'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind40', 'ind41'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ERGm38u0oN",
        "outputId": "4f72eb49-82b0-4638-970d-04453d1c448d"
      },
      "source": [
        "len(df_nan[df_nan.values==34].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49eQZdrEpex6",
        "outputId": "eab85b83-a8e8-415d-e8b3-a23864d6ff33"
      },
      "source": [
        "df_nan[df_nan.values==599].index    \n",
        "\n",
        "# 11 colunas/variáveis que possuem 599 NaN cada:\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "# 'ind38', 'ind39',\n",
        "# 'ind42', 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind38',\n",
              "       'ind39', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o593PHygvLJ8",
        "outputId": "0e4aa74f-9572-4e25-9d89-5aa08cc581b1"
      },
      "source": [
        "len(df_nan[df_nan.values==599].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5mETHrgpe_I",
        "outputId": "4b37dbdb-ef2f-4d98-cfd1-534af3742742"
      },
      "source": [
        "df_nan[df_nan.values==602].index    \n",
        "\n",
        "# 3 colunas/variáveis que possuem 602 NaN cada\n",
        "# ['mc1', 'mc2', 'mc3']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHecZd8jfuGi",
        "outputId": "722fece4-a4fa-49e2-a0e8-cb209f74ac2d"
      },
      "source": [
        "linhas_602nan = df_train['mc1'][df_train['mc1'].isna()].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   26,    27,    32,    34,    47,    64,    76,    88,   100,\n",
              "              121,\n",
              "            ...\n",
              "            10848, 10891, 10911, 10921, 10935, 10941, 10979, 10986, 10991,\n",
              "            11007],\n",
              "           dtype='int64', length=602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EUky3VvxJH"
      },
      "source": [
        "linhas_599nan = df_train['ind21'][df_train['ind21'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI4pULl0wble",
        "outputId": "1fbcf7a7-e9f0-4d47-d135-2cd10f15172a"
      },
      "source": [
        "len(set(list(linhas_602nan)) & set(list(linhas_599nan)))  \n",
        "# 602nan e 599nan apresentam 596 linhas em comum\n",
        "# então tem 3 linhas em 599nan que não estão em 602 nan e\n",
        "# 6 linhas em 602nan que não estão em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXs7y99OyUEG",
        "outputId": "a6e963f8-43b9-4e53-d3cd-73c036721f9b"
      },
      "source": [
        "set(list(linhas_602nan)) - set(list(linhas_599nan)) # 6 linhas {1213, 1224, 3233, 5346, 6101, 7297} em 602nan mas não em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpep48R0N19",
        "outputId": "54405911-141a-480b-dd4b-57daf90b6354"
      },
      "source": [
        "set(list(linhas_599nan)) - set(list(linhas_602nan)) # 3 linhas {5788, 10284, 10965} em 599nan mas não em 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5788, 10284, 10965}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VghwKgdRwF2Y"
      },
      "source": [
        "linhas_34nan = df_train['ind01'][df_train['ind01'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozi0Gw990yml",
        "outputId": "04e1e738-a686-462c-fcc0-5b3493479a69"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_599nan))  # 34nan e 599nan não apresentam linhas nan em comum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFs38gIx0zIQ",
        "outputId": "ccb5b11a-512a-45df-b75a-fbae70a82fe6"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_602nan)) # linhas {1213, 1224, 3233, 5346, 6101, 7297} em comum em 34nan e 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g41VmVkq-_R",
        "outputId": "5dee64cb-b577-4005-9ccb-cc336e42ca62"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdaAew8P89Jn",
        "outputId": "067f5309-3973-4017-8fb3-e069c718d740"
      },
      "source": [
        "df_train[df_train['mc1'].notna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    7917\n",
              "True     2514\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Ly8LJv2_9J_x",
        "outputId": "fa8b025e-00fc-4ad8-aa29-17f3a08c7bb5"
      },
      "source": [
        "df_train[df_train['mc1'].notna()].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.00000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.00000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5998.586521</td>\n",
              "      <td>53.33851</td>\n",
              "      <td>0.011993</td>\n",
              "      <td>0.013208</td>\n",
              "      <td>0.118480</td>\n",
              "      <td>0.014551</td>\n",
              "      <td>0.009693</td>\n",
              "      <td>0.002250</td>\n",
              "      <td>0.016025</td>\n",
              "      <td>0.032519</td>\n",
              "      <td>0.017690</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.134538</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.079664</td>\n",
              "      <td>0.133032</td>\n",
              "      <td>0.311410</td>\n",
              "      <td>0.330905</td>\n",
              "      <td>0.345606</td>\n",
              "      <td>0.365514</td>\n",
              "      <td>0.321753</td>\n",
              "      <td>0.37509</td>\n",
              "      <td>0.007881</td>\n",
              "      <td>0.001454</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.149238</td>\n",
              "      <td>0.178966</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.020676</td>\n",
              "      <td>0.00391</td>\n",
              "      <td>0.014755</td>\n",
              "      <td>0.004276</td>\n",
              "      <td>0.677786</td>\n",
              "      <td>0.686280</td>\n",
              "      <td>0.544727</td>\n",
              "      <td>0.53817</td>\n",
              "      <td>0.339742</td>\n",
              "      <td>0.333741</td>\n",
              "      <td>0.099889</td>\n",
              "      <td>0.570311</td>\n",
              "      <td>0.550781</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.295011</td>\n",
              "      <td>0.333269</td>\n",
              "      <td>0.999135</td>\n",
              "      <td>0.460636</td>\n",
              "      <td>0.907238</td>\n",
              "      <td>0.714602</td>\n",
              "      <td>0.644526</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>0.134254</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.170790</td>\n",
              "      <td>0.090957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3467.890242</td>\n",
              "      <td>19.98793</td>\n",
              "      <td>0.042113</td>\n",
              "      <td>0.026769</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.040304</td>\n",
              "      <td>0.037191</td>\n",
              "      <td>0.025934</td>\n",
              "      <td>0.029294</td>\n",
              "      <td>0.027583</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>0.038919</td>\n",
              "      <td>0.022033</td>\n",
              "      <td>0.013933</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007199</td>\n",
              "      <td>0.267626</td>\n",
              "      <td>0.283498</td>\n",
              "      <td>0.456864</td>\n",
              "      <td>0.438529</td>\n",
              "      <td>0.436875</td>\n",
              "      <td>0.463864</td>\n",
              "      <td>0.435993</td>\n",
              "      <td>0.44446</td>\n",
              "      <td>0.070991</td>\n",
              "      <td>0.032711</td>\n",
              "      <td>0.030087</td>\n",
              "      <td>0.319113</td>\n",
              "      <td>0.328067</td>\n",
              "      <td>0.164659</td>\n",
              "      <td>0.133429</td>\n",
              "      <td>0.06070</td>\n",
              "      <td>0.117785</td>\n",
              "      <td>0.064327</td>\n",
              "      <td>0.458565</td>\n",
              "      <td>0.456224</td>\n",
              "      <td>0.455770</td>\n",
              "      <td>0.45715</td>\n",
              "      <td>0.433962</td>\n",
              "      <td>0.434225</td>\n",
              "      <td>0.221986</td>\n",
              "      <td>0.425340</td>\n",
              "      <td>0.412952</td>\n",
              "      <td>0.059627</td>\n",
              "      <td>0.012832</td>\n",
              "      <td>0.018721</td>\n",
              "      <td>0.456070</td>\n",
              "      <td>0.471405</td>\n",
              "      <td>0.029402</td>\n",
              "      <td>0.498472</td>\n",
              "      <td>0.290112</td>\n",
              "      <td>0.451626</td>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>0.340941</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.206812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3012.500000</td>\n",
              "      <td>42.00000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002518</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.020741</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130695</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6006.000000</td>\n",
              "      <td>47.00000</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.005624</td>\n",
              "      <td>0.112164</td>\n",
              "      <td>0.002776</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007169</td>\n",
              "      <td>0.024386</td>\n",
              "      <td>0.005072</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131472</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.58330</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8990.500000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>0.006366</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.118149</td>\n",
              "      <td>0.011908</td>\n",
              "      <td>0.004606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016753</td>\n",
              "      <td>0.033129</td>\n",
              "      <td>0.017071</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133913</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918500</td>\n",
              "      <td>0.95860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id        cnae2  ...         ind42         ind43\n",
              "count  10431.000000  10431.00000  ...  10428.000000  10428.000000\n",
              "mean    5998.586521     53.33851  ...      0.170790      0.090957\n",
              "std     3467.890242     19.98793  ...      0.376344      0.206812\n",
              "min        0.000000      0.00000  ...      0.000000      0.000000\n",
              "25%     3012.500000     42.00000  ...      0.000000      0.000000\n",
              "50%     6006.000000     47.00000  ...      0.000000      0.000000\n",
              "75%     8990.500000     69.00000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.00000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWABZ-yWrQH2",
        "outputId": "e5092897-4659-4d79-969e-cc54bd1c11c4"
      },
      "source": [
        "df_train['target'].value_counts()   22,84% True e 77,16% False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3hg6GGQt9us"
      },
      "source": [
        "# Total de 46 Colunas/variáveis que apresentam NaN:\n",
        "# 'mc1', 'mc2', 'mc3',\n",
        "# 'ind01', 'ind02', 'ind03', 'ind04', 'ind05','ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30',\n",
        "# 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
        "# 'ind41', 'ind42', 'ind43'\n",
        "sendo:\n",
        "  # 32 colunas/variáveis que possuem 34 NaN cada\n",
        "    #'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "    #'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "    #'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "    #'ind40', 'ind41'\n",
        "  # 11 colunas/variáveis que possuem 599 NaN cada:\n",
        "    # 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "    # 'ind38', 'ind39',\n",
        "    # 'ind42', 'ind43'\n",
        "  # 3 colunas/variáveis que possuem 602 NaN cada\n",
        "    # ['mc1', 'mc2', 'mc3']\n",
        "\n",
        "# 602nan e 599nan apresentam 596 linhas em comum, então:\n",
        "# 3 linhas em 599nan que não estão em 602 nan : {5788, 10284, 10965}\n",
        "# 6 linhas em 602nan que não estão em 599nan : {1213, 1224, 3233, 5346, 6101, 7297}\n",
        "\n",
        "# 602nan e 34nan apresentam 6 linhas em comum {1213, 1224, 3233, 5346, 6101, 7297} , que são as mesmas 6 linhas que não estão em 599nan\n",
        "# 599nan e 34nan não apresentam linhas em comum\n",
        "\n",
        "# Total de 633 linhas com NaN ( = 596 + 3 + 6 + 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUqmH2Bt9uz"
      },
      "source": [
        "s_coluna = pd.Series(list(df_train.columns))\n",
        "s_qtde = pd.Series(list(df_train.isna().sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOMEunK3U29"
      },
      "source": [
        "df_nan = pd.DataFrame(zip(s_coluna, s_qtde),columns = ['coluna','qtde_nan'])\n",
        "df_nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3rZDA3t3q2p"
      },
      "source": [
        "df_nan[df_nan['qtde_nan']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLD7DW9a3t-J",
        "outputId": "ac583888-6975-4f49-a1c1-c1d0ba843a64"
      },
      "source": [
        "len(df_nan[df_nan['qtde_nan']!=0])        # 46 variáveis/colunas apresentam NaN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKbN8oAZ6uRf",
        "outputId": "5d4a510a-76b9-4598-d86d-66b71d00973f"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PBBF4-719u",
        "outputId": "bd2e3929-89c5-4f4b-941b-61015797e002"
      },
      "source": [
        "df_train['ind06'].value_counts().head()     # alta correlação com 'ind32'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5441\n",
              "1.0000    4081\n",
              "0.1671      62\n",
              "0.1534      41\n",
              "0.1644      38\n",
              "Name: ind06, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyl-JR3y8B_9",
        "outputId": "5d1e8982-89c7-4a49-d77a-735e570da7da"
      },
      "source": [
        "df_train['ind32'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    6958\n",
              "1.0    4041\n",
              "Name: ind32, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyySiN6PK3iU",
        "outputId": "907b60c3-6ce4-4fd4-a96c-40b8cb143622"
      },
      "source": [
        "df_train['ind04'].value_counts().head()     # alta correlação com 'ind05'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5812\n",
              "1.0000    3151\n",
              "0.0833     532\n",
              "0.9167     258\n",
              "0.1667     224\n",
              "Name: ind04, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-2Obx4LK3xA",
        "outputId": "3d1043e4-60e6-406a-f734-ea7bb12f6d7f"
      },
      "source": [
        "df_train['ind05'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    4776\n",
              "1.0000    3161\n",
              "0.0833     434\n",
              "0.9167     250\n",
              "0.1667     179\n",
              "Name: ind05, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbhjyN3LUU2",
        "outputId": "baf93d03-285c-4688-d097-956ff3360fcf"
      },
      "source": [
        "df_train['ind03'].value_counts().head()     # alta correlação com 'ind31'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    6844\n",
              "1.0000    3642\n",
              "0.0027      21\n",
              "0.0055      12\n",
              "0.1671      11\n",
              "Name: ind03, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ZuDkAPLUgt",
        "outputId": "3e432775-b12a-41e4-fccd-f69eaabbcab3"
      },
      "source": [
        "df_train['ind31'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    7357\n",
              "1.0    3642\n",
              "Name: ind31, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrx-HSHHMyCq",
        "outputId": "55126dd1-48a4-43eb-900e-8f0db36de927"
      },
      "source": [
        "df_train['ind23'].value_counts().head()     # alta correlação com 'ind24'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5018\n",
              "1.0000    2847\n",
              "0.0833     833\n",
              "0.1667     400\n",
              "0.2500     218\n",
              "Name: ind23, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMjX8IY2MyNP",
        "outputId": "c53eb23f-5d06-435d-c8f8-92076a19f984"
      },
      "source": [
        "df_train['ind24'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5136\n",
              "1.0000    2837\n",
              "0.0833     835\n",
              "0.1667     377\n",
              "0.2500     208\n",
              "Name: ind24, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMeKN8lNUIt",
        "outputId": "cc01503e-5456-426f-ae20-6ce841716839"
      },
      "source": [
        "df_train['ind42'].value_counts().head()   #alta correlação com 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "1.0    1781\n",
              "Name: ind42, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXgzAeTgNUSM",
        "outputId": "6a572209-11ab-4302-8ccb-662e0738f363"
      },
      "source": [
        "df_train['ind43'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "0.5    1665\n",
              "1.0     116\n",
              "Name: ind43, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-xtwpcNrad",
        "outputId": "9fe5fdf5-f4f2-4bf5-d673-e3ebdacc1719"
      },
      "source": [
        "df_train['md2'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015110    8\n",
              "0.001655    7\n",
              "0.004966    6\n",
              "0.001986    6\n",
              "0.001324    5\n",
              "Name: md2, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8QRBw3Nrnf",
        "outputId": "43c65572-3f64-46bb-caab-4dd7660ad0b9"
      },
      "source": [
        "df_train['md8'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.039463    8\n",
              "0.017749    7\n",
              "0.025066    6\n",
              "0.019375    5\n",
              "0.019700    5\n",
              "Name: md8, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltYMeW-N1wG",
        "outputId": "f916e55d-abb8-46ae-b123-250e71288746"
      },
      "source": [
        "df_train['md7'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022106    8\n",
              "0.001986    7\n",
              "0.001655    6\n",
              "0.007449    6\n",
              "0.003310    5\n",
              "Name: md7, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo_VW-5a_6hL",
        "outputId": "42af1401-fa12-4e09-ddcc-c5f507918878"
      },
      "source": [
        "df_train['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv5QEKyPl0iG",
        "outputId": "35a463c7-5c68-4265-d5cd-bfb87ee1fcfa"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "cnae2     0\n",
              "rf2       0\n",
              "md1       0\n",
              "md2       0\n",
              "         ..\n",
              "ind40     0\n",
              "ind41     0\n",
              "ind42     0\n",
              "ind43     0\n",
              "target    0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxu66h0D2ZuV"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJStLm07t9u_"
      },
      "source": [
        "Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vSe45kBt9vA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WirO9VPz6tR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrodOQuDsKpc"
      },
      "source": [
        "def calcula_outliers(df):\n",
        "    Q1 = []\n",
        "    Q3 = []\n",
        "    IQR = []\n",
        "    linf = []\n",
        "    lsup = []\n",
        "    qtde_inf = []\n",
        "    qtde_sup = []\n",
        "    col = []\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        Q1.append(q1)\n",
        "        Q3.append(q3)\n",
        "        IQR.append(iqr)\n",
        "        linf.append(lim_inf)\n",
        "        lsup.append(lim_sup)\n",
        "        qtde_inf.append(len(df[df[i]<lim_inf]))\n",
        "        qtde_sup.append(len(df[df[i]>lim_sup]))\n",
        "        col.append(i)\n",
        "    return (Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6MkPFtYu7x7"
      },
      "source": [
        "Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col = calcula_outliers(df_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9t9BOagvPXU"
      },
      "source": [
        "df_outliers = pd.DataFrame(np.array([Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup]), columns=[lcol] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "0EcHYgrfzoIN",
        "outputId": "7965cfb7-0685-46e1-e75e-97fffd0f714d"
      },
      "source": [
        "df_outliers.rename(index = {0:'q1', 1:'q3', 2:'iqr', 3:'lim_inf', 4:'lim_sup', 5:'abaixo_lim_inf', 6:'acima_lim_sup'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>q1</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>q3</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iqr</th>\n",
              "      <td>0.006032</td>\n",
              "      <td>0.010318</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013209</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.016188</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_inf</th>\n",
              "      <td>-0.009046</td>\n",
              "      <td>-0.013055</td>\n",
              "      <td>0.098338</td>\n",
              "      <td>-0.016855</td>\n",
              "      <td>-0.006283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.016656</td>\n",
              "      <td>0.002453</td>\n",
              "      <td>-0.024269</td>\n",
              "      <td>-0.010959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.001895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_sup</th>\n",
              "      <td>0.015083</td>\n",
              "      <td>0.028217</td>\n",
              "      <td>0.129641</td>\n",
              "      <td>0.028091</td>\n",
              "      <td>0.010472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036180</td>\n",
              "      <td>0.050965</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.018265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138690</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abaixo_lim_inf</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acima_lim_sup</th>\n",
              "      <td>1658.000000</td>\n",
              "      <td>1181.000000</td>\n",
              "      <td>1203.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1718.000000</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1110.000000</td>\n",
              "      <td>1098.000000</td>\n",
              "      <td>1129.000000</td>\n",
              "      <td>1578.000000</td>\n",
              "      <td>339.0</td>\n",
              "      <td>1297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1233.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        md1          md2          md3  ... ind41 ind42 ind43\n",
              "q1                 0.000003     0.002422     0.110077  ...   NaN   NaN   NaN\n",
              "q3                 0.006035     0.012740     0.117903  ...   NaN   NaN   NaN\n",
              "iqr                0.006032     0.010318     0.007826  ...   NaN   NaN   NaN\n",
              "lim_inf           -0.009046    -0.013055     0.098338  ...   NaN   NaN   NaN\n",
              "lim_sup            0.015083     0.028217     0.129641  ...   NaN   NaN   NaN\n",
              "abaixo_lim_inf     0.000000     0.000000     4.000000  ...   0.0   0.0   0.0\n",
              "acima_lim_sup   1658.000000  1181.000000  1203.000000  ...   0.0   0.0   0.0\n",
              "\n",
              "[7 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "j004R47yzwCU",
        "outputId": "03cf0785-03b9-4384-d70d-a2aa4ad79054"
      },
      "source": [
        "df_train.drop(['id','cnae2'],axis=1,inplace=False).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001607</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106393</td>\n",
              "      <td>0.156942</td>\n",
              "      <td>0.345577</td>\n",
              "      <td>0.363809</td>\n",
              "      <td>0.377947</td>\n",
              "      <td>0.396748</td>\n",
              "      <td>0.304172</td>\n",
              "      <td>0.354500</td>\n",
              "      <td>0.007431</td>\n",
              "      <td>0.001371</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.170026</td>\n",
              "      <td>0.034449</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.003777</td>\n",
              "      <td>0.014728</td>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.695732</td>\n",
              "      <td>0.701113</td>\n",
              "      <td>0.555893</td>\n",
              "      <td>0.540622</td>\n",
              "      <td>0.325660</td>\n",
              "      <td>0.319979</td>\n",
              "      <td>0.094443</td>\n",
              "      <td>0.573265</td>\n",
              "      <td>0.549543</td>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.330101</td>\n",
              "      <td>0.366265</td>\n",
              "      <td>0.999184</td>\n",
              "      <td>0.487537</td>\n",
              "      <td>0.911266</td>\n",
              "      <td>0.730536</td>\n",
              "      <td>0.660654</td>\n",
              "      <td>0.004804</td>\n",
              "      <td>0.126892</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.161425</td>\n",
              "      <td>0.085969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012535</td>\n",
              "      <td>0.012276</td>\n",
              "      <td>0.013302</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305507</td>\n",
              "      <td>0.314749</td>\n",
              "      <td>0.469850</td>\n",
              "      <td>0.451344</td>\n",
              "      <td>0.448622</td>\n",
              "      <td>0.472732</td>\n",
              "      <td>0.430218</td>\n",
              "      <td>0.440494</td>\n",
              "      <td>0.068959</td>\n",
              "      <td>0.031765</td>\n",
              "      <td>0.029217</td>\n",
              "      <td>0.311906</td>\n",
              "      <td>0.322485</td>\n",
              "      <td>0.160898</td>\n",
              "      <td>0.129652</td>\n",
              "      <td>0.059707</td>\n",
              "      <td>0.117835</td>\n",
              "      <td>0.062471</td>\n",
              "      <td>0.451710</td>\n",
              "      <td>0.450337</td>\n",
              "      <td>0.445655</td>\n",
              "      <td>0.444689</td>\n",
              "      <td>0.425934</td>\n",
              "      <td>0.426005</td>\n",
              "      <td>0.217015</td>\n",
              "      <td>0.413842</td>\n",
              "      <td>0.401642</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.013319</td>\n",
              "      <td>0.018179</td>\n",
              "      <td>0.470270</td>\n",
              "      <td>0.481805</td>\n",
              "      <td>0.028551</td>\n",
              "      <td>0.499867</td>\n",
              "      <td>0.284372</td>\n",
              "      <td>0.443702</td>\n",
              "      <td>0.473509</td>\n",
              "      <td>0.069146</td>\n",
              "      <td>0.332867</td>\n",
              "      <td>0.016488</td>\n",
              "      <td>0.009520</td>\n",
              "      <td>0.367939</td>\n",
              "      <td>0.202125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.138900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860800</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                md1           md2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  11033.000000  11033.000000\n",
              "mean       0.011670      0.012928  ...      0.161425      0.085969\n",
              "std        0.041618      0.026515  ...      0.367939      0.202125\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.000003      0.002422  ...      0.000000      0.000000\n",
              "50%        0.000316      0.005415  ...      0.000000      0.000000\n",
              "75%        0.006035      0.012740  ...      0.000000      0.000000\n",
              "max        1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJF8Q05rbSF",
        "outputId": "d9835c6f-551b-4605-ab2f-9ff7464e9c1b"
      },
      "source": [
        "df_test.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JWJ0Z3ZBT8x",
        "outputId": "82b334d4-5001-4a31-c9f8-914aeab58285"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqmeyNYfBUkz"
      },
      "source": [
        "def f_trata_outliers(df):\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        df[i][df[i] < lim_inf] = lim_inf\n",
        "        df[i][df[i] > lim_sup] = lim_sup\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN--_ZdBdAb"
      },
      "source": [
        "f_trata_outliers(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6RCkr7CSAO"
      },
      "source": [
        "f_trata_outliers(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Y2TJ-Gt9vE"
      },
      "source": [
        "# função que trata NaN:\n",
        "def f_trata_NaN(df):\n",
        "    coluna_nan = df.isna().sum()[df.isna().sum().values>0].index\n",
        "    for col in coluna_nan:\n",
        "      df[col] = df[col].fillna(df[col].median())\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-4KOA0t9vK"
      },
      "source": [
        "# tratando NaN nos dataframes df_train e df_test:\n",
        "df_train = f_trata_NaN(df_train)\n",
        "df_test = f_trata_NaN(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0E1CSAYnch8"
      },
      "source": [
        "# criando dummies em df_train e df_test:\n",
        "df_train = pd.get_dummies(df_train, drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, drop_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Es33OXkQnyLc",
        "outputId": "0ea8aa72-ca3f-42fb-cd96-8ef1648ecbe8"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\":{df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 72), \"df_test.shape:\":(1000, 71)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWjvdF3F2Xs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU4mjAscF4Ge"
      },
      "source": [
        "### PULAR PARA PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3tEEKJF2pO"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfiez91PF20t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj5Nlm_iEggt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e32c74e-508b-4c85-bffb-13cdcc9e345e"
      },
      "source": [
        "df_train['target'].astype('category')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         True\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "11028    False\n",
              "11029    False\n",
              "11030     True\n",
              "11031    False\n",
              "11032     True\n",
              "Name: target, Length: 11033, dtype: category\n",
              "Categories (2, object): [False, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i57fUZmDt9vP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9098a979-065d-4cf5-90bd-977906908a55"
      },
      "source": [
        "# definindo X (sem 'id' e 'target'), y (variável target) e X_submit (sem 'id'): \n",
        "X = df_train.drop(columns= ['id','target'], axis= 1)\n",
        "y = df_train['target']\n",
        "X_submit = df_test.drop(columns='id',axis=1)\n",
        "\n",
        "f'\"X.shape:\":{X.shape}, \"y.shape:\":{y.shape}, \"X_submit.shape:\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X.shape:\":(11033, 70), \"y.shape:\":(11033,), \"X_submit.shape:\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsYMnSZXKogI",
        "outputId": "050ed15b-a6a2-48f3-e15e-f3250de8b219"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cnae2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8', 'md9',\n",
              "       'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4', 'ind01', 'ind02',\n",
              "       'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
              "       'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18',\n",
              "       'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26',\n",
              "       'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32', 'ind33', 'ind34',\n",
              "       'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40', 'ind41', 'ind42',\n",
              "       'ind43', 'rf2_d', 'rf2_i', 'rf2_k', 'rf2_p', 'rf2_q', 'rf2_r', 'rf2_s',\n",
              "       'rf2_v', 'rf2_y', 'rf2_z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8J8ej6t9vT"
      },
      "source": [
        "MODELO: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpaBkXMzmLwh"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsRI-rGxmnQC"
      },
      "source": [
        "# Função para cross validation:\n",
        "def funcao_cross_val_score(modelo, X_treinamento, y_treinamento, CV):\n",
        "    #versão com cross_val_score::\n",
        "    a_scores_CV = cross_val_score(modelo, X_treinamento, y_treinamento, cv = CV)\n",
        "    print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "    print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "    return a_scores_CV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaez67ksHsc0"
      },
      "source": [
        "# Função para Confusion Matrix:\n",
        "from sklearn.metrics import confusion_matrix \n",
        "def mostra_confusion_matrix(cf, \n",
        "                            group_names = None, \n",
        "                            categories = 'auto', \n",
        "                            count = True, \n",
        "                            percent = True, \n",
        "                            cbar = True, \n",
        "                            xyticks = False, \n",
        "                            xyplotlabels = True, \n",
        "                            sum_stats = True, \n",
        "                            figsize = (8, 8), \n",
        "                            cmap = 'Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_8spMrGt9vU"
      },
      "source": [
        "i_CV = 10 # Número de Cross-Validations\n",
        "i_Seed = 22091980 # semente por questões de reproducibilidade\n",
        "f_Test_Size = 0.3 # Proporção do dataframe de validação (outros valores poderiam ser 0.15, 0.20 ou 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDY6msH0t9vY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "864288a8-1c95-4378-93a6-c0ace2604968"
      },
      "source": [
        "# Definindo dataframes de TREINAMENTO e TESTE a partir de X e y:\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = f_Test_Size, random_state = i_Seed)\n",
        "f'\"X_treinamento.shape:\" {X_treinamento.shape}, \"y_treinamento_shape:\"{y_treinamento.shape},\"X_teste.shape:\"{X_teste.shape},\"y_teste.shape:\"{y_teste.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento.shape:\" (7723, 70), \"y_treinamento_shape:\"(7723,),\"X_teste.shape:\"(3310, 70),\"y_teste.shape:\"(3310,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjUjFaykt9vf"
      },
      "source": [
        "# Instancia...\n",
        "ml_XGB= XGBClassifier(silent=False,\n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 1,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=1000, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth= 3, \n",
        "                      gamma=1, \n",
        "                      max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTFhHr6Ar4mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623d16c7-d681-46a3-f908-a035a9fc2c8b"
      },
      "source": [
        "# Modelo treinado sobre base \"train-split-test\"\n",
        "ml_XGB.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
              "              learning_rate=0.01, max_delta_step=5, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=False, subsample=0.8, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EH4l3lAt9vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6bc8da-8467-4c10-ceb3-4d79613a7dc6"
      },
      "source": [
        "# Chamando a função do CROSS VALIDATION - Modelo treinado sobre base \"train-split-test\":\n",
        "\n",
        "a_scores_CV = funcao_cross_val_score(ml_XGB, X_treinamento, y_treinamento, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média das Acurácias calculadas pelo CV....: 77.39\n",
            "std médio das Acurácias calculadas pelo CV: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHujyPesnWF",
        "outputId": "9c5bcd70-b10e-46fd-bcc1-af15cf57f38d"
      },
      "source": [
        "y_pred = ml_XGB.predict(X_teste)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3185  125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TXeOdfIsPkp",
        "outputId": "2587031c-0e86-4569-eec6-6a4beb2d825f"
      },
      "source": [
        "y_submit_0 = ml_XGB.predict(X_submit)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_0, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Mr2xE0EMnQ"
      },
      "source": [
        "# CV com X_treinamento e y_treinamento:       # Modelo treinado sobre base \"train-split-test\"\n",
        "# Acurácia Média / STD médio\n",
        "# 77,38 / 0,54  tirando outliers - 70% X\n",
        "# 77,39 / 0,51  sem tirar outliers - 70% X\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste)\n",
        "# 0: 3177, 1: 133 => tirando outliers de df_train - 30% X\n",
        "# 0: 3185, 1: 125 => sem tirar outliers de df_train - 30% X\n",
        "\n",
        "# y_submit = ml_XGB.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "#  ???????????  => tirando outliers de df_train (não rodei)\n",
        "# 0: 952, 1: 48 => sem tirar outliers de df_train (70% X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "iQhLNFkyt9v5",
        "outputId": "5de1fb25-c83b-4706-c3e7-06fcabda7dbd"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "********* CONFUSION MATRIX - PARAMETER TUNNING ***********\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKFg_7V13qj"
      },
      "source": [
        "### Treinando o modelo sobre toda a base (100% de df_train, X_treinamento = 100% X, y_treinamento = 100% y)\n",
        "ml_XGB.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyMkW8EB-s1U"
      },
      "source": [
        "ml_XGB_1 = XGBClassifier(silent=False,\n",
        "                         scale_pos_weight=1,\n",
        "                         learning_rate=0.01,  \n",
        "                         colsample_bytree = 1,\n",
        "                         subsample = 0.8,\n",
        "                         objective='binary:logistic', \n",
        "                         n_estimators=1000, \n",
        "                         reg_alpha = 0.3,\n",
        "                         max_depth= 3, \n",
        "                         gamma=1, \n",
        "                         max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1AWis2Xt9v-"
      },
      "source": [
        "# treinando o modelo sobre toda a base X (100% de df_train)\n",
        "ml_XGB1.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsWDYOunJXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382f9662-bae4-4563-fbf8-1beae73a3be6"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média das Acurácias calculadas pelo CV....: 77.8\n",
            "std médio das Acurácias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTnHowjpQTQ"
      },
      "source": [
        "# ml_XGB_1                            # Modelo treinado sobre X e y (100% df_train)\n",
        "\n",
        "# CV com X e y:                                             # Modelo treinado sobre toda base X (100% df_train)\n",
        "# AcuráciaMédia / STD médio\n",
        "# ??????????? => tirando outliers\n",
        "# 77,80 / 0,559  => sem tirar outliers\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste) ====> X_teste (% sobre X)\n",
        "# 0: 3194, 1: 116 => tirando outliers de df_train\n",
        "# 0: 3199, 1: 111 => sem tirar outliers de df_train\n",
        "\n",
        "# y_submit calculado com modelo treinado sobre TODA A BASE 'X' (100% df_train):\n",
        "\n",
        "# y_submit = ml_XGB_1.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "# 0: 955, 1: 45 => tirando outliers de df_train ==> PyLadies.csv com pontuação = 0,4610\n",
        "# 0: 956, 1: 44 => sem tirar outliers de df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uUSripHII-8",
        "outputId": "7257fa2c-54cd-41af-f7f5-32174e77b062"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média das Acurácias calculadas pelo CV....: 77.8\n",
            "std médio das Acurácias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzvFPvCuJNbG",
        "outputId": "84b321e3-02cd-4324-cf97-c46e948b13fd"
      },
      "source": [
        "y_pred_1 = ml_XGB_1.predict(X_teste)\n",
        "unique_elements, counts_elements = np.unique(y_pred_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3199  111]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53EqCaJgJsGg"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred_1)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bafMtn3IQzi",
        "outputId": "be823d3f-a9b3-42a9-a060-1d40a478b53c"
      },
      "source": [
        "y_submit_1 = ml_XGB_1.predict(X_submit)\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9LGBShGt9wQ"
      },
      "source": [
        "df_submit_1 = pd.DataFrame(zip(df_test['id'],y_submit_1), columns = ['id','target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "MzStMVKLt9wU",
        "outputId": "cd759c29-e9a3-496d-cd20-763741fdae63"
      },
      "source": [
        "df_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  target\n",
              "0  3411   False\n",
              "1  2177   False\n",
              "2  8400   False\n",
              "3   464   False\n",
              "4  6672   False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUM9gFa1t9wa"
      },
      "source": [
        "df_submit_1.to_csv('PyLadies.csv',index = False, sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3zYdWgrzaOg"
      },
      "source": [
        "### LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llWEkYjWzZZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732a26e2-e18d-416c-eef9-4bbd8a658a30"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmo-OjUYzZl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892f8e50-78ea-4ec8-dcdb-2b9343f6d26f"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |████████████████████████████████| 66.3MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQmrMW_zpAi"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNuQMi0Lz9Gg"
      },
      "source": [
        "X_train = X\n",
        "y_train = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDTQPmLA2ANY"
      },
      "source": [
        "X_test = X_submit\n",
        "y_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-uejECUyItk"
      },
      "source": [
        "# Preprocessing our data\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#tfidf = TfidfVectorizer(max_features=2000)\n",
        "#X_train = tfidf.fit_transform(df_train).toarray()\n",
        "#X_test = tfidf.transform(df_test).toarray()\n",
        "#y_train, y_test = df_train, df_test\n",
        "X_train_sub, X_valid, y_train_sub, y_valid = train_test_split(X_train, y_train, test_size=0.5,random_state=1234)\n",
        "# Setting up our results dataframe\n",
        "df_results = pd.DataFrame(columns=['accuracy', 'run_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOVl-3DayIt6"
      },
      "source": [
        "lgbm = LGBMClassifier(n_estimators=2000,\n",
        "                      feature_fraction=0.06,\n",
        "                      bagging_fraction=0.67,\n",
        "                      bagging_freq=1,\n",
        "                      verbose=0,\n",
        "                      n_jobs=6,\n",
        "                      random_state=1234,\n",
        "                      force_row_wise=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kB4dRc2yIt6"
      },
      "source": [
        "cb = CatBoostClassifier(n_estimators=2000,\n",
        "                        colsample_bylevel=0.06,\n",
        "                        max_leaves=31,\n",
        "                        subsample=0.67,\n",
        "                        verbose=0,\n",
        "                        thread_count=6,\n",
        "                        random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-enhLnbPyIt6"
      },
      "source": [
        "models = [lgbm, cb]\n",
        "model_names = [i.__class__.__name__ for i in models]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIujmOn_yIt6"
      },
      "source": [
        "es_models = ['LGBMClassifier',\n",
        "             'CatBoostClassifier']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptnWWC5ByIt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a23ffe-8e1c-44e0-d156-d109f8b2fe66"
      },
      "source": [
        "for m, n in zip(models, model_names):\n",
        "    \n",
        "    start_time = time()\n",
        "    if n in es_models:\n",
        "        m.fit(X_train_sub,\n",
        "              y_train_sub,\n",
        "              eval_set = [(X_valid, y_valid)],\n",
        "              early_stopping_rounds=15,\n",
        "              verbose=0)\n",
        "    else:\n",
        "        m.fit(X_train, y_train)\n",
        "    \n",
        "    run_time = time() - start_time\n",
        "    accuracy = np.mean(m.predict(X_test) == y_test)\n",
        "        \n",
        "    df_results.loc[n] = [accuracy, run_time]\n",
        "    \n",
        "    del m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsoMfK1dyIt_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ffba49ac-bc08-48ee-958c-ce1693a63fd4"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.917237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoostClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.017664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  run_time\n",
              "LGBMClassifier           0.0  0.917237\n",
              "CatBoostClassifier       0.0  2.017664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAoPBG4WyIuA"
      },
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJO5N2i8yIuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc4f76f-d7c2-408a-e2ea-5e2ddb2a7adc"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_lgbm, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [961  39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wBQ5TByIuA"
      },
      "source": [
        "y_pred_cb = cb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjEtLNQKyIuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fa58f0-da53-4ba6-c995-d18d25182939"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_cb, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [965 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PsK2T-H7DZY"
      },
      "source": [
        "### ZENILSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lGpednyItU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c12_fw4I7TAt"
      },
      "source": [
        "i_Seed = 19961108\n",
        "\n",
        "preditoras = X\n",
        "target = y\n",
        "df_testeTratado = X_submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oACaNC2F9yD6"
      },
      "source": [
        "df_testeTratado.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbmI06k3yItY"
      },
      "source": [
        "## Aqui, como passo intermediário, executei o modelo usando o dataframe default (getDataFrameDefault) e analisei a importância das features:\n",
        "## então fui modificando o dataframe excluindo as features menos importantes...\n",
        "## OBS: para utilizar, carregar antes a função treina_testa\n",
        "'''\n",
        "df_default = otdf_Treino.getDataFrameDefault()\n",
        "preditoras = df_default.copy()\n",
        "preditoras.drop(columns=[\"Churn\",\"id\"],inplace=True)\n",
        "target = df_treinoTratado[\"Churn\"]\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0] #considerei todas as features que não são do tipo \"flutuante\" como categóricas\n",
        "print(f\"Qtde de features categóricas: {len(categorical_features_indices)}\")\n",
        "print(f\"Colunas preditoras: {preditoras.columns}\")\n",
        "\n",
        "acc = treina_testa(mostrarFI=True)\n",
        "print(f\"acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5oQMioHz93b"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mew6XsGRyItW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4bb2f9-06ad-4394-9e8e-5d5cc292b8ba"
      },
      "source": [
        "#considerei todas as features que não são do tipo \"flutuante\" como categóricas\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0]\n",
        "len(categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0JVbdH89w1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "75e5259a-2030-4858-83f1-ea56124d2eaf"
      },
      "source": [
        "acc = treina_testa(mostrarFI=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-d21779ef0020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-648fed880d09>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'bool' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEf7qd9yItW"
      },
      "source": [
        "ts=0.30\n",
        "it=300\n",
        "lr=0.03\n",
        "depth=5\n",
        "gerarArquivo=False\n",
        "mostrarFI=False\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg1ZO8CoyItX"
      },
      "source": [
        "catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oer3P4jcyItX"
      },
      "source": [
        "catb_tuned = catb.fit(X_treinamento, y_treinamento) # cat_features=categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITg22JTLyItY"
      },
      "source": [
        "y_pred = catb_tuned.predict(X_submit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS_5F2K4yItY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3dccaa-29d4-4911-a30f-26f6661740bd"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [963 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNshKeM8qKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11aa5ab0-d619-4186-d397-8385c720a5fb"
      },
      "source": [
        "categorical_features_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1y8ZaNQyItZ"
      },
      "source": [
        "def treina_testa(ts=0.30,it=300, lr=0.03, depth=5, gerarArquivo=False, mostrarFI=False):\n",
        "   X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)#, random_state = i_Seed)\n",
        "   catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)\n",
        "   catb_tuned = catb.fit(  X_treinamento, y_treinamento, cat_features=categorical_features_indices)\n",
        "   y_pred = catb_tuned.predict(X_submit)\n",
        "   acc_catb = round(accuracy_score(y_pred, y_teste) * 100, 2)\n",
        "   #print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\n",
        "   if (mostrarFI == True):\n",
        "      l_fi = list(zip(catb_tuned.feature_importances_,X_treinamento.columns))\n",
        "      print(l_fi)\n",
        "\n",
        "   if gerarArquivo == True: \n",
        "      df_id = df_test[[\"id\"]]\n",
        "      df_teste3 = df_testeTratado #.drop(columns=[\"id\"],axis=1)\n",
        "      resposta = catb_tuned.predict(df_teste3)\n",
        "      resposta_df = pd.DataFrame(resposta, columns=['target'])\n",
        "      resultado_submissao = pd.concat([df_id, resposta_df],axis=1)\n",
        "      resultado_submissao.head().T\n",
        "      filename = 'submissao_kaggle_catb_fs_ts0{}_it{}_lr{}_depth{}_sc{}.csv'.format(round(ts*100,0),it, lr, depth,str(int(acc_catb*100)))\n",
        "      resultado_submissao.to_csv(filename, index=False)   \n",
        "      print(filename)\n",
        "   return acc_catb   \n",
        "   #result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHlX8NFSBDwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f84da2ec-226a-455d-e82c-8d2d5a7fb96a"
      },
      "source": [
        "f'\"X_treinamento=\" : {X_treinamento.shape}, \"y_treinamento=\" : {y_treinamento.shape}, \"X_teste=\":{X_teste.shape},\"y_teste=\":{y_teste.shape},\"X_submit=\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento=\" : (7723, 70), \"y_treinamento=\" : (7723,), \"X_teste=\":(3310, 70),\"y_teste=\":(3310,),\"X_submit=\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlK6ScvayItZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "2de6fc56-250a-42ac-9318-5121166b6373"
      },
      "source": [
        "#l_ts = [0.22, 0.24, 0.25, 0.26, 0.28, 0.30, 0.32]\n",
        "#l_it =  [300, 400, 500], \n",
        "#l_lr = [0.02, 0.03, 0.04]\n",
        "#l_depth = [2, 3, 4, 5]\n",
        "l_ts, l_it, l_lr, l_depth = [0.26], [400], [0.02], [3]\n",
        "resultado = {}\n",
        "\n",
        "for vez in range(1,11):\n",
        "   resultado[vez] = {\"ts\":[], \"it\":[], \"lr\":[],\"depth\":[],\"score\":[]}\n",
        "   for ts in l_ts:\n",
        "       print(f'execução {vez}/ts {ts}...')\n",
        "       for it in l_it:\n",
        "           for lr in l_lr:\n",
        "               for depth in l_depth:\n",
        "                  res = treina_testa(ts=ts, it=it, lr=lr, depth=depth,gerarArquivo=False, mostrarFI=False) #não vai salvar o arquivo e nem mostrar as melhores features\n",
        "                  resultado[vez][\"ts\"].append(ts)\n",
        "                  resultado[vez][\"it\"].append(it)\n",
        "                  resultado[vez][\"lr\"].append(lr)\n",
        "                  resultado[vez][\"depth\"].append(depth)\n",
        "                  resultado[vez][\"score\"].append(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execução 1/ts 0.26...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-c7cedf244408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgerarArquivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#não vai salvar o arquivo e nem mostrar as melhores features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"it\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-cd249ff4f9ff>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 2869]"
          ]
        }
      ]
    }
  ]
}