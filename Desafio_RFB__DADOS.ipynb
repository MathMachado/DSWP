{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio_RFB__24nov.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35cca5020958401ea7c5bb34acd75ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3969d5f088a944e8b0d94fbe3c22c3a4",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a7eb722101d4220ab88251c24ab23bb"
          }
        },
        "3969d5f088a944e8b0d94fbe3c22c3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a7eb722101d4220ab88251c24ab23bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c22860729c4541428af37ec5c3823a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_6e824fe387ce4d8488959cd93632cfe6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6093948d2ad14c5a8ee575a291af15c5"
          }
        },
        "6e824fe387ce4d8488959cd93632cfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6093948d2ad14c5a8ee575a291af15c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f063cd207c264378afdaf29f0e9d1476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10427716ad9b4806a71095361fc3a6cf",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 79,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 79,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9eb0636962274335985e4c0f01fc0b5d"
          }
        },
        "10427716ad9b4806a71095361fc3a6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9eb0636962274335985e4c0f01fc0b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60562d130e344b4e996c4a3cc6aea22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b3a6bd5c33b4c648c083a8b9cb8100b",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ee86fc6bfb14a1792146ea56920447a"
          }
        },
        "7b3a6bd5c33b4c648c083a8b9cb8100b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ee86fc6bfb14a1792146ea56920447a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "704290000a4e40788bd9e0cc0373f217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83fe8d1efce3423ab379c058ccb0cdb7",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 7,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeaee4beeaaf454c833b431890a8d1e4"
          }
        },
        "83fe8d1efce3423ab379c058ccb0cdb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeaee4beeaaf454c833b431890a8d1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOPOEiuuXb-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Z0klE9on9bLm",
        "outputId": "8b68d828-1d46-4f39-efbd-30eefc4c5668"
      },
      "source": [
        "url_train_tr = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/train_01.csv'\n",
        "url_test_tr = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/test_01.csv'\n",
        "df_train = pd.read_csv(url_train_tr)\n",
        "df_test = pd.read_csv(url_test_tr)\n",
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\":{df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 54), \"df_test.shape:\":(1000, 53)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8cwg7LKeWwe"
      },
      "source": [
        "# para informar no pycaret:\n",
        "l_categorica = ['cnae_secao', 'ind28', 'ind31', 'ind32', 'ind34',  'ind35', 'ind36', 'ind37', 'ind39', 'ind42', 'ind43']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arpXjjKmewYf"
      },
      "source": [
        "#df_total = pd.get_dummies(df_total, drop_first=False)\n",
        "#f'\"df_total.shape:\":{df_total.shape}'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cg0y_ylqAweG",
        "outputId": "992a8a42-eb80-4d30-f7ac-4147fda6d5f3"
      },
      "source": [
        "df_train.set_index('id', inplace=True)\n",
        "df_test.set_index('id',inplace=True)\n",
        "\n",
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 53), \"df_test.shape:\": (1000, 52)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp3lzZ3KMQYW"
      },
      "source": [
        "## PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F9_sJ10M9-G",
        "outputId": "5a6829b5-e07d-485b-fd72-706d6259901f"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycaret\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/d0/390ff0f120c05795d45b353cedc81120f9c6558aae285a73e8fab62f322d/pycaret-2.2.1-py3-none-any.whl (248kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256kB 5.4MB/s \n",
            "\u001b[?25hCollecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/69/c6b3911ccb421adc779390ca2ea54cb888a54e282d50e8d20ce751b5c7ab/mlflow-1.12.1-py3-none-any.whl (13.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.9MB 275kB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.18.5)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Collecting lightgbm>=2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/4d/99073804bd31f15678f24a79e96981dcbaa840bc9926dfd132e9638d51bb/lightgbm-3.1.0-py2.py3-none-manylinux1_x86_64.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 40.6MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.8MB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.5)\n",
            "Collecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/1d/22a6c4e796fff1066bf80bf59b4494d6e3582e22012a61721f4cb730b3c3/pyod-0.8.4.tar.gz (98kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 8.5MB/s \n",
            "\u001b[?25hCollecting kmodes>=0.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/55/d8ec1ae1f7e1e202a8a4184c6852a3ee993b202b0459672c699d0ac18fc8/kmodes-0.10.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.5.0)\n",
            "Collecting xgboost>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/cc/fd3d5fc6b6616a03385a0f6492cc77a253940d1026406ecc07597095e381/xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 148.9MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.11.0)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (4.4.1)\n",
            "Collecting imbalanced-learn>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl (167kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.2)\n",
            "Collecting yellowbrick>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/ad/ae6744ddb9c7053916bed95430152b9a41b7d410e16a1cc7cd744a611d90/yellowbrick-1.2-py3-none-any.whl (269kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276kB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.4.6)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.3)\n",
            "Collecting catboost>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.3MB 60kB/s \n",
            "\u001b[?25hRequirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.14.0)\n",
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6MB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret) (7.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.0)\n",
            "Collecting pandas-profiling>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/79/5d03ed1172e3e67a997a6a795bcdd2ab58f84851969d01a91455383795b6/pandas_profiling-2.9.0-py2.py3-none-any.whl (258kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.1.4)\n",
            "Collecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/b7/eb7b7138bb5e6d28cf84fa586fe594619ca097b6207caa5f2ebe0c66a4ed/docker-4.4.0-py2.py3-none-any.whl (146kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.13)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.12.4)\n",
            "Collecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.1.2)\n",
            "Collecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 9.2MB/s \n",
            "\u001b[?25hCollecting azure-storage-blob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/5d/0bb4ed37da2523c393789b1d8ecbf56b1d35fa344af30fe423da2c06cbe9/azure_storage_blob-12.6.0-py2.py3-none-any.whl (328kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 337kB 45.8MB/s \n",
            "\u001b[?25hCollecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/88/ae1f78cf582b707c605c77df49b4c8786a4465edc51adb25d2f98ef4c4de/databricks-cli-0.14.1.tar.gz (54kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (2.8.1)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
            "Collecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.15.0)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.20)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (1.4.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (50.3.2)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Collecting combo\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/2a/61b6ac584e75d8df16dc27962aa5fe99d76b09da5b6710e83d4862c84001/combo-0.1.1.tar.gz\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.48.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Collecting suod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/87/9170cabe1b5e10a7d095c0e28f2e30e7c1886a13f063de85d3cfacc06f4b/suod-0.0.4.tar.gz (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (3.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret) (7.0.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (0.10.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (0.10.1)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.35.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (5.0.8)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Collecting tangled-up-in-unicode>=0.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/e2/e588ab9298d4989ce7fdb2b97d18aac878d99dbdc379a4476a09d9271b68/tangled_up_in_unicode-0.0.6-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1MB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (20.3.0)\n",
            "Collecting confuse>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/55/b4726d81e5d6509fa3441f770f8a9524612627dc1b2a7d6209d1d20083fe/confuse-1.4.0-py2.py3-none-any.whl\n",
            "Collecting visions[type_image_path]==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e3/9416e94e767d59a86edcbcb8e1c8f42874d272c3b343676074879e9db0e0/visions-0.5.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 8.2MB/s \n",
            "\u001b[?25hCollecting phik>=0.9.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/5a/7ef1c04ce62cd72f900c06298dc2385840550d5c653a0dbc19109a5477e6/phik-0.10.0-py3-none-any.whl (599kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 604kB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (2020.11.8)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Collecting msrest>=0.6.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/f5/9e315fe8cb985b0ce052b34bcb767883dc739f46fadb62f05a7e6d6eedbe/msrest-0.6.19-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 10.0MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a2/6565c5271a79e3c96d7a079053b4d8408a740d4bf365f0f5f244a807bd09/cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.6MB 45.6MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/4b/ea7faaafac956a168ab9a95a7ebe583f9d308e8332a68af0ed3128ef520c/azure_core-1.9.0-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.7)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.9.0)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 6.6MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->pycaret) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.6.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod->pycaret) (0.31.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis->pycaret) (1.1.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (8.6.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.7.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (2.5)\n",
            "Collecting imagehash; extra == \"type_image_path\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/9dbb772b5ef73a3069c66bb5bf29b9fb4dd57af0d5790c781c3f559bcca6/ImageHash-4.2.0-py2.py3-none-any.whl (295kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (1.3.0)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (1.14.3)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (20.0.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (3.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (2.20)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.2.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.4)\n",
            "Building wheels for collected packages: pyod, pyLDAvis, databricks-cli, prometheus-flask-exporter, alembic, combo, suod, htmlmin\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.4-cp36-none-any.whl size=112083 sha256=ee05badd340e67f7185258e1c98478d4423fb3090d93fbf27a9a9dd9b2850a93\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/31/0a/c2d4ba2d066145c55f0cb2846e59b18d874cb59c5d9adc81cf\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=b756237a7c6ca05bbaed8e03a5e7221f7917cfeaf0646153dca6c8bc7818b24f\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.1-cp36-none-any.whl size=100579 sha256=ee6bb52ad9bc075606d240af73066b0353e716b75efba0a5041158dcc11b82e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/91/ac/5d417ee5ccbb76c8cca096cf4cfb9ed9d49d889d1d1ca0fc39\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp36-none-any.whl size=17157 sha256=161eb1e741b758528eb5eb3e7c122035ad6c8e54d2871016b7c1ae3a88bb82dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=8ac62b824b08ca52e285a5f9ce645be7e604fe23150324f3049e1ef4b49add2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.1-cp36-none-any.whl size=42113 sha256=0d421bf6ad48e5e94b38d813562820c5cbe1e5655421456ff0079c1003961918\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/ec/e5/a2331372c676c467e70c6646e646edf6997d5c4905b8c0f5e6\n",
            "  Building wheel for suod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suod: filename=suod-0.0.4-cp36-none-any.whl size=2167158 sha256=06dcd81e6452d4731e606a460c7cc81c44b47425cbef8610a93210816bc6f349\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/55/e5/a4fca65bba231f6d0115059b589148774b41faea25b3f2aa27\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=acd51a104d5d5c66f2ae34ed2b2b1131fd1f61b19379f70c4bddd4249d25fec8\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "Successfully built pyod pyLDAvis databricks-cli prometheus-flask-exporter alembic combo suod htmlmin\n",
            "\u001b[31mERROR: pandas-profiling 2.9.0 has requirement tqdm>=4.43.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: websocket-client, docker, querystring-parser, gunicorn, isodate, msrest, cryptography, azure-core, azure-storage-blob, databricks-cli, smmap, gitdb, gitpython, prometheus-flask-exporter, Mako, python-editor, alembic, mlflow, threadpoolctl, scikit-learn, scikit-plot, lightgbm, combo, suod, pyod, kmodes, xgboost, imbalanced-learn, yellowbrick, catboost, funcy, pyLDAvis, tangled-up-in-unicode, confuse, imagehash, visions, phik, htmlmin, pandas-profiling, pycaret\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "  Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.1 azure-core-1.9.0 azure-storage-blob-12.6.0 catboost-0.24.3 combo-0.1.1 confuse-1.4.0 cryptography-3.2.1 databricks-cli-0.14.1 docker-4.4.0 funcy-1.15 gitdb-4.0.5 gitpython-3.1.11 gunicorn-20.0.4 htmlmin-0.1.12 imagehash-4.2.0 imbalanced-learn-0.7.0 isodate-0.6.0 kmodes-0.10.2 lightgbm-3.1.0 mlflow-1.12.1 msrest-0.6.19 pandas-profiling-2.9.0 phik-0.10.0 prometheus-flask-exporter-0.18.1 pyLDAvis-2.1.2 pycaret-2.2.1 pyod-0.8.4 python-editor-1.0.4 querystring-parser-1.2.4 scikit-learn-0.23.2 scikit-plot-0.3.7 smmap-3.0.4 suod-0.0.4 tangled-up-in-unicode-0.0.6 threadpoolctl-2.1.0 visions-0.5.0 websocket-client-0.57.0 xgboost-1.2.1 yellowbrick-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAjtbymSkJ2"
      },
      "source": [
        "# Carregar bibliotecas\n",
        "import pycaret\n",
        "from pycaret.classification import *                                       \n",
        "from pycaret.regression import *                      \n",
        "from pycaret.utils import enable_colab                # Para executar grÃ¡ficos no Colab\n",
        "from pycaret import classification as pyclass \n",
        "from pycaret import regression as pyreg\n",
        "from sklearn.model_selection import train_test_split  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "35cca5020958401ea7c5bb34acd75ff4",
            "3969d5f088a944e8b0d94fbe3c22c3a4",
            "3a7eb722101d4220ab88251c24ab23bb",
            "c22860729c4541428af37ec5c3823a1a",
            "6e824fe387ce4d8488959cd93632cfe6",
            "6093948d2ad14c5a8ee575a291af15c5"
          ]
        },
        "id": "Khs3DL5jS6s-",
        "outputId": "64115623-4ff4-4764-fb82-e91846c01207"
      },
      "source": [
        "model = pyclass.setup(data = df_train,      \n",
        "                      target = 'target',     \n",
        "                      train_size = 0.99,\n",
        "                      remove_outliers=True,\n",
        "                      outliers_threshold=0.05,\n",
        "                      remove_multicollinearity=True,\n",
        "                      multicollinearity_threshold=0.9, \n",
        "                      categorical_features = ['cnae_secao', \n",
        "                                              'ind01','ind04','ind17','ind18', 'ind21','ind22', 'ind28', \n",
        "                                              'ind31', 'ind32', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38','ind39',\n",
        "                                              'ind42', 'ind43'],\n",
        "                      fix_imbalance = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>8835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>False: 0, True: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(11033, 53)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(10375, 78)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(111, 78)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>1c3e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Description              Value\n",
              "0                               session_id               8835\n",
              "1                                   Target             target\n",
              "2                              Target Type             Binary\n",
              "3                            Label Encoded  False: 0, True: 1\n",
              "4                            Original Data        (11033, 53)\n",
              "5                           Missing Values               True\n",
              "6                         Numeric Features                 34\n",
              "7                     Categorical Features                 18\n",
              "8                         Ordinal Features              False\n",
              "9                High Cardinality Features              False\n",
              "10                 High Cardinality Method               None\n",
              "11                   Transformed Train Set        (10375, 78)\n",
              "12                    Transformed Test Set          (111, 78)\n",
              "13                      Shuffle Train-Test               True\n",
              "14                     Stratify Train-Test              False\n",
              "15                          Fold Generator    StratifiedKFold\n",
              "16                             Fold Number                 10\n",
              "17                                CPU Jobs                 -1\n",
              "18                                 Use GPU              False\n",
              "19                          Log Experiment              False\n",
              "20                         Experiment Name   clf-default-name\n",
              "21                                     USI               1c3e\n",
              "22                         Imputation Type             simple\n",
              "23          Iterative Imputation Iteration               None\n",
              "24                         Numeric Imputer               mean\n",
              "25      Iterative Imputation Numeric Model               None\n",
              "26                     Categorical Imputer           constant\n",
              "27  Iterative Imputation Categorical Model               None\n",
              "28           Unknown Categoricals Handling     least_frequent\n",
              "29                               Normalize              False\n",
              "30                        Normalize Method               None\n",
              "31                          Transformation              False\n",
              "32                   Transformation Method               None\n",
              "33                                     PCA              False\n",
              "34                              PCA Method               None\n",
              "35                          PCA Components               None\n",
              "36                     Ignore Low Variance              False\n",
              "37                     Combine Rare Levels              False\n",
              "38                    Rare Level Threshold               None\n",
              "39                         Numeric Binning              False\n",
              "40                         Remove Outliers               True\n",
              "41                      Outliers Threshold               0.05\n",
              "42                Remove Multicollinearity               True\n",
              "43             Multicollinearity Threshold                0.9\n",
              "44                              Clustering              False\n",
              "45                    Clustering Iteration               None\n",
              "46                     Polynomial Features              False\n",
              "47                       Polynomial Degree               None\n",
              "48                    Trignometry Features              False\n",
              "49                    Polynomial Threshold               None\n",
              "50                          Group Features              False\n",
              "51                       Feature Selection              False\n",
              "52            Features Selection Threshold               None\n",
              "53                     Feature Interaction              False\n",
              "54                           Feature Ratio              False\n",
              "55                   Interaction Threshold               None\n",
              "56                           Fix Imbalance               True\n",
              "57                    Fix Imbalance Method              SMOTE"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "f063cd207c264378afdaf29f0e9d1476",
            "10427716ad9b4806a71095361fc3a6cf",
            "9eb0636962274335985e4c0f01fc0b5d"
          ]
        },
        "id": "occvZWxxTMEg",
        "outputId": "7a534e9c-6e5b-4dee-d576-a0ddd0a2774b"
      },
      "source": [
        "_# Treinar modelos\n",
        "\n",
        "best = pyclass.compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Classifier</td>\n",
              "      <td>0.7506</td>\n",
              "      <td>0.7347</td>\n",
              "      <td>0.3684</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.4025</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.2486</td>\n",
              "      <td>25.982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.7433</td>\n",
              "      <td>0.7083</td>\n",
              "      <td>0.3118</td>\n",
              "      <td>0.4175</td>\n",
              "      <td>0.3567</td>\n",
              "      <td>0.2007</td>\n",
              "      <td>0.2041</td>\n",
              "      <td>3.033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.7423</td>\n",
              "      <td>0.7223</td>\n",
              "      <td>0.3785</td>\n",
              "      <td>0.4277</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.2379</td>\n",
              "      <td>0.2388</td>\n",
              "      <td>3.473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.7418</td>\n",
              "      <td>0.7181</td>\n",
              "      <td>0.3759</td>\n",
              "      <td>0.4259</td>\n",
              "      <td>0.3990</td>\n",
              "      <td>0.2355</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>6.346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.7395</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.3861</td>\n",
              "      <td>0.4224</td>\n",
              "      <td>0.4031</td>\n",
              "      <td>0.2370</td>\n",
              "      <td>0.2376</td>\n",
              "      <td>1.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.7153</td>\n",
              "      <td>0.7235</td>\n",
              "      <td>0.4958</td>\n",
              "      <td>0.4007</td>\n",
              "      <td>0.4429</td>\n",
              "      <td>0.2547</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>6.599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.6958</td>\n",
              "      <td>0.7132</td>\n",
              "      <td>0.5245</td>\n",
              "      <td>0.3799</td>\n",
              "      <td>0.4405</td>\n",
              "      <td>0.2389</td>\n",
              "      <td>0.2449</td>\n",
              "      <td>1.966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.6677</td>\n",
              "      <td>0.5867</td>\n",
              "      <td>0.4376</td>\n",
              "      <td>0.3291</td>\n",
              "      <td>0.3754</td>\n",
              "      <td>0.1553</td>\n",
              "      <td>0.1583</td>\n",
              "      <td>0.934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.6420</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6359</td>\n",
              "      <td>0.3522</td>\n",
              "      <td>0.4389</td>\n",
              "      <td>0.2137</td>\n",
              "      <td>0.2442</td>\n",
              "      <td>0.881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.6361</td>\n",
              "      <td>0.7183</td>\n",
              "      <td>0.6979</td>\n",
              "      <td>0.3511</td>\n",
              "      <td>0.4671</td>\n",
              "      <td>0.2343</td>\n",
              "      <td>0.2663</td>\n",
              "      <td>0.837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.6309</td>\n",
              "      <td>0.7114</td>\n",
              "      <td>0.6954</td>\n",
              "      <td>0.3466</td>\n",
              "      <td>0.4625</td>\n",
              "      <td>0.2268</td>\n",
              "      <td>0.2589</td>\n",
              "      <td>1.681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.6300</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7042</td>\n",
              "      <td>0.3472</td>\n",
              "      <td>0.4651</td>\n",
              "      <td>0.2293</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.6019</td>\n",
              "      <td>0.6290</td>\n",
              "      <td>0.5759</td>\n",
              "      <td>0.3044</td>\n",
              "      <td>0.3982</td>\n",
              "      <td>0.1414</td>\n",
              "      <td>0.1574</td>\n",
              "      <td>3.843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.4302</td>\n",
              "      <td>0.6434</td>\n",
              "      <td>0.8236</td>\n",
              "      <td>0.2630</td>\n",
              "      <td>0.3981</td>\n",
              "      <td>0.0794</td>\n",
              "      <td>0.1280</td>\n",
              "      <td>0.624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.2288</td>\n",
              "      <td>0.5001</td>\n",
              "      <td>0.9996</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.3719</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>0.702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "catboost              CatBoost Classifier    0.7506  0.7347  0.3684  0.4443   \n",
              "et                 Extra Trees Classifier    0.7433  0.7083  0.3118  0.4175   \n",
              "rf               Random Forest Classifier    0.7423  0.7223  0.3785  0.4277   \n",
              "xgboost         Extreme Gradient Boosting    0.7418  0.7181  0.3759  0.4259   \n",
              "lightgbm  Light Gradient Boosting Machine    0.7395  0.7246  0.3861  0.4224   \n",
              "gbc          Gradient Boosting Classifier    0.7153  0.7235  0.4958  0.4007   \n",
              "ada                  Ada Boost Classifier    0.6958  0.7132  0.5245  0.3799   \n",
              "dt               Decision Tree Classifier    0.6677  0.5867  0.4376  0.3291   \n",
              "svm                   SVM - Linear Kernel    0.6420  0.0000  0.6359  0.3522   \n",
              "lda          Linear Discriminant Analysis    0.6361  0.7183  0.6979  0.3511   \n",
              "lr                    Logistic Regression    0.6309  0.7114  0.6954  0.3466   \n",
              "ridge                    Ridge Classifier    0.6300  0.0000  0.7042  0.3472   \n",
              "knn                K Neighbors Classifier    0.6019  0.6290  0.5759  0.3044   \n",
              "nb                            Naive Bayes    0.4302  0.6434  0.8236  0.2630   \n",
              "qda       Quadratic Discriminant Analysis    0.2288  0.5001  0.9996  0.2285   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "catboost  0.4025  0.2467  0.2486    25.982  \n",
              "et        0.3567  0.2007  0.2041     3.033  \n",
              "rf        0.4012  0.2379  0.2388     3.473  \n",
              "xgboost   0.3990  0.2355  0.2364     6.346  \n",
              "lightgbm  0.4031  0.2370  0.2376     1.274  \n",
              "gbc       0.4429  0.2547  0.2575     6.599  \n",
              "ada       0.4405  0.2389  0.2449     1.966  \n",
              "dt        0.3754  0.1553  0.1583     0.934  \n",
              "svm       0.4389  0.2137  0.2442     0.881  \n",
              "lda       0.4671  0.2343  0.2663     0.837  \n",
              "lr        0.4625  0.2268  0.2589     1.681  \n",
              "ridge     0.4651  0.2293  0.2629     0.624  \n",
              "knn       0.3982  0.1414  0.1574     3.843  \n",
              "nb        0.3981  0.0794  0.1280     0.624  \n",
              "qda       0.3719  0.0001  0.0021     0.702  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "60562d130e344b4e996c4a3cc6aea22a",
            "7b3a6bd5c33b4c648c083a8b9cb8100b",
            "4ee86fc6bfb14a1792146ea56920447a"
          ]
        },
        "id": "wzCG8d-in2ny",
        "outputId": "fdd53d82-d12a-47f9-8a4a-805d193db798"
      },
      "source": [
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/regression/#create-model\n",
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/classification/#create-model\n",
        "modelo = pyclass.create_model('catboost')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7312</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.3629</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>0.3814</td>\n",
              "      <td>0.2103</td>\n",
              "      <td>0.2107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7428</td>\n",
              "      <td>0.7341</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.4202</td>\n",
              "      <td>0.3718</td>\n",
              "      <td>0.2127</td>\n",
              "      <td>0.2150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7514</td>\n",
              "      <td>0.7469</td>\n",
              "      <td>0.3840</td>\n",
              "      <td>0.4483</td>\n",
              "      <td>0.4136</td>\n",
              "      <td>0.2571</td>\n",
              "      <td>0.2584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7486</td>\n",
              "      <td>0.7329</td>\n",
              "      <td>0.3376</td>\n",
              "      <td>0.4348</td>\n",
              "      <td>0.3800</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.2283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7592</td>\n",
              "      <td>0.7283</td>\n",
              "      <td>0.4093</td>\n",
              "      <td>0.4686</td>\n",
              "      <td>0.4369</td>\n",
              "      <td>0.2846</td>\n",
              "      <td>0.2857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7608</td>\n",
              "      <td>0.7463</td>\n",
              "      <td>0.4219</td>\n",
              "      <td>0.4739</td>\n",
              "      <td>0.4464</td>\n",
              "      <td>0.2946</td>\n",
              "      <td>0.2954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7589</td>\n",
              "      <td>0.7405</td>\n",
              "      <td>0.3840</td>\n",
              "      <td>0.4667</td>\n",
              "      <td>0.4213</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.2729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7560</td>\n",
              "      <td>0.7462</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>0.4588</td>\n",
              "      <td>0.4130</td>\n",
              "      <td>0.2609</td>\n",
              "      <td>0.2630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7454</td>\n",
              "      <td>0.7158</td>\n",
              "      <td>0.3418</td>\n",
              "      <td>0.4286</td>\n",
              "      <td>0.3803</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>0.2249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7512</td>\n",
              "      <td>0.7312</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.4413</td>\n",
              "      <td>0.3798</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7506</td>\n",
              "      <td>0.7347</td>\n",
              "      <td>0.3684</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.4025</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.2486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>0.0257</td>\n",
              "      <td>0.0291</td>\n",
              "      <td>0.0288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7312  0.7246  0.3629  0.4019  0.3814  0.2103  0.2107\n",
              "1       0.7428  0.7341  0.3333  0.4202  0.3718  0.2127  0.2150\n",
              "2       0.7514  0.7469  0.3840  0.4483  0.4136  0.2571  0.2584\n",
              "3       0.7486  0.7329  0.3376  0.4348  0.3800  0.2255  0.2283\n",
              "4       0.7592  0.7283  0.4093  0.4686  0.4369  0.2846  0.2857\n",
              "5       0.7608  0.7463  0.4219  0.4739  0.4464  0.2946  0.2954\n",
              "6       0.7589  0.7405  0.3840  0.4667  0.4213  0.2709  0.2729\n",
              "7       0.7560  0.7462  0.3755  0.4588  0.4130  0.2609  0.2630\n",
              "8       0.7454  0.7158  0.3418  0.4286  0.3803  0.2226  0.2249\n",
              "9       0.7512  0.7312  0.3333  0.4413  0.3798  0.2280  0.2315\n",
              "Mean    0.7506  0.7347  0.3684  0.4443  0.4025  0.2467  0.2486\n",
              "SD      0.0086  0.0098  0.0304  0.0222  0.0257  0.0291  0.0288"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "3vrIvLxRokBF",
        "outputId": "0cc96766-8de6-41be-a43d-d201565deccc"
      },
      "source": [
        "# Verificar importÃ¢ncia das variÃ¡veis\n",
        "\n",
        "pyclass.plot_model(modelo, 'feature')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns0RTh9JnXXp"
      },
      "source": [
        "holdout = pyclass.predict_model(modelo, data = df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQJrjf7zT6YN",
        "outputId": "6ffe4584-4da3-4c38-9f51-3ac7afd4a386"
      },
      "source": [
        "holdout['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    766\n",
              "True     234\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1lVo4rCKVc0",
        "outputId": "98fc8b8a-ba88-4ec8-cc94-47ea384e9975"
      },
      "source": [
        "pycaret_cat3 = pd.DataFrame(zip(holdout.index, holdout['Label'], holdout['Score']), columns=['id','Label','Score_ex_tree'])\n",
        "pycaret_cat3['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    766\n",
              "True     234\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "eXifNlrhThqM",
        "outputId": "16c35e95-7bef-46c1-d30e-6e7d439bc17e"
      },
      "source": [
        "pycaret_ex_tree.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score_ex_tree</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>False</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>False</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>False</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>False</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>True</td>\n",
              "      <td>0.51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  Label  Score_ex_tree\n",
              "0  3411  False           0.73\n",
              "1  2177  False           0.69\n",
              "2  8400  False           0.87\n",
              "3   464  False           0.62\n",
              "4  6672   True           0.51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeiYmG0JTNjN"
      },
      "source": [
        "pycaret_cat3.to_csv('pycaret_cat3.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dY0kbA8Tp2D"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(holdout.index, holdout['Label']), columns=['id','target'])\n",
        "df_submit.to_csv('PyLadies.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHhDjV0cILKv"
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OT4CmbQUrH8"
      },
      "source": [
        "url_modelo_e_target = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/modelo_e_target%20(1).csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TLIh_VsU3Pt"
      },
      "source": [
        "modelo_e_target = pd.read_csv(url_modelo_e_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "10zIuwKTVNiS",
        "outputId": "05a8fd6a-1f0b-4c90-8522-cfff32051de2"
      },
      "source": [
        "modelo_e_target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nome_modelo</th>\n",
              "      <th>target_0</th>\n",
              "      <th>target_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb70</td>\n",
              "      <td>830</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cb70_tuned</td>\n",
              "      <td>820</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cb90</td>\n",
              "      <td>821</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cb90_tuned</td>\n",
              "      <td>811</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cb90_ensemble_boosting</td>\n",
              "      <td>839</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cat</td>\n",
              "      <td>771</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cat1</td>\n",
              "      <td>773</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>et2</td>\n",
              "      <td>785</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cat2</td>\n",
              "      <td>776</td>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>cat3</td>\n",
              "      <td>766</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              nome_modelo  target_0  target_1\n",
              "0                    cb70       830       170\n",
              "1              cb70_tuned       820       180\n",
              "2                    cb90       821       179\n",
              "3              cb90_tuned       811       189\n",
              "4  cb90_ensemble_boosting       839       161\n",
              "5                     cat       771       229\n",
              "6                    cat1       773       227\n",
              "7                     et2       785       215\n",
              "8                    cat2       776       224\n",
              "9                    cat3       766       234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmbqFwnoWkmQ"
      },
      "source": [
        "modelo_e_target.loc[[9][0]]= ['cat3',766,234]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LliEiDNU189"
      },
      "source": [
        "modelo_e_target.to_csv('modelo_e_target.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVYFg_ZkU0m-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-7gQgxOXUMk"
      },
      "source": [
        "### TUNED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "704290000a4e40788bd9e0cc0373f217",
            "83fe8d1efce3423ab379c058ccb0cdb7",
            "eeaee4beeaaf454c833b431890a8d1e4"
          ]
        },
        "id": "BT3QPZVeIa6-",
        "outputId": "09da2ee3-8200-45dc-883a-02ee88e9c9d4"
      },
      "source": [
        "tuned = pyclass.tune_model(cat, n_iter = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7334</td>\n",
              "      <td>0.3916</td>\n",
              "      <td>0.4545</td>\n",
              "      <td>0.4207</td>\n",
              "      <td>0.2674</td>\n",
              "      <td>0.2685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7316</td>\n",
              "      <td>0.7109</td>\n",
              "      <td>0.3054</td>\n",
              "      <td>0.3864</td>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.1755</td>\n",
              "      <td>0.1774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7193</td>\n",
              "      <td>0.6748</td>\n",
              "      <td>0.2994</td>\n",
              "      <td>0.3597</td>\n",
              "      <td>0.3268</td>\n",
              "      <td>0.1514</td>\n",
              "      <td>0.1524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7371</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>0.3054</td>\n",
              "      <td>0.3984</td>\n",
              "      <td>0.3458</td>\n",
              "      <td>0.1848</td>\n",
              "      <td>0.1874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7439</td>\n",
              "      <td>0.7161</td>\n",
              "      <td>0.3533</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.3856</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.2271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7861</td>\n",
              "      <td>0.7519</td>\n",
              "      <td>0.3653</td>\n",
              "      <td>0.5446</td>\n",
              "      <td>0.4373</td>\n",
              "      <td>0.3115</td>\n",
              "      <td>0.3210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7517</td>\n",
              "      <td>0.7219</td>\n",
              "      <td>0.3434</td>\n",
              "      <td>0.4385</td>\n",
              "      <td>0.3851</td>\n",
              "      <td>0.2325</td>\n",
              "      <td>0.2352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7381</td>\n",
              "      <td>0.7288</td>\n",
              "      <td>0.3554</td>\n",
              "      <td>0.4097</td>\n",
              "      <td>0.3806</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.2165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7503</td>\n",
              "      <td>0.7239</td>\n",
              "      <td>0.4217</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4334</td>\n",
              "      <td>0.2735</td>\n",
              "      <td>0.2737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7326</td>\n",
              "      <td>0.7069</td>\n",
              "      <td>0.3976</td>\n",
              "      <td>0.4074</td>\n",
              "      <td>0.4024</td>\n",
              "      <td>0.2302</td>\n",
              "      <td>0.2303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7447</td>\n",
              "      <td>0.7185</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>0.4270</td>\n",
              "      <td>0.3859</td>\n",
              "      <td>0.2268</td>\n",
              "      <td>0.2289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0173</td>\n",
              "      <td>0.0190</td>\n",
              "      <td>0.0398</td>\n",
              "      <td>0.0477</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.0461</td>\n",
              "      <td>0.0474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7561  0.7334  0.3916  0.4545  0.4207  0.2674  0.2685\n",
              "1       0.7316  0.7109  0.3054  0.3864  0.3411  0.1755  0.1774\n",
              "2       0.7193  0.6748  0.2994  0.3597  0.3268  0.1514  0.1524\n",
              "3       0.7371  0.7163  0.3054  0.3984  0.3458  0.1848  0.1874\n",
              "4       0.7439  0.7161  0.3533  0.4245  0.3856  0.2255  0.2271\n",
              "5       0.7861  0.7519  0.3653  0.5446  0.4373  0.3115  0.3210\n",
              "6       0.7517  0.7219  0.3434  0.4385  0.3851  0.2325  0.2352\n",
              "7       0.7381  0.7288  0.3554  0.4097  0.3806  0.2156  0.2165\n",
              "8       0.7503  0.7239  0.4217  0.4459  0.4334  0.2735  0.2737\n",
              "9       0.7326  0.7069  0.3976  0.4074  0.4024  0.2302  0.2303\n",
              "Mean    0.7447  0.7185  0.3538  0.4270  0.3859  0.2268  0.2289\n",
              "SD      0.0173  0.0190  0.0398  0.0477  0.0368  0.0461  0.0474"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "hza1TggsKkRB",
        "outputId": "d0f4266b-02c4-442c-bfc0-aa89aac60f5b"
      },
      "source": [
        "# Verificar importÃ¢ncia das variÃ¡veis\n",
        "pyclass.plot_model(tuned, 'feature')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4b56893be394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Verificar importÃ¢ncia das variÃ¡veis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pyclass' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Nm4pjwKL0B"
      },
      "source": [
        "tuned_holdout = pyclass.predict_model(tuned, data = df_test)\n",
        "tuned_holdout['Label'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQMbKRLjN4wM"
      },
      "source": [
        "#df_pycaret['lda_setup_tuned_AUC'] = holdout['Label']\n",
        "#df_pycaret.to_csv('df_pycaret_Label_modelos.csv', index=False, sep=',')\n",
        "pycaret_cb90_tuned = pd.DataFrame(zip(tuned_holdout.index, tuned_holdout['Label'], tuned_holdout['Score']), columns=['id','Label','Score'])\n",
        "pycaret_cb90_tuned['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyS9YbXGb7VP"
      },
      "source": [
        "pycaret_cb90_tuned['Label'].value_counts()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fcziqXScPbv"
      },
      "source": [
        "pycaret_cb90.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctoC2-2OaXoG"
      },
      "source": [
        "modelos=['cb70', 'cb70_tuned', 'cb90', 'cb90_tuned', 'cb90_ensemble_boosting']\n",
        "modelos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBoQYVXyavBD"
      },
      "source": [
        "target_0 = [pycaret_cb['Label'].value_counts()[0], pycaret_cb_tuned['Label'].value_counts()[0], pycaret_cb90['cb90'].value_counts()[0], pycaret_cb90_tuned['Label'].value_counts()[0],pycaret_cb90_ensemble_boosting['Label'].value_counts()[0]]\n",
        "type(target_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAZPJ6flcpoD"
      },
      "source": [
        "target_1 = [pycaret_cb['Label'].value_counts()[1], pycaret_cb_tuned['Label'].value_counts()[1], pycaret_cb90['cb90'].value_counts()[1], pycaret_cb90_tuned['Label'].value_counts()[1],pycaret_cb90_ensemble_boosting['Label'].value_counts()[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbulp98sc9jz"
      },
      "source": [
        "modelo_e_target = pd.DataFrame(zip(modelos, target_0,target_1),columns=['nome_modelo','target_0','target_1'])\n",
        "modelo_e_target.to_csv('modelo_e_target.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xwUyGkQfrA9"
      },
      "source": [
        "modelo_e_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQwbdM_iL7b-"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(tuned_holdout.index, tuned_holdout['Label']), columns=['id','target'])\n",
        "df_submit.to_csv('PyLadies1.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh22ZcfDHBTH"
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrFn0j2jHBKs"
      },
      "source": [
        "df_pycaret['catboost_setup_tuned_F1'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UXpoFdtP9kv"
      },
      "source": [
        "pycaret_cb_tuned.to_csv('pycaret_cb_tuned.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR0PHYn1XDsQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INOSNxqBIYe8"
      },
      "source": [
        "### ENSEMBLE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8gX5K0mI0Vh"
      },
      "source": [
        "# cb90 => 'boosting'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "caXHz7EJXD1w",
        "outputId": "40b1bc61-189f-4543-dee8-df056a292383"
      },
      "source": [
        "boosting = pyclass.ensemble_model(modelo, method= 'Boosting')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7825</td>\n",
              "      <td>0.7459</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.5398</td>\n",
              "      <td>0.3609</td>\n",
              "      <td>0.2468</td>\n",
              "      <td>0.2681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7704</td>\n",
              "      <td>0.7281</td>\n",
              "      <td>0.2533</td>\n",
              "      <td>0.4872</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.2110</td>\n",
              "      <td>0.2275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7664</td>\n",
              "      <td>0.7468</td>\n",
              "      <td>0.2933</td>\n",
              "      <td>0.4748</td>\n",
              "      <td>0.3626</td>\n",
              "      <td>0.2293</td>\n",
              "      <td>0.2392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7573</td>\n",
              "      <td>0.7299</td>\n",
              "      <td>0.2178</td>\n",
              "      <td>0.4298</td>\n",
              "      <td>0.2891</td>\n",
              "      <td>0.1613</td>\n",
              "      <td>0.1748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>0.2622</td>\n",
              "      <td>0.4470</td>\n",
              "      <td>0.3305</td>\n",
              "      <td>0.1958</td>\n",
              "      <td>0.2061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7523</td>\n",
              "      <td>0.7198</td>\n",
              "      <td>0.2578</td>\n",
              "      <td>0.4234</td>\n",
              "      <td>0.3204</td>\n",
              "      <td>0.1798</td>\n",
              "      <td>0.1880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7293</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.4435</td>\n",
              "      <td>0.3152</td>\n",
              "      <td>0.1838</td>\n",
              "      <td>0.1958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7383</td>\n",
              "      <td>0.2124</td>\n",
              "      <td>0.4404</td>\n",
              "      <td>0.2866</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.1782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7654</td>\n",
              "      <td>0.7325</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.3399</td>\n",
              "      <td>0.2107</td>\n",
              "      <td>0.2236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7782</td>\n",
              "      <td>0.7495</td>\n",
              "      <td>0.2622</td>\n",
              "      <td>0.5221</td>\n",
              "      <td>0.3491</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7650</td>\n",
              "      <td>0.7354</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>0.4680</td>\n",
              "      <td>0.3288</td>\n",
              "      <td>0.2014</td>\n",
              "      <td>0.2154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0091</td>\n",
              "      <td>0.0091</td>\n",
              "      <td>0.0229</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0252</td>\n",
              "      <td>0.0282</td>\n",
              "      <td>0.0304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7825  0.7459  0.2711  0.5398  0.3609  0.2468  0.2681\n",
              "1       0.7704  0.7281  0.2533  0.4872  0.3333  0.2110  0.2275\n",
              "2       0.7664  0.7468  0.2933  0.4748  0.3626  0.2293  0.2392\n",
              "3       0.7573  0.7299  0.2178  0.4298  0.2891  0.1613  0.1748\n",
              "4       0.7593  0.7339  0.2622  0.4470  0.3305  0.1958  0.2061\n",
              "5       0.7523  0.7198  0.2578  0.4234  0.3204  0.1798  0.1880\n",
              "6       0.7593  0.7293  0.2444  0.4435  0.3152  0.1838  0.1958\n",
              "7       0.7593  0.7383  0.2124  0.4404  0.2866  0.1625  0.1782\n",
              "8       0.7654  0.7325  0.2655  0.4724  0.3399  0.2107  0.2236\n",
              "9       0.7782  0.7495  0.2622  0.5221  0.3491  0.2328  0.2528\n",
              "Mean    0.7650  0.7354  0.2540  0.4680  0.3288  0.2014  0.2154\n",
              "SD      0.0091  0.0091  0.0229  0.0371  0.0252  0.0282  0.0304"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiqwtRifJQ20",
        "outputId": "696391e1-d91f-4949-9e91-9d5e7f26946f"
      },
      "source": [
        "holdout = pyclass.predict_model(boosting, data = df_test)\n",
        "holdout['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    839\n",
              "1    161\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "p9wCjH5DKPod",
        "outputId": "b916a5b5-d3e2-4da7-939e-9e56efa7e71f"
      },
      "source": [
        "holdout.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>...</th>\n",
              "      <th>md5_o</th>\n",
              "      <th>md7_o</th>\n",
              "      <th>md8_o</th>\n",
              "      <th>md9_o</th>\n",
              "      <th>md10_o</th>\n",
              "      <th>md12_o</th>\n",
              "      <th>mc1_o</th>\n",
              "      <th>mc3_o</th>\n",
              "      <th>mc4_o</th>\n",
              "      <th>rf2_d</th>\n",
              "      <th>rf2_i</th>\n",
              "      <th>rf2_k</th>\n",
              "      <th>rf2_p</th>\n",
              "      <th>rf2_q</th>\n",
              "      <th>rf2_r</th>\n",
              "      <th>rf2_s</th>\n",
              "      <th>rf2_v</th>\n",
              "      <th>rf2_y</th>\n",
              "      <th>rf2_z</th>\n",
              "      <th>cnae_secao_0</th>\n",
              "      <th>cnae_secao_A</th>\n",
              "      <th>cnae_secao_B</th>\n",
              "      <th>cnae_secao_C</th>\n",
              "      <th>cnae_secao_D</th>\n",
              "      <th>cnae_secao_E</th>\n",
              "      <th>cnae_secao_F</th>\n",
              "      <th>cnae_secao_G</th>\n",
              "      <th>cnae_secao_H</th>\n",
              "      <th>cnae_secao_I</th>\n",
              "      <th>cnae_secao_J</th>\n",
              "      <th>cnae_secao_K</th>\n",
              "      <th>cnae_secao_L</th>\n",
              "      <th>cnae_secao_M</th>\n",
              "      <th>cnae_secao_N</th>\n",
              "      <th>cnae_secao_P</th>\n",
              "      <th>cnae_secao_Q</th>\n",
              "      <th>cnae_secao_R</th>\n",
              "      <th>cnae_secao_S</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3411</th>\n",
              "      <td>71</td>\n",
              "      <td>0.017485</td>\n",
              "      <td>0.004743</td>\n",
              "      <td>0.111771</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005432</td>\n",
              "      <td>0.023085</td>\n",
              "      <td>0.00989</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.13132</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.442161e-09</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297611</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.425478</td>\n",
              "      <td>0.243343</td>\n",
              "      <td>0.623462</td>\n",
              "      <td>0.424363</td>\n",
              "      <td>0.04456</td>\n",
              "      <td>4.620425e-07</td>\n",
              "      <td>0.273459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 107 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cnae2       md1       md2  ...  cnae_secao_S  Label   Score\n",
              "id                               ...                             \n",
              "3411     71  0.017485  0.004743  ...             0      0  0.6018\n",
              "\n",
              "[1 rows x 107 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOwi-zh1JZFw",
        "outputId": "4fb2a1f6-2e06-4bac-97e8-07f48ea3147c"
      },
      "source": [
        "pycaret_cb90_ensemble_boosting = pd.DataFrame(zip(holdout.index, holdout['Label'], holdout['Score']), columns=['id','Label','Score'])\n",
        "pycaret_cb90_ensemble_boosting['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    839\n",
              "1    161\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXD8q3bgJTCw"
      },
      "source": [
        "#f'\"0 = \" : {pycaret_cb90_ensemble_boosting['Label'].value_counts()[0]}, \"1 = \" : {pycaret_cb90_ensemble_boosting['Label'].value_counts()[1]}'\n",
        "pycaret_cb90_ensemble_boosting.to_csv('pycaret_cb90_ensemble_boosting.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQYErGjQUcG",
        "outputId": "facf1626-c790-4323-e536-bdf2129ce0a4"
      },
      "source": [
        "pycaret_cb90_ensemble_boosting['Label'].value_counts()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ckXKKMuK47_"
      },
      "source": [
        "classification.interpret_model(boosting)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK3T5r8xK51O"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKIdA04hTFp4"
      },
      "source": [
        "# tentando rodar: ensemble model com modelo 'tuned' (cb90_tuned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "1Jw7nmoJTGEQ",
        "outputId": "86a3a650-957a-4050-a469-6fb2866287c2"
      },
      "source": [
        "boosting_tuned = pyclass.ensemble_model(tuned, method= 'Boosting')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7784</td>\n",
              "      <td>0.7345</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.5214</td>\n",
              "      <td>0.3567</td>\n",
              "      <td>0.2387</td>\n",
              "      <td>0.2573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7613</td>\n",
              "      <td>0.7422</td>\n",
              "      <td>0.2400</td>\n",
              "      <td>0.4500</td>\n",
              "      <td>0.3130</td>\n",
              "      <td>0.1845</td>\n",
              "      <td>0.1979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7744</td>\n",
              "      <td>0.7468</td>\n",
              "      <td>0.3067</td>\n",
              "      <td>0.5036</td>\n",
              "      <td>0.3812</td>\n",
              "      <td>0.2531</td>\n",
              "      <td>0.2648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7523</td>\n",
              "      <td>0.7289</td>\n",
              "      <td>0.2044</td>\n",
              "      <td>0.4071</td>\n",
              "      <td>0.2722</td>\n",
              "      <td>0.1422</td>\n",
              "      <td>0.1545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7373</td>\n",
              "      <td>0.2800</td>\n",
              "      <td>0.4500</td>\n",
              "      <td>0.3452</td>\n",
              "      <td>0.2074</td>\n",
              "      <td>0.2162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7523</td>\n",
              "      <td>0.7191</td>\n",
              "      <td>0.2622</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.3242</td>\n",
              "      <td>0.1827</td>\n",
              "      <td>0.1907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7805</td>\n",
              "      <td>0.7274</td>\n",
              "      <td>0.2889</td>\n",
              "      <td>0.5285</td>\n",
              "      <td>0.3736</td>\n",
              "      <td>0.2541</td>\n",
              "      <td>0.2711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7613</td>\n",
              "      <td>0.7415</td>\n",
              "      <td>0.2168</td>\n",
              "      <td>0.4495</td>\n",
              "      <td>0.2925</td>\n",
              "      <td>0.1695</td>\n",
              "      <td>0.1859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7704</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.3053</td>\n",
              "      <td>0.4929</td>\n",
              "      <td>0.3770</td>\n",
              "      <td>0.2457</td>\n",
              "      <td>0.2563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7792</td>\n",
              "      <td>0.7505</td>\n",
              "      <td>0.2533</td>\n",
              "      <td>0.5278</td>\n",
              "      <td>0.3423</td>\n",
              "      <td>0.2289</td>\n",
              "      <td>0.2512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.7353</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.4755</td>\n",
              "      <td>0.3378</td>\n",
              "      <td>0.2107</td>\n",
              "      <td>0.2246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0330</td>\n",
              "      <td>0.0424</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.0373</td>\n",
              "      <td>0.0386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7784  0.7345  0.2711  0.5214  0.3567  0.2387  0.2573\n",
              "1       0.7613  0.7422  0.2400  0.4500  0.3130  0.1845  0.1979\n",
              "2       0.7744  0.7468  0.3067  0.5036  0.3812  0.2531  0.2648\n",
              "3       0.7523  0.7289  0.2044  0.4071  0.2722  0.1422  0.1545\n",
              "4       0.7593  0.7373  0.2800  0.4500  0.3452  0.2074  0.2162\n",
              "5       0.7523  0.7191  0.2622  0.4245  0.3242  0.1827  0.1907\n",
              "6       0.7805  0.7274  0.2889  0.5285  0.3736  0.2541  0.2711\n",
              "7       0.7613  0.7415  0.2168  0.4495  0.2925  0.1695  0.1859\n",
              "8       0.7704  0.7246  0.3053  0.4929  0.3770  0.2457  0.2563\n",
              "9       0.7792  0.7505  0.2533  0.5278  0.3423  0.2289  0.2512\n",
              "Mean    0.7669  0.7353  0.2629  0.4755  0.3378  0.2107  0.2246\n",
              "SD      0.0104  0.0097  0.0330  0.0424  0.0351  0.0373  0.0386"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "w4fYeP-Ago8U",
        "outputId": "eace10f1-373d-4af4-f44e-7a76207f174b"
      },
      "source": [
        "holdout = pyclass.predict_model(boosting_tuned, data = df_test)\n",
        "\n",
        "pycaret_cb90_tuned_ensemble_boosting = pd.DataFrame(zip(holdout.index, holdout['Label'], holdout['Score']), columns=['id','Label','Score'])\n",
        "pycaret_cb90_tuned_ensemble_boosting.to_csv('pycaret_cb90_tuned_ensemble_boosting.csv', index=False, sep=',')\n",
        "\n",
        "modelos[6] = ['pycaret_cb90_tuned_ensemble_boosting']\n",
        "target_0[6] = [pycaret_cb90_tuned_ensemble_boosting['Label'].value_counts()[0]]\n",
        "target_1[6] = [pycaret_cb90_tuned_ensemble_boosting['Label'].value_counts()[1]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f579f3da3c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mholdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboosting_tuned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpycaret_cb90_tuned_ensemble_boosting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpycaret_cb90_tuned_ensemble_boosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pycaret_cb90_tuned_ensemble_boosting.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pyclass' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXjbsi1oXno1"
      },
      "source": [
        "### SIMULAR REGRESSÃƒO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "tmJA8ZH7P-Lc",
        "outputId": "e03c28cb-90a3-489d-cf75-ce0064dd7ee1"
      },
      "source": [
        "_# Treinar modelos\n",
        "from pycaret import regression as pyreg\n",
        "best_reg = pyreg.compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-44662f4b5d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_\u001b[0m\u001b[0;31m# Treinar modelos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpyreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/regression.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, verbose)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, verbose, display)\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1951\u001b[0;31m                 \u001b[0;34mf\"Sort method not supported. See docstring for list of available parameters.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m             )\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sort method not supported. See docstring for list of available parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH09bBhcM80y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOaLYAnxFSDo"
      },
      "source": [
        "### PULAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypwM33UBpCw"
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_test.csv'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oDXHvVPustij",
        "outputId": "ec4b7355-4299-4add-87e7-6c1fa1c4a2f1"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}, \"df_total.shape:\": {df_total.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 63), \"df_test.shape:\": (1000, 62), \"df_total.shape:\": (12033, 80)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj2DFFRNt9uT",
        "outputId": "4fdc2ca6-c935-44f8-e614-a1018a61ed59"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11033 entries, 0 to 11032\n",
            "Data columns (total 63 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      11033 non-null  int64  \n",
            " 1   cnae2   11033 non-null  int64  \n",
            " 2   rf2     11033 non-null  object \n",
            " 3   md1     11033 non-null  float64\n",
            " 4   md2     11033 non-null  float64\n",
            " 5   md3     11033 non-null  float64\n",
            " 6   md4     11033 non-null  float64\n",
            " 7   md5     11033 non-null  float64\n",
            " 8   md6     11033 non-null  float64\n",
            " 9   md7     11033 non-null  float64\n",
            " 10  md8     11033 non-null  float64\n",
            " 11  md9     11033 non-null  float64\n",
            " 12  md10    11033 non-null  float64\n",
            " 13  md11    11033 non-null  float64\n",
            " 14  md12    11033 non-null  float64\n",
            " 15  mc1     10431 non-null  float64\n",
            " 16  mc2     10431 non-null  float64\n",
            " 17  mc3     10431 non-null  float64\n",
            " 18  mc4     11033 non-null  float64\n",
            " 19  ind01   10999 non-null  float64\n",
            " 20  ind02   10999 non-null  float64\n",
            " 21  ind03   10999 non-null  float64\n",
            " 22  ind04   10999 non-null  float64\n",
            " 23  ind05   10999 non-null  float64\n",
            " 24  ind06   10999 non-null  float64\n",
            " 25  ind07   10999 non-null  float64\n",
            " 26  ind08   10999 non-null  float64\n",
            " 27  ind09   10999 non-null  float64\n",
            " 28  ind10   10999 non-null  float64\n",
            " 29  ind11   10999 non-null  float64\n",
            " 30  ind12   10999 non-null  float64\n",
            " 31  ind13   10999 non-null  float64\n",
            " 32  ind14   10999 non-null  float64\n",
            " 33  ind15   10999 non-null  float64\n",
            " 34  ind16   10999 non-null  float64\n",
            " 35  ind17   10999 non-null  float64\n",
            " 36  ind18   10999 non-null  float64\n",
            " 37  ind19   10999 non-null  float64\n",
            " 38  ind20   10999 non-null  float64\n",
            " 39  ind21   10434 non-null  float64\n",
            " 40  ind22   10434 non-null  float64\n",
            " 41  ind23   10434 non-null  float64\n",
            " 42  ind24   10434 non-null  float64\n",
            " 43  ind25   10434 non-null  float64\n",
            " 44  ind26   10434 non-null  float64\n",
            " 45  ind27   10434 non-null  float64\n",
            " 46  ind28   10999 non-null  float64\n",
            " 47  ind29   10999 non-null  float64\n",
            " 48  ind30   10999 non-null  float64\n",
            " 49  ind31   10999 non-null  float64\n",
            " 50  ind32   10999 non-null  float64\n",
            " 51  ind33   10999 non-null  float64\n",
            " 52  ind34   10999 non-null  float64\n",
            " 53  ind35   10999 non-null  float64\n",
            " 54  ind36   10999 non-null  float64\n",
            " 55  ind37   10999 non-null  float64\n",
            " 56  ind38   10434 non-null  float64\n",
            " 57  ind39   10434 non-null  float64\n",
            " 58  ind40   10999 non-null  float64\n",
            " 59  ind41   10999 non-null  float64\n",
            " 60  ind42   10434 non-null  float64\n",
            " 61  ind43   10434 non-null  float64\n",
            " 62  target  11033 non-null  bool   \n",
            "dtypes: bool(1), float64(59), int64(2), object(1)\n",
            "memory usage: 5.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNVOd-U9uzXe",
        "outputId": "83a7dc81-5bef-454b-c91e-60ae74288ff5"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'cnae2', 'rf2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7',\n",
              "       'md8', 'md9', 'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4',\n",
              "       'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24',\n",
              "       'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32',\n",
              "       'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
              "       'ind41', 'ind42', 'ind43', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "mgT2KGJBt9ub",
        "outputId": "eea02333-d133-4a95-f54e-01d19e50b9e3"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6007.300462</td>\n",
              "      <td>53.105774</td>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106722</td>\n",
              "      <td>0.157427</td>\n",
              "      <td>0.346646</td>\n",
              "      <td>0.364934</td>\n",
              "      <td>0.378858</td>\n",
              "      <td>0.397906</td>\n",
              "      <td>0.305112</td>\n",
              "      <td>0.355596</td>\n",
              "      <td>0.007454</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.141280</td>\n",
              "      <td>0.170552</td>\n",
              "      <td>0.034556</td>\n",
              "      <td>0.019556</td>\n",
              "      <td>0.003789</td>\n",
              "      <td>0.014774</td>\n",
              "      <td>0.004045</td>\n",
              "      <td>0.694791</td>\n",
              "      <td>0.700189</td>\n",
              "      <td>0.544750</td>\n",
              "      <td>0.538172</td>\n",
              "      <td>0.339573</td>\n",
              "      <td>0.333567</td>\n",
              "      <td>0.099865</td>\n",
              "      <td>0.570295</td>\n",
              "      <td>0.550792</td>\n",
              "      <td>0.005119</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.331121</td>\n",
              "      <td>0.367397</td>\n",
              "      <td>0.999182</td>\n",
              "      <td>0.489044</td>\n",
              "      <td>0.910992</td>\n",
              "      <td>0.729703</td>\n",
              "      <td>0.659605</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>0.134177</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.170692</td>\n",
              "      <td>0.090905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3470.840481</td>\n",
              "      <td>19.885298</td>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305922</td>\n",
              "      <td>0.315114</td>\n",
              "      <td>0.470182</td>\n",
              "      <td>0.451587</td>\n",
              "      <td>0.449015</td>\n",
              "      <td>0.473002</td>\n",
              "      <td>0.430549</td>\n",
              "      <td>0.440732</td>\n",
              "      <td>0.069064</td>\n",
              "      <td>0.031814</td>\n",
              "      <td>0.029262</td>\n",
              "      <td>0.312289</td>\n",
              "      <td>0.322844</td>\n",
              "      <td>0.161135</td>\n",
              "      <td>0.129848</td>\n",
              "      <td>0.059799</td>\n",
              "      <td>0.118014</td>\n",
              "      <td>0.062567</td>\n",
              "      <td>0.452090</td>\n",
              "      <td>0.450725</td>\n",
              "      <td>0.455767</td>\n",
              "      <td>0.457155</td>\n",
              "      <td>0.433901</td>\n",
              "      <td>0.434164</td>\n",
              "      <td>0.221941</td>\n",
              "      <td>0.425365</td>\n",
              "      <td>0.412976</td>\n",
              "      <td>0.060052</td>\n",
              "      <td>0.013340</td>\n",
              "      <td>0.018207</td>\n",
              "      <td>0.470638</td>\n",
              "      <td>0.482118</td>\n",
              "      <td>0.028595</td>\n",
              "      <td>0.499903</td>\n",
              "      <td>0.284768</td>\n",
              "      <td>0.444134</td>\n",
              "      <td>0.473863</td>\n",
              "      <td>0.071093</td>\n",
              "      <td>0.340858</td>\n",
              "      <td>0.016514</td>\n",
              "      <td>0.009535</td>\n",
              "      <td>0.376258</td>\n",
              "      <td>0.206764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3018.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6016.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9003.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862600</td>\n",
              "      <td>0.932700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id         cnae2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  10434.000000  10434.000000\n",
              "mean    6007.300462     53.105774  ...      0.170692      0.090905\n",
              "std     3470.840481     19.885298  ...      0.376258      0.206764\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%     3018.000000     42.000000  ...      0.000000      0.000000\n",
              "50%     6016.000000     47.000000  ...      0.000000      0.000000\n",
              "75%     9003.000000     69.000000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "J7U16Y6SQ4Zs",
        "outputId": "1bfaa59c-c8b3-44d4-b470-9f221cdd5cdf"
      },
      "source": [
        "l_train_unique = []\n",
        "for i in df_train.columns:\n",
        "  l_train_unique.append(len(df_train[i].unique()))\n",
        "  #print(\"coluna:\", i, \" - len(df_train[i].unique()):\", len(df_train[i].unique()))\n",
        "\n",
        "df_train_unique = pd.DataFrame(zip(df_train.columns,l_train_unique))\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>11033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cnae2</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rf2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>md1</td>\n",
              "      <td>8829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>md2</td>\n",
              "      <td>10968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>ind40</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>ind41</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>ind42</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>ind43</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>target</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0      1\n",
              "0       id  11033\n",
              "1    cnae2     80\n",
              "2      rf2     10\n",
              "3      md1   8829\n",
              "4      md2  10968\n",
              "..     ...    ...\n",
              "58   ind40      3\n",
              "59   ind41      3\n",
              "60   ind42      3\n",
              "61   ind43      4\n",
              "62  target      2\n",
              "\n",
              "[63 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "B2JdxJRJShUQ",
        "outputId": "f24734e0-41ae-4153-c402-dbfef6a396a7"
      },
      "source": [
        "df_train_unique.rename(columns={0:'coluna',1:'qtde_unique'})\n",
        "df_train_unique = df_train_unique.set_index(0).T\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11033</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>8829</td>\n",
              "      <td>10968</td>\n",
              "      <td>10967</td>\n",
              "      <td>8168</td>\n",
              "      <td>5612</td>\n",
              "      <td>379</td>\n",
              "      <td>10970</td>\n",
              "      <td>10968</td>\n",
              "      <td>8282</td>\n",
              "      <td>5777</td>\n",
              "      <td>340</td>\n",
              "      <td>10967</td>\n",
              "      <td>9925</td>\n",
              "      <td>1484</td>\n",
              "      <td>8157</td>\n",
              "      <td>10451</td>\n",
              "      <td>14</td>\n",
              "      <td>1417</td>\n",
              "      <td>194</td>\n",
              "      <td>14</td>\n",
              "      <td>765</td>\n",
              "      <td>227</td>\n",
              "      <td>2101</td>\n",
              "      <td>2522</td>\n",
              "      <td>331</td>\n",
              "      <td>45</td>\n",
              "      <td>22</td>\n",
              "      <td>1554</td>\n",
              "      <td>2503</td>\n",
              "      <td>830</td>\n",
              "      <td>77</td>\n",
              "      <td>24</td>\n",
              "      <td>45</td>\n",
              "      <td>13</td>\n",
              "      <td>488</td>\n",
              "      <td>429</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>748</td>\n",
              "      <td>159</td>\n",
              "      <td>164</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0     id  cnae2  rf2   md1    md2  ...  ind40  ind41  ind42  ind43  target\n",
              "1  11033     80   10  8829  10968  ...      3      3      3      4       2\n",
              "\n",
              "[1 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yll7hKsUxWUK",
        "outputId": "22b004c4-e69a-4b96-b4ac-b14d83bb0602"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpnm_zhckXD9",
        "outputId": "d0293f89-1ee1-450d-cbf5-f1d686cfaf06"
      },
      "source": [
        "df_nan = df_train.isna().sum()\n",
        "df_nan[df_nan.values>0].sort_values()\n",
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy8hCEistGiR",
        "outputId": "f532aa00-480d-4eb9-e0d1-9096d0858f5b"
      },
      "source": [
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIaxV70rhhE-",
        "outputId": "f7e2eced-6a2d-4ec6-8ce2-3cbd338cfeac"
      },
      "source": [
        "df_nan[df_nan.values==34].index   \n",
        "\n",
        "# 32 colunas/variÃ¡veis que possuem 34 NaN cada\n",
        "#'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "#'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "#'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "#'ind40', 'ind41']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind28', 'ind29', 'ind30', 'ind31',\n",
              "       'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind40', 'ind41'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ERGm38u0oN",
        "outputId": "4f72eb49-82b0-4638-970d-04453d1c448d"
      },
      "source": [
        "len(df_nan[df_nan.values==34].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49eQZdrEpex6",
        "outputId": "eab85b83-a8e8-415d-e8b3-a23864d6ff33"
      },
      "source": [
        "df_nan[df_nan.values==599].index    \n",
        "\n",
        "# 11 colunas/variÃ¡veis que possuem 599 NaN cada:\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "# 'ind38', 'ind39',\n",
        "# 'ind42', 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind38',\n",
              "       'ind39', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o593PHygvLJ8",
        "outputId": "0e4aa74f-9572-4e25-9d89-5aa08cc581b1"
      },
      "source": [
        "len(df_nan[df_nan.values==599].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5mETHrgpe_I",
        "outputId": "4b37dbdb-ef2f-4d98-cfd1-534af3742742"
      },
      "source": [
        "df_nan[df_nan.values==602].index    \n",
        "\n",
        "# 3 colunas/variÃ¡veis que possuem 602 NaN cada\n",
        "# ['mc1', 'mc2', 'mc3']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHecZd8jfuGi",
        "outputId": "722fece4-a4fa-49e2-a0e8-cb209f74ac2d"
      },
      "source": [
        "linhas_602nan = df_train['mc1'][df_train['mc1'].isna()].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   26,    27,    32,    34,    47,    64,    76,    88,   100,\n",
              "              121,\n",
              "            ...\n",
              "            10848, 10891, 10911, 10921, 10935, 10941, 10979, 10986, 10991,\n",
              "            11007],\n",
              "           dtype='int64', length=602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EUky3VvxJH"
      },
      "source": [
        "linhas_599nan = df_train['ind21'][df_train['ind21'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI4pULl0wble",
        "outputId": "1fbcf7a7-e9f0-4d47-d135-2cd10f15172a"
      },
      "source": [
        "len(set(list(linhas_602nan)) & set(list(linhas_599nan)))  \n",
        "# 602nan e 599nan apresentam 596 linhas em comum\n",
        "# entÃ£o tem 3 linhas em 599nan que nÃ£o estÃ£o em 602 nan e\n",
        "# 6 linhas em 602nan que nÃ£o estÃ£o em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXs7y99OyUEG",
        "outputId": "a6e963f8-43b9-4e53-d3cd-73c036721f9b"
      },
      "source": [
        "set(list(linhas_602nan)) - set(list(linhas_599nan)) # 6 linhas {1213, 1224, 3233, 5346, 6101, 7297} em 602nan mas nÃ£o em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpep48R0N19",
        "outputId": "54405911-141a-480b-dd4b-57daf90b6354"
      },
      "source": [
        "set(list(linhas_599nan)) - set(list(linhas_602nan)) # 3 linhas {5788, 10284, 10965} em 599nan mas nÃ£o em 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5788, 10284, 10965}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VghwKgdRwF2Y"
      },
      "source": [
        "linhas_34nan = df_train['ind01'][df_train['ind01'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozi0Gw990yml",
        "outputId": "04e1e738-a686-462c-fcc0-5b3493479a69"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_599nan))  # 34nan e 599nan nÃ£o apresentam linhas nan em comum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFs38gIx0zIQ",
        "outputId": "ccb5b11a-512a-45df-b75a-fbae70a82fe6"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_602nan)) # linhas {1213, 1224, 3233, 5346, 6101, 7297} em comum em 34nan e 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g41VmVkq-_R",
        "outputId": "5dee64cb-b577-4005-9ccb-cc336e42ca62"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdaAew8P89Jn",
        "outputId": "067f5309-3973-4017-8fb3-e069c718d740"
      },
      "source": [
        "df_train[df_train['mc1'].notna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    7917\n",
              "True     2514\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Ly8LJv2_9J_x",
        "outputId": "fa8b025e-00fc-4ad8-aa29-17f3a08c7bb5"
      },
      "source": [
        "df_train[df_train['mc1'].notna()].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.00000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.00000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5998.586521</td>\n",
              "      <td>53.33851</td>\n",
              "      <td>0.011993</td>\n",
              "      <td>0.013208</td>\n",
              "      <td>0.118480</td>\n",
              "      <td>0.014551</td>\n",
              "      <td>0.009693</td>\n",
              "      <td>0.002250</td>\n",
              "      <td>0.016025</td>\n",
              "      <td>0.032519</td>\n",
              "      <td>0.017690</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.134538</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.079664</td>\n",
              "      <td>0.133032</td>\n",
              "      <td>0.311410</td>\n",
              "      <td>0.330905</td>\n",
              "      <td>0.345606</td>\n",
              "      <td>0.365514</td>\n",
              "      <td>0.321753</td>\n",
              "      <td>0.37509</td>\n",
              "      <td>0.007881</td>\n",
              "      <td>0.001454</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.149238</td>\n",
              "      <td>0.178966</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.020676</td>\n",
              "      <td>0.00391</td>\n",
              "      <td>0.014755</td>\n",
              "      <td>0.004276</td>\n",
              "      <td>0.677786</td>\n",
              "      <td>0.686280</td>\n",
              "      <td>0.544727</td>\n",
              "      <td>0.53817</td>\n",
              "      <td>0.339742</td>\n",
              "      <td>0.333741</td>\n",
              "      <td>0.099889</td>\n",
              "      <td>0.570311</td>\n",
              "      <td>0.550781</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.295011</td>\n",
              "      <td>0.333269</td>\n",
              "      <td>0.999135</td>\n",
              "      <td>0.460636</td>\n",
              "      <td>0.907238</td>\n",
              "      <td>0.714602</td>\n",
              "      <td>0.644526</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>0.134254</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.170790</td>\n",
              "      <td>0.090957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3467.890242</td>\n",
              "      <td>19.98793</td>\n",
              "      <td>0.042113</td>\n",
              "      <td>0.026769</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.040304</td>\n",
              "      <td>0.037191</td>\n",
              "      <td>0.025934</td>\n",
              "      <td>0.029294</td>\n",
              "      <td>0.027583</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>0.038919</td>\n",
              "      <td>0.022033</td>\n",
              "      <td>0.013933</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007199</td>\n",
              "      <td>0.267626</td>\n",
              "      <td>0.283498</td>\n",
              "      <td>0.456864</td>\n",
              "      <td>0.438529</td>\n",
              "      <td>0.436875</td>\n",
              "      <td>0.463864</td>\n",
              "      <td>0.435993</td>\n",
              "      <td>0.44446</td>\n",
              "      <td>0.070991</td>\n",
              "      <td>0.032711</td>\n",
              "      <td>0.030087</td>\n",
              "      <td>0.319113</td>\n",
              "      <td>0.328067</td>\n",
              "      <td>0.164659</td>\n",
              "      <td>0.133429</td>\n",
              "      <td>0.06070</td>\n",
              "      <td>0.117785</td>\n",
              "      <td>0.064327</td>\n",
              "      <td>0.458565</td>\n",
              "      <td>0.456224</td>\n",
              "      <td>0.455770</td>\n",
              "      <td>0.45715</td>\n",
              "      <td>0.433962</td>\n",
              "      <td>0.434225</td>\n",
              "      <td>0.221986</td>\n",
              "      <td>0.425340</td>\n",
              "      <td>0.412952</td>\n",
              "      <td>0.059627</td>\n",
              "      <td>0.012832</td>\n",
              "      <td>0.018721</td>\n",
              "      <td>0.456070</td>\n",
              "      <td>0.471405</td>\n",
              "      <td>0.029402</td>\n",
              "      <td>0.498472</td>\n",
              "      <td>0.290112</td>\n",
              "      <td>0.451626</td>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>0.340941</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.206812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3012.500000</td>\n",
              "      <td>42.00000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002518</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.020741</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130695</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6006.000000</td>\n",
              "      <td>47.00000</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.005624</td>\n",
              "      <td>0.112164</td>\n",
              "      <td>0.002776</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007169</td>\n",
              "      <td>0.024386</td>\n",
              "      <td>0.005072</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131472</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.58330</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8990.500000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>0.006366</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.118149</td>\n",
              "      <td>0.011908</td>\n",
              "      <td>0.004606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016753</td>\n",
              "      <td>0.033129</td>\n",
              "      <td>0.017071</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133913</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918500</td>\n",
              "      <td>0.95860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id        cnae2  ...         ind42         ind43\n",
              "count  10431.000000  10431.00000  ...  10428.000000  10428.000000\n",
              "mean    5998.586521     53.33851  ...      0.170790      0.090957\n",
              "std     3467.890242     19.98793  ...      0.376344      0.206812\n",
              "min        0.000000      0.00000  ...      0.000000      0.000000\n",
              "25%     3012.500000     42.00000  ...      0.000000      0.000000\n",
              "50%     6006.000000     47.00000  ...      0.000000      0.000000\n",
              "75%     8990.500000     69.00000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.00000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWABZ-yWrQH2",
        "outputId": "e5092897-4659-4d79-969e-cc54bd1c11c4"
      },
      "source": [
        "df_train['target'].value_counts()   22,84% True e 77,16% False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3hg6GGQt9us"
      },
      "source": [
        "# Total de 46 Colunas/variÃ¡veis que apresentam NaN:\n",
        "# 'mc1', 'mc2', 'mc3',\n",
        "# 'ind01', 'ind02', 'ind03', 'ind04', 'ind05','ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30',\n",
        "# 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
        "# 'ind41', 'ind42', 'ind43'\n",
        "sendo:\n",
        "  # 32 colunas/variÃ¡veis que possuem 34 NaN cada\n",
        "    #'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "    #'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "    #'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "    #'ind40', 'ind41'\n",
        "  # 11 colunas/variÃ¡veis que possuem 599 NaN cada:\n",
        "    # 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "    # 'ind38', 'ind39',\n",
        "    # 'ind42', 'ind43'\n",
        "  # 3 colunas/variÃ¡veis que possuem 602 NaN cada\n",
        "    # ['mc1', 'mc2', 'mc3']\n",
        "\n",
        "# 602nan e 599nan apresentam 596 linhas em comum, entÃ£o:\n",
        "# 3 linhas em 599nan que nÃ£o estÃ£o em 602 nan : {5788, 10284, 10965}\n",
        "# 6 linhas em 602nan que nÃ£o estÃ£o em 599nan : {1213, 1224, 3233, 5346, 6101, 7297}\n",
        "\n",
        "# 602nan e 34nan apresentam 6 linhas em comum {1213, 1224, 3233, 5346, 6101, 7297} , que sÃ£o as mesmas 6 linhas que nÃ£o estÃ£o em 599nan\n",
        "# 599nan e 34nan nÃ£o apresentam linhas em comum\n",
        "\n",
        "# Total de 633 linhas com NaN ( = 596 + 3 + 6 + 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUqmH2Bt9uz"
      },
      "source": [
        "s_coluna = pd.Series(list(df_train.columns))\n",
        "s_qtde = pd.Series(list(df_train.isna().sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOMEunK3U29"
      },
      "source": [
        "df_nan = pd.DataFrame(zip(s_coluna, s_qtde),columns = ['coluna','qtde_nan'])\n",
        "df_nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3rZDA3t3q2p"
      },
      "source": [
        "df_nan[df_nan['qtde_nan']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLD7DW9a3t-J",
        "outputId": "ac583888-6975-4f49-a1c1-c1d0ba843a64"
      },
      "source": [
        "len(df_nan[df_nan['qtde_nan']!=0])        # 46 variÃ¡veis/colunas apresentam NaN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKbN8oAZ6uRf",
        "outputId": "5d4a510a-76b9-4598-d86d-66b71d00973f"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PBBF4-719u",
        "outputId": "bd2e3929-89c5-4f4b-941b-61015797e002"
      },
      "source": [
        "df_train['ind06'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind32'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5441\n",
              "1.0000    4081\n",
              "0.1671      62\n",
              "0.1534      41\n",
              "0.1644      38\n",
              "Name: ind06, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyl-JR3y8B_9",
        "outputId": "5d1e8982-89c7-4a49-d77a-735e570da7da"
      },
      "source": [
        "df_train['ind32'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    6958\n",
              "1.0    4041\n",
              "Name: ind32, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyySiN6PK3iU",
        "outputId": "907b60c3-6ce4-4fd4-a96c-40b8cb143622"
      },
      "source": [
        "df_train['ind04'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind05'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5812\n",
              "1.0000    3151\n",
              "0.0833     532\n",
              "0.9167     258\n",
              "0.1667     224\n",
              "Name: ind04, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-2Obx4LK3xA",
        "outputId": "3d1043e4-60e6-406a-f734-ea7bb12f6d7f"
      },
      "source": [
        "df_train['ind05'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    4776\n",
              "1.0000    3161\n",
              "0.0833     434\n",
              "0.9167     250\n",
              "0.1667     179\n",
              "Name: ind05, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbhjyN3LUU2",
        "outputId": "baf93d03-285c-4688-d097-956ff3360fcf"
      },
      "source": [
        "df_train['ind03'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind31'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    6844\n",
              "1.0000    3642\n",
              "0.0027      21\n",
              "0.0055      12\n",
              "0.1671      11\n",
              "Name: ind03, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ZuDkAPLUgt",
        "outputId": "3e432775-b12a-41e4-fccd-f69eaabbcab3"
      },
      "source": [
        "df_train['ind31'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    7357\n",
              "1.0    3642\n",
              "Name: ind31, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrx-HSHHMyCq",
        "outputId": "55126dd1-48a4-43eb-900e-8f0db36de927"
      },
      "source": [
        "df_train['ind23'].value_counts().head()     # alta correlaÃ§Ã£o com 'ind24'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5018\n",
              "1.0000    2847\n",
              "0.0833     833\n",
              "0.1667     400\n",
              "0.2500     218\n",
              "Name: ind23, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMjX8IY2MyNP",
        "outputId": "c53eb23f-5d06-435d-c8f8-92076a19f984"
      },
      "source": [
        "df_train['ind24'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5136\n",
              "1.0000    2837\n",
              "0.0833     835\n",
              "0.1667     377\n",
              "0.2500     208\n",
              "Name: ind24, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMeKN8lNUIt",
        "outputId": "cc01503e-5456-426f-ae20-6ce841716839"
      },
      "source": [
        "df_train['ind42'].value_counts().head()   #alta correlaÃ§Ã£o com 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "1.0    1781\n",
              "Name: ind42, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXgzAeTgNUSM",
        "outputId": "6a572209-11ab-4302-8ccb-662e0738f363"
      },
      "source": [
        "df_train['ind43'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "0.5    1665\n",
              "1.0     116\n",
              "Name: ind43, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-xtwpcNrad",
        "outputId": "9fe5fdf5-f4f2-4bf5-d673-e3ebdacc1719"
      },
      "source": [
        "df_train['md2'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015110    8\n",
              "0.001655    7\n",
              "0.004966    6\n",
              "0.001986    6\n",
              "0.001324    5\n",
              "Name: md2, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8QRBw3Nrnf",
        "outputId": "43c65572-3f64-46bb-caab-4dd7660ad0b9"
      },
      "source": [
        "df_train['md8'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.039463    8\n",
              "0.017749    7\n",
              "0.025066    6\n",
              "0.019375    5\n",
              "0.019700    5\n",
              "Name: md8, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltYMeW-N1wG",
        "outputId": "f916e55d-abb8-46ae-b123-250e71288746"
      },
      "source": [
        "df_train['md7'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022106    8\n",
              "0.001986    7\n",
              "0.001655    6\n",
              "0.007449    6\n",
              "0.003310    5\n",
              "Name: md7, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo_VW-5a_6hL",
        "outputId": "42af1401-fa12-4e09-ddcc-c5f507918878"
      },
      "source": [
        "df_train['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv5QEKyPl0iG",
        "outputId": "35a463c7-5c68-4265-d5cd-bfb87ee1fcfa"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "cnae2     0\n",
              "rf2       0\n",
              "md1       0\n",
              "md2       0\n",
              "         ..\n",
              "ind40     0\n",
              "ind41     0\n",
              "ind42     0\n",
              "ind43     0\n",
              "target    0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxu66h0D2ZuV"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJStLm07t9u_"
      },
      "source": [
        "Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vSe45kBt9vA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WirO9VPz6tR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrodOQuDsKpc"
      },
      "source": [
        "def calcula_outliers(df):\n",
        "    Q1 = []\n",
        "    Q3 = []\n",
        "    IQR = []\n",
        "    linf = []\n",
        "    lsup = []\n",
        "    qtde_inf = []\n",
        "    qtde_sup = []\n",
        "    col = []\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        Q1.append(q1)\n",
        "        Q3.append(q3)\n",
        "        IQR.append(iqr)\n",
        "        linf.append(lim_inf)\n",
        "        lsup.append(lim_sup)\n",
        "        qtde_inf.append(len(df[df[i]<lim_inf]))\n",
        "        qtde_sup.append(len(df[df[i]>lim_sup]))\n",
        "        col.append(i)\n",
        "    return (Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6MkPFtYu7x7"
      },
      "source": [
        "Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col = calcula_outliers(df_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9t9BOagvPXU"
      },
      "source": [
        "df_outliers = pd.DataFrame(np.array([Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup]), columns=[lcol] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "0EcHYgrfzoIN",
        "outputId": "7965cfb7-0685-46e1-e75e-97fffd0f714d"
      },
      "source": [
        "df_outliers.rename(index = {0:'q1', 1:'q3', 2:'iqr', 3:'lim_inf', 4:'lim_sup', 5:'abaixo_lim_inf', 6:'acima_lim_sup'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>q1</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>q3</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iqr</th>\n",
              "      <td>0.006032</td>\n",
              "      <td>0.010318</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013209</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.016188</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_inf</th>\n",
              "      <td>-0.009046</td>\n",
              "      <td>-0.013055</td>\n",
              "      <td>0.098338</td>\n",
              "      <td>-0.016855</td>\n",
              "      <td>-0.006283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.016656</td>\n",
              "      <td>0.002453</td>\n",
              "      <td>-0.024269</td>\n",
              "      <td>-0.010959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.001895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_sup</th>\n",
              "      <td>0.015083</td>\n",
              "      <td>0.028217</td>\n",
              "      <td>0.129641</td>\n",
              "      <td>0.028091</td>\n",
              "      <td>0.010472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036180</td>\n",
              "      <td>0.050965</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.018265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138690</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abaixo_lim_inf</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acima_lim_sup</th>\n",
              "      <td>1658.000000</td>\n",
              "      <td>1181.000000</td>\n",
              "      <td>1203.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1718.000000</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1110.000000</td>\n",
              "      <td>1098.000000</td>\n",
              "      <td>1129.000000</td>\n",
              "      <td>1578.000000</td>\n",
              "      <td>339.0</td>\n",
              "      <td>1297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1233.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        md1          md2          md3  ... ind41 ind42 ind43\n",
              "q1                 0.000003     0.002422     0.110077  ...   NaN   NaN   NaN\n",
              "q3                 0.006035     0.012740     0.117903  ...   NaN   NaN   NaN\n",
              "iqr                0.006032     0.010318     0.007826  ...   NaN   NaN   NaN\n",
              "lim_inf           -0.009046    -0.013055     0.098338  ...   NaN   NaN   NaN\n",
              "lim_sup            0.015083     0.028217     0.129641  ...   NaN   NaN   NaN\n",
              "abaixo_lim_inf     0.000000     0.000000     4.000000  ...   0.0   0.0   0.0\n",
              "acima_lim_sup   1658.000000  1181.000000  1203.000000  ...   0.0   0.0   0.0\n",
              "\n",
              "[7 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "j004R47yzwCU",
        "outputId": "03cf0785-03b9-4384-d70d-a2aa4ad79054"
      },
      "source": [
        "df_train.drop(['id','cnae2'],axis=1,inplace=False).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001607</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106393</td>\n",
              "      <td>0.156942</td>\n",
              "      <td>0.345577</td>\n",
              "      <td>0.363809</td>\n",
              "      <td>0.377947</td>\n",
              "      <td>0.396748</td>\n",
              "      <td>0.304172</td>\n",
              "      <td>0.354500</td>\n",
              "      <td>0.007431</td>\n",
              "      <td>0.001371</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.170026</td>\n",
              "      <td>0.034449</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.003777</td>\n",
              "      <td>0.014728</td>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.695732</td>\n",
              "      <td>0.701113</td>\n",
              "      <td>0.555893</td>\n",
              "      <td>0.540622</td>\n",
              "      <td>0.325660</td>\n",
              "      <td>0.319979</td>\n",
              "      <td>0.094443</td>\n",
              "      <td>0.573265</td>\n",
              "      <td>0.549543</td>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.330101</td>\n",
              "      <td>0.366265</td>\n",
              "      <td>0.999184</td>\n",
              "      <td>0.487537</td>\n",
              "      <td>0.911266</td>\n",
              "      <td>0.730536</td>\n",
              "      <td>0.660654</td>\n",
              "      <td>0.004804</td>\n",
              "      <td>0.126892</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.161425</td>\n",
              "      <td>0.085969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012535</td>\n",
              "      <td>0.012276</td>\n",
              "      <td>0.013302</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305507</td>\n",
              "      <td>0.314749</td>\n",
              "      <td>0.469850</td>\n",
              "      <td>0.451344</td>\n",
              "      <td>0.448622</td>\n",
              "      <td>0.472732</td>\n",
              "      <td>0.430218</td>\n",
              "      <td>0.440494</td>\n",
              "      <td>0.068959</td>\n",
              "      <td>0.031765</td>\n",
              "      <td>0.029217</td>\n",
              "      <td>0.311906</td>\n",
              "      <td>0.322485</td>\n",
              "      <td>0.160898</td>\n",
              "      <td>0.129652</td>\n",
              "      <td>0.059707</td>\n",
              "      <td>0.117835</td>\n",
              "      <td>0.062471</td>\n",
              "      <td>0.451710</td>\n",
              "      <td>0.450337</td>\n",
              "      <td>0.445655</td>\n",
              "      <td>0.444689</td>\n",
              "      <td>0.425934</td>\n",
              "      <td>0.426005</td>\n",
              "      <td>0.217015</td>\n",
              "      <td>0.413842</td>\n",
              "      <td>0.401642</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.013319</td>\n",
              "      <td>0.018179</td>\n",
              "      <td>0.470270</td>\n",
              "      <td>0.481805</td>\n",
              "      <td>0.028551</td>\n",
              "      <td>0.499867</td>\n",
              "      <td>0.284372</td>\n",
              "      <td>0.443702</td>\n",
              "      <td>0.473509</td>\n",
              "      <td>0.069146</td>\n",
              "      <td>0.332867</td>\n",
              "      <td>0.016488</td>\n",
              "      <td>0.009520</td>\n",
              "      <td>0.367939</td>\n",
              "      <td>0.202125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.138900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860800</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                md1           md2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  11033.000000  11033.000000\n",
              "mean       0.011670      0.012928  ...      0.161425      0.085969\n",
              "std        0.041618      0.026515  ...      0.367939      0.202125\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.000003      0.002422  ...      0.000000      0.000000\n",
              "50%        0.000316      0.005415  ...      0.000000      0.000000\n",
              "75%        0.006035      0.012740  ...      0.000000      0.000000\n",
              "max        1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJF8Q05rbSF",
        "outputId": "d9835c6f-551b-4605-ab2f-9ff7464e9c1b"
      },
      "source": [
        "df_test.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JWJ0Z3ZBT8x",
        "outputId": "82b334d4-5001-4a31-c9f8-914aeab58285"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqmeyNYfBUkz"
      },
      "source": [
        "def f_trata_outliers(df):\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        df[i][df[i] < lim_inf] = lim_inf\n",
        "        df[i][df[i] > lim_sup] = lim_sup\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN--_ZdBdAb"
      },
      "source": [
        "f_trata_outliers(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6RCkr7CSAO"
      },
      "source": [
        "f_trata_outliers(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Y2TJ-Gt9vE"
      },
      "source": [
        "# funÃ§Ã£o que trata NaN:\n",
        "def f_trata_NaN(df):\n",
        "    coluna_nan = df.isna().sum()[df.isna().sum().values>0].index\n",
        "    for col in coluna_nan:\n",
        "      df[col] = df[col].fillna(df[col].median())\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-4KOA0t9vK"
      },
      "source": [
        "# tratando NaN nos dataframes df_train e df_test:\n",
        "df_train = f_trata_NaN(df_train)\n",
        "df_test = f_trata_NaN(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0E1CSAYnch8"
      },
      "source": [
        "# criando dummies em df_train e df_test:\n",
        "df_train = pd.get_dummies(df_train, drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, drop_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Es33OXkQnyLc",
        "outputId": "0ea8aa72-ca3f-42fb-cd96-8ef1648ecbe8"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\":{df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 72), \"df_test.shape:\":(1000, 71)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWjvdF3F2Xs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU4mjAscF4Ge"
      },
      "source": [
        "### PULAR PARA PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3tEEKJF2pO"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfiez91PF20t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj5Nlm_iEggt",
        "outputId": "7e32c74e-508b-4c85-bffb-13cdcc9e345e"
      },
      "source": [
        "df_train['target'].astype('category')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         True\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "11028    False\n",
              "11029    False\n",
              "11030     True\n",
              "11031    False\n",
              "11032     True\n",
              "Name: target, Length: 11033, dtype: category\n",
              "Categories (2, object): [False, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i57fUZmDt9vP",
        "outputId": "9098a979-065d-4cf5-90bd-977906908a55"
      },
      "source": [
        "# definindo X (sem 'id' e 'target'), y (variÃ¡vel target) e X_submit (sem 'id'): \n",
        "X = df_train.drop(columns= ['id','target'], axis= 1)\n",
        "y = df_train['target']\n",
        "X_submit = df_test.drop(columns='id',axis=1)\n",
        "\n",
        "f'\"X.shape:\":{X.shape}, \"y.shape:\":{y.shape}, \"X_submit.shape:\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X.shape:\":(11033, 70), \"y.shape:\":(11033,), \"X_submit.shape:\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsYMnSZXKogI",
        "outputId": "050ed15b-a6a2-48f3-e15e-f3250de8b219"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cnae2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8', 'md9',\n",
              "       'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4', 'ind01', 'ind02',\n",
              "       'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
              "       'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18',\n",
              "       'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26',\n",
              "       'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32', 'ind33', 'ind34',\n",
              "       'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40', 'ind41', 'ind42',\n",
              "       'ind43', 'rf2_d', 'rf2_i', 'rf2_k', 'rf2_p', 'rf2_q', 'rf2_r', 'rf2_s',\n",
              "       'rf2_v', 'rf2_y', 'rf2_z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8J8ej6t9vT"
      },
      "source": [
        "MODELO: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpaBkXMzmLwh"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsRI-rGxmnQC"
      },
      "source": [
        "# FunÃ§Ã£o para cross validation:\n",
        "def funcao_cross_val_score(modelo, X_treinamento, y_treinamento, CV):\n",
        "    #versÃ£o com cross_val_score::\n",
        "    a_scores_CV = cross_val_score(modelo, X_treinamento, y_treinamento, cv = CV)\n",
        "    print(f'MÃ©dia das AcurÃ¡cias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "    print(f'std mÃ©dio das AcurÃ¡cias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "    return a_scores_CV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaez67ksHsc0"
      },
      "source": [
        "# FunÃ§Ã£o para Confusion Matrix:\n",
        "from sklearn.metrics import confusion_matrix \n",
        "def mostra_confusion_matrix(cf, \n",
        "                            group_names = None, \n",
        "                            categories = 'auto', \n",
        "                            count = True, \n",
        "                            percent = True, \n",
        "                            cbar = True, \n",
        "                            xyticks = False, \n",
        "                            xyplotlabels = True, \n",
        "                            sum_stats = True, \n",
        "                            figsize = (8, 8), \n",
        "                            cmap = 'Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_8spMrGt9vU"
      },
      "source": [
        "i_CV = 10 # NÃºmero de Cross-Validations\n",
        "i_Seed = 22091980 # semente por questÃµes de reproducibilidade\n",
        "f_Test_Size = 0.3 # ProporÃ§Ã£o do dataframe de validaÃ§Ã£o (outros valores poderiam ser 0.15, 0.20 ou 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eDY6msH0t9vY",
        "outputId": "864288a8-1c95-4378-93a6-c0ace2604968"
      },
      "source": [
        "# Definindo dataframes de TREINAMENTO e TESTE a partir de X e y:\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = f_Test_Size, random_state = i_Seed)\n",
        "f'\"X_treinamento.shape:\" {X_treinamento.shape}, \"y_treinamento_shape:\"{y_treinamento.shape},\"X_teste.shape:\"{X_teste.shape},\"y_teste.shape:\"{y_teste.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento.shape:\" (7723, 70), \"y_treinamento_shape:\"(7723,),\"X_teste.shape:\"(3310, 70),\"y_teste.shape:\"(3310,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjUjFaykt9vf"
      },
      "source": [
        "# Instancia...\n",
        "ml_XGB= XGBClassifier(silent=False,\n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 1,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=1000, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth= 3, \n",
        "                      gamma=1, \n",
        "                      max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTFhHr6Ar4mP",
        "outputId": "623d16c7-d681-46a3-f908-a035a9fc2c8b"
      },
      "source": [
        "# Modelo treinado sobre base \"train-split-test\"\n",
        "ml_XGB.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
              "              learning_rate=0.01, max_delta_step=5, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=False, subsample=0.8, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EH4l3lAt9vo",
        "outputId": "1a6bc8da-8467-4c10-ceb3-4d79613a7dc6"
      },
      "source": [
        "# Chamando a funÃ§Ã£o do CROSS VALIDATION - Modelo treinado sobre base \"train-split-test\":\n",
        "\n",
        "a_scores_CV = funcao_cross_val_score(ml_XGB, X_treinamento, y_treinamento, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.39\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHujyPesnWF",
        "outputId": "9c5bcd70-b10e-46fd-bcc1-af15cf57f38d"
      },
      "source": [
        "y_pred = ml_XGB.predict(X_teste)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3185  125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TXeOdfIsPkp",
        "outputId": "2587031c-0e86-4569-eec6-6a4beb2d825f"
      },
      "source": [
        "y_submit_0 = ml_XGB.predict(X_submit)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_0, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Mr2xE0EMnQ"
      },
      "source": [
        "# CV com X_treinamento e y_treinamento:       # Modelo treinado sobre base \"train-split-test\"\n",
        "# AcurÃ¡cia MÃ©dia / STD mÃ©dio\n",
        "# 77,38 / 0,54  tirando outliers - 70% X\n",
        "# 77,39 / 0,51  sem tirar outliers - 70% X\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste)\n",
        "# 0: 3177, 1: 133 => tirando outliers de df_train - 30% X\n",
        "# 0: 3185, 1: 125 => sem tirar outliers de df_train - 30% X\n",
        "\n",
        "# y_submit = ml_XGB.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "#  ???????????  => tirando outliers de df_train (nÃ£o rodei)\n",
        "# 0: 952, 1: 48 => sem tirar outliers de df_train (70% X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "iQhLNFkyt9v5",
        "outputId": "5de1fb25-c83b-4706-c3e7-06fcabda7dbd"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "********* CONFUSION MATRIX - PARAMETER TUNNING ***********\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAIKCAYAAABBQBSMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hURdvH8e+dhN5Dkya9o1QFBZEmIIL0JioKCgooFlB6E6zYRRAQBVEUFRUQQYoNFQF5EJEiVXrvhJIyzx9ZYoAkLIeEJO7v817nYnf2nDNz9vHdO/fMnDnmnENEREQuLSi5GyAiIpJaKGiKiIj4SUFTRETETwqaIiIiflLQFBER8ZOCpoiIiJ8UNEVEJFUxs0Jm9p2ZrTGzv8yst698mJntNLOVvq1JrGP6m9lGM1tvZo1ilTf2lW00s36XrDsp7tPMULmXbv6UVO/wsreSuwkiiSJ9CJZU506K3/tT/3srwfaaWT4gn3NuhZllAX4HWgDtgBPOudEX7F8OmAbcCOQHFgClfB//DdwG7ACWAR2dc2viqzvE0xWJiIgkE+fcbmC37/VxM1sLFEjgkObAx865M8AWM9tIdAAF2Oic2wxgZh/79o03aKp7VkREvLOgxN8up3qzIkBl4DdfUS8zW2Vmk8wsh6+sALA91mE7fGXxlcdLQVNERFIUM+tmZstjbd3i2S8z8DnwmHPuGDAWKA5UIjoTfTmx26buWRER8c4Sf7jUOTceGJ9wtZaG6ID5oXNuhu+4vbE+nwDM9r3dCRSKdXhBXxkJlMdJmaaIiKQqZmbAu8Ba59wrscrzxdqtJbDa93om0MHM0plZUaAksJToiT8lzayomaUFOvj2jZcyTRER8e4yxyATSU3gHuBPM1vpKxsAdDSzSoADtgLdAZxzf5nZdKIn+EQAPZ1zkQBm1guYBwQDk5xzfyVUsYKmiIh4lwTds5finFsMcd5GMyeBY0YBo+Ion5PQcRdS96yIiIiflGmKiIh3ydM9m2wC62pFRESugDJNERHxLhnGNJOTgqaIiHin7lkRERGJizJNERHxLsC6Z5VpioiI+EmZpoiIeBdgY5oKmiIi4p26Z0VERCQuyjRFRMS7AOueDayrFRERuQLKNEVExDuNaYqIiEhclGmKiIh3ATamqaApIiLeBVjQDKyrFRERuQLKNEVExLsgTQQSERGROCjTFBER7wJsTFNBU0REvNN9miIiIhIXZZoiIuJdgHXPBtbVioiIXAFlmiIi4l2AjWkqaIqIiHfqnhUREZG4KNMUERHvAqx7VpmmiIiIn5RpioiIdwE2pqmgKSIi3ql7VkREROKiTFNERLwLsO7ZwLpaERGRK6BMU0REvNOYpoiIiMRFmaaIiHgXYGOaCpoiIuJdgAXNwLpaERGRK6BMU0REvNNEIBEREYmLMk0REfEuwMY0FTRFRMQ7dc+KiIhIXJRpioiIdwHWPRtYVysiInIFlGmKiIh3ATamqaApIiKeWYAFTXXPioiI+EmZpoiIeKZMU0REROKkTFNERLwLrERTmaaIiIi/lGmKiIhngTamqaApIiKeBVrQVPesiIiIn5RpioiIZ8o0RUREJE7KNEVExLNAyzQVNEVExLvAipnqnhUREfGXMk0REfEs0LpnlWmKiIj4SZmmiIh4FmiZpoKmiIh4FmhBU92zIiIiflKmKSIininTFBERkTgp0xQREe8CK9FUpikiIuIvZZoiIuJZoI1pKmiKiIhngRY01T0rIiLiJ2WaIiLimTJNERERiZMyTRER8S6wEk0FTRER8U7dsyIiIhInZZoiIuKZMk0REZEUzMwKmdl3ZrbGzP4ys96+8lAzm29mG3z/5vCVm5m9YWYbzWyVmVWJda7Ovv03mFnnS9WtoCkiIp6ZWaJvfogAnnTOlQNqAD3NrBzQD1jonCsJLPS9B7gdKOnbugFjfW0PBYYC1YEbgaHnAm18FDRFRMSz5AiazrndzrkVvtfHgbVAAaA5MNm322Sghe91c2CKi7YEyG5m+YBGwHzn3CHn3GFgPtA4oboVNEVEJNUysyJAZeA3IK9zbrfvoz1AXt/rAsD2WIft8JXFVx4vBU0REfHOEn8zs25mtjzW1i3Oqs0yA58DjznnjsX+zDnnAJfIV6ugeTlCs2Viycf9WPJxP7bMf5ZN80bGvE8TEpyoda37ejjTRj8Q875lg0qMH353otYB0OuuOmRInybm/RdvPky2zBkSvR5JmSpfV5Z2rZrHbDt37oh33xrVKidavV3vu4c772hE25Z30rlTB7Zu2XzZ5+j50IMcO3aMY8eO8cm0D2PK9+3by5OPPZpobZWrzzk33jlXLdY2/sJ9zCwN0QHzQ+fcDF/xXl+3K75/9/nKdwKFYh1e0FcWX3m8dMvJZTh09CQ1OjwPwMDuTTgZdobXPlgY83lwcBCRkVGJVl/lsoUoU+wa1m3ek2jnvFCvTnWZNmcZp06HA9DykbFJVpekPOnSpWf6jK+Spe7nXhhN+QrX8dn0T3hl9Iu8MWbcZR0/ZtwEAHbu3MEnH0+jfcdOAOTJk5eXX3sj0dsrcUuOW04sutJ3gbXOuVdifTQT6Aw87/v3q1jlvczsY6In/Rx1zu02s3nAs7Em/zQE+idUtzLNKzR++N28MbADP07pw7OPtWBg9yY8dk/9mM+XfzqAa/OFAtChyQ389EEflnzcjzcHdiAoKOH/2F7/YBFPd210UXnG9GkZN7QTP33Qh1+nPU3TOtcBkCF9Gqa+0IUVnw/kk5cf5McpfahS7trocw1oz+IPn+L3zwYy6KEmAPToeCv5cmdj7vjezB0f/Zf5uq+HkzN7Jp559E66t6sdU2fs63r83vosntqXpZ/0jzmX/DeEnTzJg106075NS1q3aMZ3ixZctM/+/fu4/95OtGvVnFbNm7Li9+UA/PLzYu65qz3t27Skz+OPEnbypF91Vq1Wje3btuGc45XRL9CqeVNat2jG3G/mJFjf7bfV4/DhQ7z+6svs2L6Ndq2a88roF9i5cwetmjcF4O6O7di4cUNMXV3vu4e/Vv9JWFgYQwb15672bWjXukWc1ykpWk3gHqCema30bU2IDpa3mdkGoIHvPcAcYDOwEZgA9ABwzh0CngGW+bYRvrJ4KdNMBAXyZKfOfS8TFeUY2D3uIFK6aF7aNKxC3ftfISIiitf6t6NDkxv4aPbSeM/7+bcr6Nb2FooVynVe+dMPNOL7ZX/z0PAPyZY5Az9N7cuiJevp1vYWDh8Lo0rrUZQrno/fPu4Xc8ywt2Zx+FgYQUHGN+88SoWS+Xl72g88enc9Gnd7nYNHzv+B+2zeCl7q25p3pv8IQOuGlbmzxxjq1yhD8WvzUOvulzAzPnutOzWrFOfnFZu8fn2SjM6cOU27Vs0ByF+wIKNfeZ1X3xhD5syZOXz4EPd0bE+duvXPyybmfD2bm2vW4sHuDxMZGcnp06c4fPgQE94ZyzsT3yNjxoxMmjieKZPf46EevS7Zhh++/44SpUqxcP63rF+3jk9nfMWRw4e5q30bqlarFmd9sfV+/Ek2btgQkzHH7mJu1LgJ3879hhK9SrJ//z72799H+QrX8cZrr3Bj9RqMGPkcx44do1OHtlSvcTMZM2ZMjK81oCRHpumcW0z8q97Wv7DAN77ZM55zTQIm+Vu3gmYimLHgf0RFJTzeXPfG0lQpdy2Lpz4FQIZ0adh/6ESCx0RGRfHqlAX07dKQb39eE1Ne/6ay3HHrdTx2b/R/G+nThlAoXw5urlyMtz76HoA1m3bz54ZdMce0bliFLq1qEhIcxDW5s1K2WD5Wx/r8Qn+s30HuHFnIlzsbuXJk5sixMHbsPULPu+rS4KYyLPEF5MwZ0lHi2jwKmqnUhd2z4eHhvPHaK6z4fRlBFsS+fXs5eOAAuXLnjtmnQoXrGDpoABEREdSt14AyZcuyfNl3bN60kfvu7hhznusrVUqw7v5P9yF9uvTkL1CAfgMG88Hk92jc5A6Cg4PJmSsXVW+4gb/+/DPO+vzVsPHtPPRgF3r0epRv537DbQ2j7yb49ZfFfP/dIqa8F/1befbMGfbs3k2x4sX9PrdEC7QVgRQ0E0HYqTMxryMiI8/rdk2fNnqSjZkxddZvDHlz5mWd+6Ovl9K3S0PWbNwdU2ZAxz4T2fDPvvgPjKVw/pw8dk99at39IkeOn2L88LtJl/bS/9PPWPA/WjaoRN6cWfns2xW+64CXJn3Lu5//fFnXIanDnNmzOHz4ENOmzyBNmjTcfls9zpw9c94+VavdwKQpU/nphx8YMrAf93S+nyxZs1Ljppq8MPqVeM58sXNjmpcSV33Nmre45HEAefPmJXv27Py9fh3z5n7DoCHDAHAOXnntDYoULeZ3e0VAY5qJ7p9dh6hUNnoyVqUyBSlSICcA3y1dT8sGlcidIzMAObJm5Np8CS48AUBERBRvTv2ORzrVjSlb8OtaenS4NeZ9xdIFAfh15WZaN4xeHapMsWuoUCI/AFkzp+fk6TMcPXGaPKFZaFizXMyxx0+eIXPG9HHW/dm832nbqCotG1Rmxvz/ATD/l7V0bn4TmTKkBSB/7mwx1ySp34kTxwkNzUmaNGlY+tsSdu26eCLhrl07yZkzF63btqNl67asXfMX11esxMr/rWDbP/8AEBYWxtatWy6r7spVqzHvm2+IjIzk0KFDrFi+nArXXR9nfbFlypQpwfHTRo2b8N6kiRw/fpxSpcsAcHPNWnz04VSie+1g7do18R4vl5AEt5ykZMo0E9mXC1fSqemN/P7ZQJb9uTUmG1y3eQ/Dx8xm1theBJkRHhHJ489PZ9vuw5c85/tf/kq/B/9dpOK5CXN5qU9rlk0fQFCQsXXnQVr3Hsc7039i4jP3sOLzgfy9ZS9rNu/m6IlTbNq2nz/W7eCPLwazY89hlqz8d3r/pBk/M3NMD3bvP0rjbufPOFy7eQ+ZM6Zn174j7DkQfQvUwiXrKFP0Gr6f3AeAk6fOcP/Ayew/nHBXs6QOTZo249GeD9O6RTPKla9A0WIXZ2LLly7l/ffeJSQkhIwZMzLyuRcIDQ1lxKjn6Nf3Cc6GnwWg1yOPUaRIUb/rrt/gNlb98T/atmqOmfHYk33JlTs3M7/84qL6YsuePQeVKlehVfOm1LrllphZtOfc1rARLz4/im4P9Ygp6/ZQD158/lnatLyTqKgoChQsyFtvv3M5X5UEKDv3l1ZiylC5V+KfVC4pKMhIExLMmbMRFC2YiznjenF9i2cIj4hM7qalSoeXvZXcTRBJFOlDki5/u/aRmYn+e7/tzTtTbL6pTPM/JGP6tMyd0Js0IUEYRu/npitgikiS0kQguap+nNKHtBdMyuk6aAp/bYx/Zmt8ToSdoVanFxOraSJX7LFHe7Jrx/mrDPV+og81a92STC0SuTLqnk1BCubNzsRn7iVPziw4B5M+/5kx075nYPcmdGl1c8y44dC3ZjJv8RpCs2Xio5e6UrV8YabOXMLjL3wac652javSt0sjnHPs3n+ULoMmX3QvpiRM3bOJ79ixYwwfMoiNG//GzBj+zLP88vNiPv9sOqE5ohcBeeSxJ7il9q2XOJNcjqTsni3Se3ai/95vfb1pik1flWmmIBGRUfR7ZQYr1+0gc8Z0/PLR0yz8bR0Ab0797rwl+wBOnwlnxNuzKVciP+WL54spDw4O4qW+bajSeiQHj5xkVO/mPNT+Vka9M+eqXo/IhV58bhQ1a93Cy6+9QfjZs5w6fTp6JaF776Pz/V2Tu3kil6RbTlKQPQeOsXJddFfWibAzrNuyh/y5s8e7f9jps/yycjOnz4SfV24WvZ27LSRL5gzs3n806Rou4ofjx4/z++/LaNm6DQBp0qYla9asydwquVLJ9BDqZKOgmUJdmy+USqULsmz1VgAe6lCbpZ/0Z9zQTmTPkvBTSCIiouj97Ccsmz6Azd+Oomyxa3j/y1+uQqtF4rdzxw5y5AhlyMD+tGvdgmFDBhIWFgbAxx99SJuWzRgyqD/HjuoPvFQlwO7TVNBMgTJlSMu00Q/Qd/TnHD95mgmf/kS5ZsOo3uF59hw4xvNPtErw+JCQIB5scws1Or5AsYYDWf33Tvp2aXiVWi8St8jICNatXUPbDh2Z/vmXZMiQgUkTx9OufUdmz53P9M+/InfuPIx+6flLn0wkmShopjAhIUFMG/0gn3yznK8W/QHAvkPHiYpyOOeYNONnqlUonOA5KpaKXiFoy44DAHw2fwU1Kmq5MEleefNeQ96813D99RUBuK1hY9atXUPOXLkIDg4mKCiIVm3asvrPP5O5pXI51D0ryWrc0E6s37KHN6Yuiim7Jte/4z7N61VkzabdcR0aY9f+o5Qpdg25fMvb1a9RhvVbku6ZnCL+yJU7N3mvuSbmgdO/LfmVYsWLs3//v2soL1qwgBIlSyZXE0UuSbNnU5CbKxWjU9Pq/Pn3zpiniAx9aybtGlXj+tIFcc7xz+5DPDJyWswx674eTpZM6UmbJoRmda+naY8xrNu8h2fHf8P8iY8RHhHJtt2H6DZ0anJdlkiMfgMG0//pPoSHh1OwYCFGjHyO558byfp16zCD/PkLMHjYiORuplyGlJ4ZJjbdpykSD92nKf8VSXmfZvEnv0n03/tNL9+eYiOxMk0REfEswBJNBU0REfEu0LpnNRFIRETET8o0r7KShfPwwQtdYt4XLZCTZ8Z+zVsffc/DHW6le7tbiIxyzP1pNQNf/+qi42+7uSyj+7YhOCiI97/8hdHvzQdgwbuPkTlT9MOk84RmYfnqrbR7YgIt6ldi8MN3cPjoSdo9MYFDR09StGAuRvRqxj393rsq1yz/fUMG9efHH74nNDQnM76afdHnx44eZcjgAezYvo20adMxfOSzlCxZKvqzONajrVipMq++/BI/L/6R0mXKMuq56AcRzJ71FUcOH+bue++7mpcnCQiwRFNB82rb8M8+anSIvnk7KMjYNG8UM7/7g9rVStK0znXc2P55zoZHkNt3u0hsQUHGa/3accfDb7Fz7xEWf9iX2T/8ybrNe2jQ9bWY/aaNfoBZ368C4OEOt1Lr7hdpXq8S7W+vxtiPf2BYz6YMe/viHzYRr5q3aEXHu+5mYP+n4/x84oRxlClTltfeGMOWzZt4duQIJkyaDMS9Hu3x48dZt3YNn30xi2FDBrLh7/UUurYwX30xg7ffmXg1L03kPOqeTUZ1byzNlh372bb7MN3a3sLo9+ZzNjwCIOaJJrHdUKEIm7YfYOvOg4RHRPLpvBU0rXP9eftkyZSeW28oxazvooNmVFQU6dKEkDF9WsIjIqlZuTh7Dxxj07b9SX+BEjCqVruBrNmyxfv55k2buLF6DQCKFivOrl07OXjgQLzr0QYFGRERETjnOH3qNCEhIUx+7106drqHNGnSXJVrEv9ocQO5ato2qsr0ub8DUKJwHmpWLs6PU/rw7cTeVC137UX758+TjR17D8e837n3MAVyn/9D1azu9Xy/dD3HT54G4KVJ8/l63CM0qV2B6XOX0+/Bxjw3YW4SXpXIxUqVLsPC+d8C8OeqVezetYu9e/fEux5tpkyZqXVLbdq3bkGu3LnJnCULf/65inr1GyTzlciFzj0gIjG3lExBM5mkCQnmjluvY8b8/wEQEhxEaLZM1L53NANe/ZKpL3a5xBni1q7xv4EYYNFv66jZ6UXaPPYOTetcz7zFf1GycB4+eqkrYwZ3JEN6/dUuSa/LA904dvw47Vo1Z9pHH1CmTFmCgoLjXY8W4P6uDzJ9xlf0eaofY958nZ69HmXGZ5/S94nejB/3djJfkQQqBc1k0qhWOVau286+Q8cB2Ln3CF8uXAnA8r/+ISrKxSyDd86ufUcpmDdHzPsCeXOwM9Yjv3Jmz0S18kX45qfVF9WXIX0a7mlWnXHTf2TQQ3fwwOAP+GXlZjrcfkNSXJ7IeTJnzswzo55j+oyvGPXcixw+fJiChQrFux5tbGvXrsE5R+EiRfl23lxeeuV1tm/fzj//bE2GK5ELBQVZom8pmYJmMmnXuNp5GeGs71dx6w3RswlLXJuHtGlCOHDBuObyv/6hxLW5KZw/J2lCgmnbqApf+yb8ALRsUJlvflrNmbMRF9X3+L0NeHvaD0RERJEhfRocjqioKDKmT5tEVyjyr2PHjhF+9iwAMz77lCrVqpE5c+Z416ONbcybr9Pzkd5EREQQFRUJRP9Qnz51+upehAiaPZssMqZPS73qZegVaw3ZyV/+yjvDOrH80wGcDY/kgSEfAJAvdzbeHnIXLR8ZS2RkFI+/MJ1Zb/ckOMiY/NUS1m7+dyH2to2qMvq9by+qL1/ubFSrUJhnx38DwNhpP7B46lMcPR5GuycmJPHVSiB4us8TLF+2lCNHDnNbvdo83PMRIiKi/3hr174jWzZvYtCAfphB8RIlGT5iVMyxca1He86ihQsoX74CefLkBaB0mbK0btGMUqVKUbpMmat7kRKnlD4Gmdi09qxIPLT2rPxXJOXasxUGzU/03/vVI29LsaFY3bMiIiJ+UvesiIh4Fmjds8o0RURE/KRMU0REPEvpK/gkNmWaIiIiflKmKSIingVapqmgKSIingVYzFT3rIiIiL+UaYqIiGeB1j2rTFNERMRPyjRFRMSzAEs0FTRFRMQ7dc+KiIhInJRpioiIZwGWaCrTFBER8ZcyTRER8SzQxjQVNEVExLMAi5nqnhUREfGXMk0REfEs0LpnlWmKiIj4SZmmiIh4FmCJpjJNERERfynTFBERzwJtTFNBU0REPAuwmKnuWREREX8p0xQREc8CrXtWmaaIiIiflGmKiIhnAZZoKmiKiIh36p4VERGROCnTFBERz5RpioiISJyUaYqIiGcBlmgqaIqIiHfqnhUREZE4KdMUERHPAizRVKYpIiLiL2WaIiLiWaCNaSpoioiIZwEWM9U9KyIi4i9lmiIi4llQgKWayjRFRET8pExTREQ8C7BEU5mmiIiIv5RpioiIZ7rlRERExE9BgRUz1T0rIiLiL2WaIiLiWaB1zyrTFBER8ZMyTRER8SzAEk0FTRER8c4IrKip7lkREUl1zGySme0zs9WxyoaZ2U4zW+nbmsT6rL+ZbTSz9WbWKFZ5Y1/ZRjPrd6l6lWmKiIhnyXjLyfvAW8CUC8pfdc6Njl1gZuWADkB5ID+wwMxK+T4eA9wG7ACWmdlM59ya+CpV0BQRkVTHOfejmRXxc/fmwMfOuTPAFjPbCNzo+2yjc24zgJl97Ns33qCp7lkREfHMzBJ9u0K9zGyVr/s2h6+sALA91j47fGXxlcdLQVNERDwzS4rNupnZ8lhbNz+bMxYoDlQCdgMvJ/b1qntWRERSFOfceGC8h+P2nnttZhOA2b63O4FCsXYt6CsjgfI4KdMUERHPgswSffPKzPLFetsSODezdibQwczSmVlRoCSwFFgGlDSzomaWlujJQjMTqkOZpoiIpDpmNg2oA+Qysx3AUKCOmVUCHLAV6A7gnPvLzKYTPcEnAujpnIv0nacXMA8IBiY55/5KqF4FTRER8Sy5VgRyznWMo/jdBPYfBYyKo3wOMMffetU9KyIi4idlmiIi4lmgPeVEQVNERDwLsJip7lkRERF/KdMUERHPruQWkdRImaaIiIiflGmKiIhngZVnKmiKiMgVCLTZs+qeFRER8ZMyTRER8SwZH0KdLOINmmb2JtHr98XJOfdokrRIREQkhUoo01x+1VohIiKpUqCNacYbNJ1zk2O/N7OMzrmwpG+SiIikFgEWMy89EcjMbjKzNcA63/uKZvZ2krdMREQkhfFn9uxrQCPgIIBz7g+gdlI2SkREUgczS/QtJfPrlhPn3PYLiiKToC0iIiIpmj+3nGw3s5sBZ2ZpgN7A2qRtloiIpAaBdsuJP5nmQ0BPoACwC6jkey8iIhJQLplpOucOAJ2uQltERCSVSeljkInNn9mzxcxslpntN7N9ZvaVmRW7Go0TEZGUzZJgS8n86Z79CJgO5APyA58C05KyUSIiIimRP0Ezo3PuA+dchG+bCqRP6oaJiEjKF2SW6FtKltDas6G+l9+YWT/gY6LXom0PzLkKbRMREUlREpoI9DvRQfJc2O8e6zMH9E+qRomISOqQwhPDRJfQ2rNFr2ZDREQk9Qm02bN+PU/TzCoA5Yg1lumcm5JUjRIREUmJLhk0zWwoUIfooDkHuB1YDChoiogEuABLNP2aPdsGqA/scc7dD1QEsiVpq0RERFIgf7pnTznnoswswsyyAvuAQkncLhERSQVS+i0iic2foLnczLIDE4ieUXsC+DVJWyUiIqlCgMVMv9ae7eF7Oc7M5gJZnXOrkrZZIiIiKU9CixtUSegz59yKpGmSiIikFrrl5F8vJ/CZA+rF9+F3n4703CAREZGUKqHFDepezYaIiEjq488tGP8lgXa9IiIinvm1IpCIiEhcNKYpIiLip6DAipmX7p61aHeb2RDf+2vN7Makb5qIiEjK4s+Y5tvATUBH3/vjwJgka5GIiKQaQZb4W0rmT/dsdedcFTP7H4Bz7rCZpU3idomIiKQ4/gTNcDMLJvreTMwsNxCVpK0SEZFUQROBLvYG8AWQx8xGEf3Uk0FJ2ioREUkVUnp3amLzZ+3ZD83sd6IfD2ZAC+fc2iRvmYiISArjz0OorwXCgFmxy5xz25KyYSIikvIFWO+sX92zXxM9nmlAeqAosB4on4TtEhERSXH86Z69LvZ739NPesSzu4iIBBA9hPoSnHMrzKx6UjRGRERSl0BbwNyfMc0nYr0NAqoAu5KsRSIiIimUP5lmllivI4ge4/w8aZojIiKpSYD1ziYcNH2LGmRxzvW5Su0RERFJseINmmYW4pyLMLOaV7NBIiKSemgi0L+WEj1+udLMZgKfAifPfeicm5HEbRMREUlR/BnTTA8cBOrx7/2aDlDQFBEJcAGWaCYYNPP4Zs6u5t9geY5L0laJiEiqoLVn/xUMZOb8YHmOgqaIiASchILmbufciKvWEhERSXUCbSJQQos5BNY3ISIicgkJZZr1r1orREQkVQqwRDP+oOmcO3Q1GyIiIqlPoE0ECrS1dkVERDy77KeciIiInGMBNv1FmaaIiIiflGmKiIhngTamqaApIt5Iyn4AACAASURBVCKeBVrQVPesiIiIn5RpioiIZxZgN2oq0xQREfGTMk0REfFMY5oiIiISJ2WaIiLiWYANaSpoioiId3o0mIiIiMRJmaaIiHimiUAiIiISJ2WaIiLiWYANaSpoioiId0F6NJiIiIjERZmmiIh4Fmjds8o0RURE/KRMU0REPNMtJyIiIn4KMkv0zR9mNsnM9pnZ6lhloWY238w2+P7N4Ss3M3vDzDaa2SozqxLrmM6+/TeYWedLXq+H70hERCS5vQ80vqCsH7DQOVcSWOh7D3A7UNK3dQPGQnSQBYYC1YEbgaHnAm18FDRFRMQzs8Tf/OGc+xE4dEFxc2Cy7/VkoEWs8iku2hIgu5nlAxoB851zh5xzh4H5XByIz6OgKSIiKYqZdTOz5bG2bn4emtc5t9v3eg+Q1/e6ALA91n47fGXxlcdLE4FERMSzpHjKiXNuPDD+Cs/hzMwlUpNiKNMUEZH/ir2+bld8/+7zle8ECsXar6CvLL7yeCloioiIZ8k1phmPmcC5GbCdga9ild/rm0VbAzjq68adBzQ0sxy+CUANfWXxUvesiIh4llyZl5lNA+oAucxsB9GzYJ8HpptZV+AfoJ1v9zlAE2AjEAbcD+CcO2RmzwDLfPuNcM5dOLnoPAqaIiKS6jjnOsbzUf049nVAz3jOMwmY5G+9CpoiIuKZBdjisxrTFBER8ZMyTRER8Syw8kwFTRERuQJJcZ9mSqbuWRERET8p0xQREc8CK89UpikiIuI3ZZoiIuJZgA1pKmiKiIh3uk9TRERE4qRMU0REPAu0zCvQrldERMQzZZoiIuKZxjRFREQkTso0RUTEs8DKMxU0RUTkCqh7VkREROKkTFNERDwLtMwr0K5XRETEM2WaIiLiWaCNaSpoioiIZ4EVMtU9KyIi4jdlmiIi4lmA9c4q0xQREfGXMk0REfEsKMBGNRU0RUTEM3XPioiISJyUaYqIiGcWYN2zyjRFRET8pExTREQ8C7QxTQVNERHxLNBmz6p7VkRExE/KNEVExLNA655VpikiIuInZZoiIuKZMk0RERGJk4Kmn+5rdhODe90ds+3fuyvefbu1rpNo9T7X72GG9u4c837LhrU81+/hRDv/OT/Nn83hg/tj3r/7+ih2btuc6PVIynPkyGHatWpOu1bNqVe7Jg3q3hLzPvzs2USt6/bb6tG6RTPatGxG9we7cGD//ksfdIF7O3UAYOfOHcyZPSum/K/Vf/L8syMTra3iH0uC/0vJ1D3rp7Rp0/HMW1OTpe5jRw/zx/JfqFjt5iSrY/HCrylYpDg5cuYGoGvvgUlWl6Qs2bPnYPqMrwAYO+ZNMmbMSOf7u8Z8HhERQUhI4v1UTHxvMjlyhPLGa68wccI79Bsw6LKOn/LhxwDs2rmTOXNm06RpMwDKV7iO8hWuS7R2in+CUnaMS3QKmh6dPhXG68/05eSJ40RGRND6nu5UuenW8/Y5cugAY54fyOmwk0RGRdK5x1OUrlCZP1cs4YsPJxARHk6eawrwwOODSZ8hY7x1NWl1N7M+ee+ioBkVGcn098ew7s8VhIeH06Bpa+re3oqoqCg+GDuatauWE5orL8EhwdS+rRk31KrPlx9NZOXSxZw9e4YSZa7j/kf6s/znRWzZsJZxLw0hbdp0DH55Ii8PfZwOXR9ly4a17Nu9gw5dHwWiM9ItG9dy78N9+XnRN8yfNZ3I8HCKlS5P5x5PERQcnPhftlx1gwf0I226tKxbu5ZKlauQOXPm84Jpq+ZNefPtcRQoUJDZs77io6kfEBEeToXrKzJw8FCC/fjvoGrVanz04QecOXOGkSOGseav1QQHB9PnqX7cWL0GGzduYMjA/kSEhxPlonj5tTcpXLgINapVZsny//H6qy+zZfMm2rVqTrPmLSlTtiyT35/EG2+N5Y5GDfjk8y/JmjUrAM1ub8j7H3yEBQUxcvhQ9uyO7inq228AlatUTbovUv5zFDT9dPbsGQb3uhuAXNfkp1f/Z3l00AtkyJiZ40ePMOLJrlSuURuLNSr+6/fzuK5KDe7scD9RkZGcOXOa40ePMPPj93h61FukS5+Brz+dwtwvPqLFXQ/EW3eJstfx+6/fs/aP5aTPmCmm/IdvZ5IhU2aGvfY+4eFnGdnnQSpUrsHWjWs5sG8Xz479mGNHDtP/ofbUvi36r/EGzdrG1PXO6KGsXLqYG2rVZ8Hsz+jQ9VGKlix7Xt3VatblmScfiAmav/20gDvb38eubVtY+tMCBr00gZCQECaPeZFfvp9HrfpNEucLl2S3d+9epnz4McHBwYwd82ac+2zetIl533zD5KnTSJMmDaNGDGPO7Fk0a97ikuf/4YfvKVGyFB9P+xAz+PzLWWzZvImHHuzKzDnz+PSTj+l0z73c0fROws+eJTIq6rzjez/+JJPfn8Rbb78DwLKlvwEQFBREnXr1WLRwPi1atmbVqj/Ilz8/OXPlol/fJ7n73s5UqVqN3bt28XD3rnw565sr/KYCW0rvTk1sCpp+urB7NiIigk8nj2X96pUEmXH44H6OHj5E9tCcMfsULVWOd18bSWRkBFVq3Erh4qVYuXQxu7ZvYWSfB33nCadEmUt3Kd3ZoQszP3mPdvf3iilb/b/f2L5lI8sXLwIgLOwEe3Zt4+81f3BDrfoEBQWRPTQnZa//9y/ptat+Z85nUzl75jQnThyjwLXFqFz9lnjrzZotB7mvyc/GdX9yTf5r2b1jKyXLVWTB7M/YunEdwx+7D4j+oyJr9hz+fZmSKjRs2PiSGeNvS35l7ZrVdGrfBoDTZ04TmjNngsc8cH9ngoOCKFm6NL0efYwhg/rT8a7oP0iLFitOvvz5+WfrFipWrMSE8ePYu2cP9W9rSOHCRfxue6PGTXhn7BhatGzNvDlf06hx9B9zS5b8wuZNG2P2O3HiBGEnT5IxU6b4TiVyHgVNj379bi7Hjx5h+OuTCQkJ4cn7WxAefua8fcpUqMyAF8bxx7KfmfjqCBq1vItMmbNQvtKN9Hj68iYslKtYjc+njGPjutX/FjrHPQ/14bqqNc7bd9XyX+I8x9mzZ5jy9osMe20yOXPn5YsPJxAefumJHjVq38bSnxaSr2Bhqt5UJzqbdo6a9ZvQ7r6el3UdknpkyJAh5nVwcDBRsTK9s2ei/1t3OJo1b0nvx5/0+7znxjQvpUnTZlx3fUV+/PF7ej3UjUFDh1O9xk1+1VGxUmW2b9vGoUOHWLRoAQ8+FD15zkVF8cG06aRLl87v9krCdMuJ+OVU2AmyZstBSEgIa/9YzoF9uy/a58C+3WTLHkqdxi2o3ag5/2xaR/EyFdiwdhV7d20H4MzpU+zZuc2vOu/scD9zPv8g5n2FKjVYNOdzIiIiANizcxtnTp+iZNmKLP/5O6Kiojh6+CDr/lwBEDMTMkvWbJw+FcaynxfFnCt9hoycDjsZZ71Vb6rDiiU/suSHb6le+zYAylWqxvKfF3HsyCEAThw/Gud3IP8N+QsUYO3aNQCsXfMXO3fuAKB69ZtY8O08Dh48CMDRI0fYtWvnZZ27SpVqzPk6ehbs1q1b2LN7N0WKFmPH9u0ULFSITnffS5169dnw9/rzjsuUKRNhJ+P+b9bMqNegAaNffI5ixYqT3dcLctPNtZj24b//P7Ru7drLaqtcTLNnxS831WnMqyOeZGCPuyhSsgz5Cha5aJ91q1YwZ8ZUgoNDSJ8hA92eGEbWbDl48PEhjH1xMOHh4QC0vqc71xS49pJ1VryhJlmyZo95f2uj5hzYt5uhj96Lw5Ela3Z6D36JajXrsuaPZQx4uAOhufJSuHhpMmTKTKbMWbi1UQsG9LiLbDlynjd+WavBHbw/5oWYiUCxZcqSlfyFirBr2xaKly4PQIFri9H6nod4adCjRDlHcHAw9/boS648+bx8nZLCNbitEbNmfkXLO+/guuuvp3CRIgAUL1GCno8+xsMPdiHKRRESkoYBg4aQP38Bv8/dvuNdjBwxjNYtmhEcHMyIUc+RNm1a5s39htmzviJNSAg5c+XigQe7n3dcyVKlCQoKom3LO7mzRSvKlD1/PL5R4ybc1b4Nz4x6Pqbs6QEDeXbkCNq0bEZkRCRVqlVj8NAR3r8YCTjmnEv0ky7ZeCTxTyqX5fSpMNJnyMiJY0cZ9vj9DHppwnnjrXJplYpkv/ROIqlA+pCkS99+/PtQov/e1y4VmmLTTWWa/1GvDn+SsBPHiYgIp3mHLgqYIiKJQEEzhXh95FMc2HP+KkPt7u910SQff/V/fmxiNEvEk04d2l60mtCo51+kZKnSydQiSSopfQwysal7ViQe6p6V/4qk7J5dvOFwov/e1yqZI8VGYmWaKdjJE8eZ9MYodv6zGTAeeGwQJcpex/yZ01n49WdYUBCVbqhJ+y6P8Mt3c/nm83/vI92+dSPDX59C4eKlku8CRC5w7Ngxhg8ZxMaNf2NmDH/mWYoUKcpTfR5n186d5C9QgJdefo2s2bIld1NF4qRMMwUb/8pwSpWvRJ1GzYkID+fMmdNs27SemZ+8zxPDXyFNmrQcO3KIrNnPv+dt+9aNvP7MU4x+d0Yytfy/QZlm4hvU/2mqVK1GqzbR3benTp/m3fHjyJotO10f7Ma7E8Zz7NhRHn+yb3I39T8lKTPNn5Mg06yZgjNN3aeZQoWdPMH61f/j1oZ3AhCSJg2ZMmdh4ZwZNG17L2nSpAW4KGACLPnhW2r47qcUSSmOHz/O778vo2Xr6NWD0qRNS9asWfnuu4Xc2SJ62b07W7Tgu0ULkrOZIglS92wKtX/PLrJky8HEV59h25YNFClRhru7P8HendtY/9dKPpsyjjRp09Kh66MUK1XuvGN/+3EBjw1+KZlaLhK3nTt2kCNHKEMG9mf9+nWUK1+ep/oN5NDBg+TOnQeAXLlyc8i3UIKkDkEBtiSQMs0UKioqkn82rqdek1Y88+YHpEufntmfTiYyKpKTx48x5JV3ad/lEcY8P4DYXeyb1q0mXbr0FCxSPBlbL3KxyMgI1q1dQ9sOHZn++ZdkyJCBSRPHn7ePmQXeumySqihoplA5cuYhNFceipepAMANNevxz8b1hObMQ7Wbo9d/LV66PGZBHD92JOa4JT/Op8atDZOr2SLxypv3GvLmvYbrr68IwG0NG7Nu7RpCc+Zk//59AOzfv4/Q0EuvSysphyXBlpIpaKZQ2UNzEpo7D7t3/APAmj+Wk//aolS56VbWrvodiF5rNjIiPGZpvaioKJYuXhizPqxISpIrd27yXnMNW7dsBqKfkFKseHHq1K3HzC+/BGDml19St2795GymXK4Ai5oa00zB7u7eh3EvDSEiIoI81+TngccGky59Bia+NpIBPToSEpKGB58YGvMMz/Wr/0fOXHnIk8//dT9FrqZ+AwbT/+k+hIeHU7BgIUaMfI4oF0XfJx7jyxmfkS9/fl56+bXkbqZIvHTLiUg8dMuJ/Fck5S0nv206mui/99WLZ0ux+aa6Z0VERPyk7lkREfEs0CY7K2heZQf372X8y8OiH95sRt3GLWjYvAMnjh/l7ecHcWDfLnLlyU/PfqPIlCXrRcePHtybTetXU7JcRZ4Y9kpM+YRXRrBu9QoyZswMwAOPD6Fw8VIs+3kRM6aOJ3OWrPQe9BKZs2Zj7+4dfDZ5LD37jbpq1y3/bUMG9efHH74nNDQnM76afdHnx48fZ8DTfdmzexcRkZF0vr8LLVq2BuDhbl35c9UfVKpSlbfefifmmP5PPcmGDX9T+9a6PPrYEwCMH/c2JUqWol79BlfnwuSSAixmKmhebcHBwXR8oDdFSpThVNhJhvbuTPnKN7J4wdeUq1iNpu06M3v6ZGZ/OoX2XXpddPztre/m7JnTfPfNFxd91qHLI9xQ6/yZhwtmfcqwV99n+S/f8ev387jtznZ8PmUcre/pftHxIl41b9GKjnfdzcD+T8f5+SfTPqRY8eK8+fY4Dh06RPM7GnPHHc1IkzYt93V5gFOnTvHZp5/E7P/3+nWkS5+ez76YRfcH7uf48eOcPn2KP1etottDPa7WZYlcRGOaV1n20FwUKVEGgAwZM5G/UBEOH9zPiiU/UqvBHQDUanAHK5b8EOfx5SvdQPoMGf2uz8yICD/L2TOnCQ4JYf3q/5EtR06uKXDtlV+MiE/VajckuMi6mRF28iTOOcLCTpItWzaCQ6L/Zq9e4yYyZcp03v4hIWk4c/o0UVFRREREEBwUxNtvvkGPXo8k6XWIBwF2y4mCZjLav3cX/2z+m+Kly3PsyCGyh+YCIFuOnNHdt5fpsynjGNizEx+Of5Xw8OhnGTZt15kXBvZi5dLF1Li1IV99PInmHbsk6nWIXEqHuzqxefMmGtS5hTYt7uSp/gMJCor/56dY8eLkyBFKhzYtqV2nLtu2bSPKRVG2XPmr2GqRi6l7NpmcPhXGm6P60enBx8ngG4c8J/q+y8v7c6vtfT3IliMnERHhvPfmc3z96RRa3PUAFSpXp0Ll6gAsXjiHitVuZs/ObXwz40MyZc5Kp25PkC59+sS6LJE4/bJ4MWXKlGXie1PYvm0b3R+8nypVq5E5c+Z4j3mq/8CY14/0eIjBw4Yz4Z2x/L1+HTVuqknrtu2uRtPlEgLtIdTKNJNBREQEbz7bj5vrNqZazbpA9NNKjhw6AMCRQwfImj3HZZ0ze2guzIw0adJyS4OmbP57zXmfnzl9msULZlO/aVu++HAC3Z4YSqlyFfn1+7mJc1EiCfjqyxnUv60hZsa1hQtToEBBtmze7Nex3y1aQLny5QkLC2P79m289MrrzP92HqdOnUriVos/zi0XnJhbSqageZU553j39ZHkL1SExi3viimvXP0WFi/4GoDFC76mSo3al3XecwHXOceKJT9QsPD5C7bPmTGV2+5sT0hICGfPnAEMCzLOnjl9ZRck4odr8uXjtyW/AnDwwAG2bt1CwUIFL3lceHg4U6dM5r4uD3Dm9JmY1a+ioiIJDw9P0jaLxEUrAl1lf/+1klFPdadgkRIxj9Rp0/lhipeuwJjnB3Bw/x5y5s5Hz/6jyJwlG1s2rGXRnBl07R3dVTXqqW7s3v4Pp0+fInOWrHTtPYjrqtbg+f49OH70CA7HtUVLcV+vp2MmDB0+uJ/33niWJ4a/CsDSnxbyxUcTyJgpC70Hv0jWbJeX1QYKrQjkv6f7PMHyZUs5cuQwoTlz8nDPR4iIiACgXfuO7Nu3l8ED+3Ng/36cc3R54EGaNmsOwH333MXWLZsJCwsjW/bsDBsxipq1bgFg6pT3yZIlK81btsI5R7++T7Jx4wZq3VJbD6q+DEm5ItCKrccS/fe+SpGsKTbfVNAUiYeCpvxXKGgmHk0EEhER71JseEsaGtMUERHxkzJNERHxLNBuOVHQFBERz1L6LSKJTd2zIiIiflKmKSIingVYoqlMU0RExF/KNEVExLsASzUVNEVExLNAmz2r7lkRERE/KdMUERHPdMuJiIhICmdmW83sTzNbaWbLfWWhZjbfzDb4/s3hKzcze8PMNprZKjOr4rVeBU0REfHMkmC7DHWdc5Wcc9V87/sBC51zJYGFvvcAtwMlfVs3YOxlX6iPgqaIiHiXzFHzAs2Byb7Xk4EWscqnuGhLgOxmls9LBQqaIiKSGjngWzP73cy6+cryOud2+17vAfL6XhcAtsc6doev7LJpIpCIiHiWFLec+IJgt1hF451z4y/YrZZzbqeZ5QHmm9m62B8655yZJfqzPhU0RUQkRfEFyAuD5IX77PT9u8/MvgBuBPaaWT7n3G5f9+s+3+47gUKxDi/oK7ts6p4VERHPzBJ/u3SdlsnMspx7DTQEVgMzgc6+3ToDX/lezwTu9c2irQEcjdWNe1mUaYqISGqTF/jCoiNsCPCRc26umS0DpptZV+AfoJ1v/zlAE2AjEAbc77ViBU0REfEsOdY2cM5tBirGUX4QqB9HuQN6JkbdCpoiIuKdVgQSERGRuCjTFBERz/SUExEREYmTMk0REfEs0J5yoqApIiKeBVjMVPesiIiIv5RpioiIdwGWairTFBER8ZMyTRER8SzQbjlR0BQREc8CbfasumdFRET8pExTREQ8C7BEU5mmiIiIv5RpioiIdwGWairTFBER8ZMyTRER8Uy3nIiIiPhJt5yIiIhInJRpioiIZwGWaCrTFBER8ZcyTRER8S7AUk0FTRER8SzQZs+qe1ZERMRPyjRFRMQz3XIiIiIicVKmKSIingVYoqmgKSIi3ql7VkREROKkTFNERK5AYKWayjRFRET8pExTREQ805imiIiIxEmZpoiIeBZgiaaCpoiIeKfuWREREYmTMk0REfFMTzkRERGROCnTFBER7wIr0VTQFBER7wIsZqp7VkRExF/KNEVExDPdciIiIiJxUqYpIiKeBdotJwqaIiLiXWDFTHXPioiI+EuZpoiIeBZgiaYyTREREX8p0xQREc90y4mIiIjESZmmiIh4pltORERE/KTuWREREYmTgqaIiIifFDRFRET8pDFNERHxLNDGNBU0RUTEs0CbPavuWRERET8p0xQREc8CrXtWmaaIiIiflGmKiIhnAZZoKmiKiMgVCLCoqe5ZERERPynTFBERz3TLiYiIiMRJmaaIiHimW05EREQkTso0RUTEswBLNBU0RUTkCgRY1FT3rIiIiJ+UaYqIiGe65URERETipExTREQ8C7RbTsw5l9xtEBERSRXUPSsiIuInBU0RERE/KWiKiIj4SUFTUhQzizSzlWa22sw+NbOMV3Cu982sje/1RDMrl8C+dczsZg91bDWzXP6WX7DPicusa5iZ9bncNopI4lHQlJTmlHOuknOuAnAWeCj2h2bmaca3c+4B59yaBHapA1x20BSRwKKgKSnZT0AJXxb4k5nNBNaYWbCZvWRmy8xslZl1B7Bob5nZejNbAOQ5dyIz+97MqvleNzazFWb2h5ktNLMiRAfnx31Z7i1mltvMPvfVsczMavqOzWlm35rZX2Y2ET8WETOzL83sd98x3S747FVf+UIzy+0rK25mc33H/GRmZRLjyxSRK6f7NCVF8mWUtwNzfUVVgArOuS2+wHPUOXeDmaUDfjazb4HKQGmgHJAXWANMuuC8uYEJQG3fuUKdc4fMbBxwwjk32rffR8CrzrnFZnYtMA8oCwwFFjvnRpjZHUBXPy6ni6+ODMAyM/vcOXcQyAQsd849bmZDfOfuBYwHHnLObTCz6sDbQD0PX6OIJDIFTUlpMpjZSt/rn4B3ie42Xeqc2+Irbwhcf268EsgGlARqA9Occ5HALjNbFMf5awA/njuXc+5QPO1oAJSzf+/czmpmmX11tPId+7WZHfbjmh41s5a+14V8bT0IRAGf+MqnAjN8ddwMfBqr7nR+1CEiV4GCpqQ0p5xzlWIX+ILHydhFwCPOuXkX7NckEdsRBNRwzp2Ooy1+M7M6RAfgm5xzYWb2PZA+nt2dr94jF34HIpIyaExTUqN5wMNmlgbAzEqZWSbgR6C9b8wzH1A3jmOXALXNrKjv2FBf+XEgS6z9vgUeOffGzM4FsR+Bu3xltwM5LtHWbMBhX8AsQ3Sme04QcC5bvovobt9jwBYza+urw8ys4iXqEJGrREFTUqOJRI9XrjCz1cA7RPeafAFs8H02Bfj1wgOdc/uBbkR3hf7Bv92js4CW5yYCAY8C1XwTjdbw7yze4UQH3b+I7qbddom2zgVCzGwt8DzRQfuck8CNvmuoB4zwlXcCuvra9xfQ3I/vRESuAq09KyIi4idlmiIiIn5S0BQREfGTgqaIiIifFDRFRET8pKApIiLiJwVNERERPyloioiI+ElBU0RExE8KmiIiIn5S0BQREfGTgqaIiIifFDRFRET8pKApIiLiJwVNERERPyloSrIysxZm5nwPaE71zKyqmf1pZhvN7A0zszj26et7budKM1ttZpFmFmpmpWOVrzSzY2b2mO+Yimb2q+/cs8ws69W/OhHR8zQlWZnZJ0B+YJFzbmgS1RHsnItMinPHUddSoh9g/RswB3jDOfdNAvs3Ax53ztW7oDwY2AlUd879Y2bLgD7OuR/MrAtQ1Dk3OMkuRETipExTko2ZZQZqAV2BDr6yYDMb7cvAVpnZI77yG8zsFzP7w8yWmlkWM7vPzN6Kdb7ZZlbH9/qEmb1sZn8AN5nZEDNb5jvv+HMZoJmVMLMFvvOuMLPiZjbFzFrEOu+HZtbcj+vJB2R1zi1x0X+NTgFaXOKwjsC0OMrrA5ucc//43pcCfvS9ng+0vlR7RCTxhSR3AySgNQfmOuf+NrODZlYVuBEoAlRyzkX4ui3TAp8A7Z1zy3xdk6cuce5MwG/OuScBzGyNc26E7/UHQFNgFvAh8Lxz7gszS0/0H5LvAo8DX5pZNuBmoLOZlfa1Iy51gALAjlhlO3xlcTKzjEBjoFccH3fg/GD6F9Hf15dAW6DQ/9u792Cry3qP4++PoqRBXss4ZMERGzIvVKBmmZeMk1YWE10srbyUt9LyWFbT1X/SbKbSxuMpG0ubstQoogIvo0SWZmGCgBQFdiNPR0UFRQM//fE8q36u1tqszd6bvZn5vGbWrLWe9bs8vz0yX5/f5fN0PfKIGDIpmjGcjgO+WD9fXb9PBC6zvQHA9gOS9gNW276jtj0M0OFyYdNG4LrG9yMkfQjYEdgVWCLpFmC87Vl1u+vrsvMlXSrpmZQR3XW1P8uBKd12uIn+dPI64FbbD7RtZ3vgWOAjjeaTgIslfRyYDTzR351FxMClaMawkLQrcCSwnyQD2wIG7ujHZjbw1EsMT2t8Xt+6jllHkJcCU23/UdKn2pbt5ErgeMqI78S6nU2NNP8MPKfR9pza1k37aLLlaGCh7ftaDbbvAabXfjwfeM0m+h8RQyDXNGO4zASusv082xNs7wmsBO4CTpU0Cv5ZXJcD4yRNq21j6++rgCmStpG0J+XUbietAvn/9TrqTADbjwB/0OrTVgAACatJREFUal2/lDS6njIF+Brw/rrc0vq+3PaULq81tlcDD0s6uF4zfQfw/U4dqqd9D+vy+79d55T0rPq+DfAx4LIuxxoRQyhFM4bLccCstrbrgHHAH4BF9Saet9l+AngLcEltu4FSCG+lFNqlwMXAwk47sr0G+ApwNzCPp45mTwDOkrQI+Bnw7LrOfcAy4Ip+HtcZwOXACuB3wI8BJJ0m6bTGcjOA622va64s6enAq4Dvtm33OEm/Ae4B/rIZ/YqIQZBHTiI6qCPOxcCLbT803P2JiJEhI82INpKOoowyL0nBjIimjDQjIiJ6lJFmREREj1I0Y1jV3NVWBus1jbtXB7LN8+sp1m6/nybpHQPdTx/b32T+bGPZaZI2SJrZaPuspCWSljXX7892I2JopGjGcHusPrKxL+WB/eYdprQePekP25+wfWMfv19m+8r+d7Vn/wO8G9i7vl7daaGaL3shcH2j7RDgZcD+wL7ANMqjKT1vNyKGTopmjCQLgEmSDpe0QNJsYGnNo72oZscuknRqawVJ59XR112SLqhtX2uN3CRdIGlpXe9zte1Tks6tn6dIuq3+PkvSLrX9FkkXquTc/kbSob0cQD/zZ99Heczm/xptpjxOsz0wGtgOuG8zc20jYpAlEShGhDqiPBqYW5teDOxre6Wk9wAP2Z4maTRwq6TrgcmUPNaDbD9agxCa29yN8jzkZNuWtHOHXV8JvK/OHnI+8ElqqAEwyvaBko6p7UcNVv6spPG1b0dQRpMA2P65pJuB1YCAL9leJmlqL9uNiKGVohnDbQdJv66fF1DC0g8BfmF7ZW2fDuzfuO63E+X05FHAFbYfhZJT27bth4D1wFclzQHmNH+sqTw7255fm74OXNNYpBUw8CtKiDy2Byt/9gvAebafbK4jaRLwAv4Vx3dDHeVuKqA+IraAFM0Ybo/ZfkoRqkWkmZQjymhwXtty/9XXhussKQdSptmaSZlN5Mi+1mnzeH3fSP23Moj5s1OBq+ux7g4cI2kD5X8GbrO9tu7vx8BLgat63G5EDKFc04ytwTzgdEnbQQksr3FzNwAntu647XB6dgywk+0fUab6OqD5ew0ueLBxvfIEYD59GKz8WdsTa+buBOBa4Azb36NECB4maVQ93sOAZf3JtY2IoZORZmwNLqecHl1YC8bfgDfYnitpCvBLSU8APwI+2lhvLPB9lVlOBJzTYdvvBC6rhff31BlNBugMSuD7DpTs2X/mz0K5e7ePda+ljIYXU24Kmmv7B31tNyK2nCQCRURE9CinZyMiInqUohkREdGjFM0Y0dpi9n7Q5VnLgWx/laTd6+e1/VhvoqTba6TdtyVt32W5j9Rlljfv9pX0gRqVd7ekb9Xrrkj6ag1qWCTp2nozU0SMECmaMdI1Y/YeAM4c7g5VFwKftz0JeBA4uX0BSfsAbwVeSIm8u7SmG40HzgKm1uPati4H8AHbB9jen3In7XuH/lAiolcpmrE1+Tk1BUfSXpLmSvpVjdybXNv3qHF4d9XXIbX9e3XZJTVhaLPVO3iPpNzpCiUUoVOk3euBq20/XoMaVgAH1t9GUYIdRgE7An8BsP1wYx87UO6gjYgRIo+cxFZBJdz8lZTEIIAvA6fZ/q2kg4BLKYXsYmC+7Rl1ndbpzZNsPyBpB+AOSdfZvr/LvsZS0ok6eRslK3aN7Q21rVuk3Xjgtsb3PwHja1Te5ygjyceA6203Q9uvAI4BlgL/3aUfETEMUjRjpGvF7I0HllFi5cZQovauaUTQja7vR1Ie/Mf2RkqUHsBZkmbUz3tSknc6Fk3bj9B3VN7um300Zf1dKKPQicAaynEcb/sbdf8n1oJ/CfAW4IqB7C8iBk9Oz8ZI14rZex4loOBMyn+3a9rSeF7QbQOSDqfk1L7U9gHAnZSZRLotP7befNTptQ+l2O6sf01b1i3S7s+UAk3bckcBK23/zfbfKRm3hzRXrAX/auCN3foZEVteimZsFWoo+1mU05WPAislvQnK9T9JrYi8m4DTa/u2NZR9J+DBOhPKZODgTezrkT6i8pbWqblupuTZQkkV6hRpNxt4q6TRkiZSRre/oJyWPVjSjvXa5SuBZfU4JrWOCTgWuGcz/lwRMURSNGOrYftOYBFwHPB24GRJdwFLKKc7Ac4GjpC0mDI7yT6U6cZGSVoGXMBTrzNurvOAcyStAHajXmuVdKzKFGPYXgJ8h3Jtci5wpu2Ntm+n3ES0kBKXtw3lGq2Ar9e+LwbGAecPQl8jYpAkRi8iIqJHGWlGRET0KEUzIiKiRymaERERPUrRjGHXyJdtvSZI2k3SzZLWSvpSH+u+VtKdNf1nqaRTt2TfO/RnV0k3SPptfd+ly3JzJa2RNKfL7xc3s3AlvULSQkkbJM3stE5EDL0UzRgJHmt7rGMVsB74OHBut5UkbUe56/R19fnLFwG3DKQj9bGPgfy7+DBwk+29KY+/fLjLchcBJ3Tpw1Sgvdj+AXgX8M0B9C0iBihFM0Yk2+ts/5RSPLsZS0m1ur+u87jt5dBnBu05dWaRuyW9v7ZNUJmF5ErgbmBPSR+UdIfKbCOf7kfXX0/JooXumbTYvgl4pL29JgFdBHyobflVthcBT/ajLxExyBKjFyNBKyoPSlLOjD6XrmqW7GzgXkk3AXOAb9l+kg4ZtJJeApwIHER5JvJ2SfMps5TsDbzT9m2SptfvB9blZkt6he2fSFpAKdbtzrV9I7CH7dW17a/AHv38W7wXmG17dSMiMCJGiBTNGAlaUXn9ZvsUSftRounOBV5FOY35bxm0kl4OzLK9DkDSd4FDKck999puhR5Mr6876/cxlCL6E9uH9qNvltTzg9CS/gN4E3B4r+tExJaVohlbPduLgcWSrgJWUopmf61rfBbwGdv/275QDyPN+ySNqyPFcZQZUXr1ImASsKKOMneUtKLO2RkRI0CuacZWS9KYGsbeMgW4t37ulEG7AHhDzXx9OjCDzlOAzQNOqrOpIGm8pGcB2D60SybtjXXd2ZQsWuieSduR7R/afrbtCbYnAI+mYEaMLInRi2Enaa3tMR3aVwHPALanTKE13fbSxu9jgW8De1HmpVwHnG37l5L2oNxZ+5/ARuD0Oo/lOcBJdROX2/6CpAnAHNv7NrZ9NnBK/boWON7273o4lt0oebPPpRTwN9drr1Mp83+eUpdbAEymnPq9HzjZ9rxufxdJ04BZlLtq1wN/tf3CTfUnIgZXimZERESPcno2IiKiRymaERERPUrRjIiI6FGKZkRERI9SNCMiInqUohkREdGjFM2IiIgepWhGRET06B/04yIG9mMwQQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKFg_7V13qj"
      },
      "source": [
        "### Treinando o modelo sobre toda a base (100% de df_train, X_treinamento = 100% X, y_treinamento = 100% y)\n",
        "ml_XGB.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyMkW8EB-s1U"
      },
      "source": [
        "ml_XGB_1 = XGBClassifier(silent=False,\n",
        "                         scale_pos_weight=1,\n",
        "                         learning_rate=0.01,  \n",
        "                         colsample_bytree = 1,\n",
        "                         subsample = 0.8,\n",
        "                         objective='binary:logistic', \n",
        "                         n_estimators=1000, \n",
        "                         reg_alpha = 0.3,\n",
        "                         max_depth= 3, \n",
        "                         gamma=1, \n",
        "                         max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1AWis2Xt9v-"
      },
      "source": [
        "# treinando o modelo sobre toda a base X (100% de df_train)\n",
        "ml_XGB1.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STsWDYOunJXw",
        "outputId": "382f9662-bae4-4563-fbf8-1beae73a3be6"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.8\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTnHowjpQTQ"
      },
      "source": [
        "# ml_XGB_1                            # Modelo treinado sobre X e y (100% df_train)\n",
        "\n",
        "# CV com X e y:                                             # Modelo treinado sobre toda base X (100% df_train)\n",
        "# AcurÃ¡ciaMÃ©dia / STD mÃ©dio\n",
        "# ??????????? => tirando outliers\n",
        "# 77,80 / 0,559  => sem tirar outliers\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste) ====> X_teste (% sobre X)\n",
        "# 0: 3194, 1: 116 => tirando outliers de df_train\n",
        "# 0: 3199, 1: 111 => sem tirar outliers de df_train\n",
        "\n",
        "# y_submit calculado com modelo treinado sobre TODA A BASE 'X' (100% df_train):\n",
        "\n",
        "# y_submit = ml_XGB_1.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "# 0: 955, 1: 45 => tirando outliers de df_train ==> PyLadies.csv com pontuaÃ§Ã£o = 0,4610\n",
        "# 0: 956, 1: 44 => sem tirar outliers de df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uUSripHII-8",
        "outputId": "7257fa2c-54cd-41af-f7f5-32174e77b062"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MÃ©dia das AcurÃ¡cias calculadas pelo CV....: 77.8\n",
            "std mÃ©dio das AcurÃ¡cias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzvFPvCuJNbG",
        "outputId": "84b321e3-02cd-4324-cf97-c46e948b13fd"
      },
      "source": [
        "y_pred_1 = ml_XGB_1.predict(X_teste)\n",
        "unique_elements, counts_elements = np.unique(y_pred_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3199  111]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53EqCaJgJsGg"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred_1)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bafMtn3IQzi",
        "outputId": "be823d3f-a9b3-42a9-a060-1d40a478b53c"
      },
      "source": [
        "y_submit_1 = ml_XGB_1.predict(X_submit)\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9LGBShGt9wQ"
      },
      "source": [
        "df_submit_1 = pd.DataFrame(zip(df_test['id'],y_submit_1), columns = ['id','target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "MzStMVKLt9wU",
        "outputId": "cd759c29-e9a3-496d-cd20-763741fdae63"
      },
      "source": [
        "df_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  target\n",
              "0  3411   False\n",
              "1  2177   False\n",
              "2  8400   False\n",
              "3   464   False\n",
              "4  6672   False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUM9gFa1t9wa"
      },
      "source": [
        "df_submit_1.to_csv('PyLadies.csv',index = False, sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3zYdWgrzaOg"
      },
      "source": [
        "### LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llWEkYjWzZZF",
        "outputId": "732a26e2-e18d-416c-eef9-4bbd8a658a30"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmo-OjUYzZl5",
        "outputId": "892f8e50-78ea-4ec8-dcdb-2b9343f6d26f"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.3MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQmrMW_zpAi"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNuQMi0Lz9Gg"
      },
      "source": [
        "X_train = X\n",
        "y_train = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDTQPmLA2ANY"
      },
      "source": [
        "X_test = X_submit\n",
        "y_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-uejECUyItk"
      },
      "source": [
        "# Preprocessing our data\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#tfidf = TfidfVectorizer(max_features=2000)\n",
        "#X_train = tfidf.fit_transform(df_train).toarray()\n",
        "#X_test = tfidf.transform(df_test).toarray()\n",
        "#y_train, y_test = df_train, df_test\n",
        "X_train_sub, X_valid, y_train_sub, y_valid = train_test_split(X_train, y_train, test_size=0.5,random_state=1234)\n",
        "# Setting up our results dataframe\n",
        "df_results = pd.DataFrame(columns=['accuracy', 'run_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOVl-3DayIt6"
      },
      "source": [
        "lgbm = LGBMClassifier(n_estimators=2000,\n",
        "                      feature_fraction=0.06,\n",
        "                      bagging_fraction=0.67,\n",
        "                      bagging_freq=1,\n",
        "                      verbose=0,\n",
        "                      n_jobs=6,\n",
        "                      random_state=1234,\n",
        "                      force_row_wise=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kB4dRc2yIt6"
      },
      "source": [
        "cb = CatBoostClassifier(n_estimators=2000,\n",
        "                        colsample_bylevel=0.06,\n",
        "                        max_leaves=31,\n",
        "                        subsample=0.67,\n",
        "                        verbose=0,\n",
        "                        thread_count=6,\n",
        "                        random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-enhLnbPyIt6"
      },
      "source": [
        "models = [lgbm, cb]\n",
        "model_names = [i.__class__.__name__ for i in models]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIujmOn_yIt6"
      },
      "source": [
        "es_models = ['LGBMClassifier',\n",
        "             'CatBoostClassifier']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptnWWC5ByIt6",
        "outputId": "b9a23ffe-8e1c-44e0-d156-d109f8b2fe66"
      },
      "source": [
        "for m, n in zip(models, model_names):\n",
        "    \n",
        "    start_time = time()\n",
        "    if n in es_models:\n",
        "        m.fit(X_train_sub,\n",
        "              y_train_sub,\n",
        "              eval_set = [(X_valid, y_valid)],\n",
        "              early_stopping_rounds=15,\n",
        "              verbose=0)\n",
        "    else:\n",
        "        m.fit(X_train, y_train)\n",
        "    \n",
        "    run_time = time() - start_time\n",
        "    accuracy = np.mean(m.predict(X_test) == y_test)\n",
        "        \n",
        "    df_results.loc[n] = [accuracy, run_time]\n",
        "    \n",
        "    del m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "hsoMfK1dyIt_",
        "outputId": "ffba49ac-bc08-48ee-958c-ce1693a63fd4"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.917237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoostClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.017664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  run_time\n",
              "LGBMClassifier           0.0  0.917237\n",
              "CatBoostClassifier       0.0  2.017664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAoPBG4WyIuA"
      },
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJO5N2i8yIuA",
        "outputId": "0dc4f76f-d7c2-408a-e2ea-5e2ddb2a7adc"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_lgbm, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [961  39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wBQ5TByIuA"
      },
      "source": [
        "y_pred_cb = cb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjEtLNQKyIuA",
        "outputId": "69fa58f0-da53-4ba6-c995-d18d25182939"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_cb, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [965 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PsK2T-H7DZY"
      },
      "source": [
        "### ZENILSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lGpednyItU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c12_fw4I7TAt"
      },
      "source": [
        "i_Seed = 19961108\n",
        "X = df_train.drop('target', axis=1)\n",
        "y = df_train['target']\n",
        "X_submit = df_test\n",
        "\n",
        "preditoras = X\n",
        "target = y\n",
        "df_testeTratado = X_submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4zYAa4r-6ye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ccb904a-53b0-42e4-f550-6ad119a3c41a"
      },
      "source": [
        "X_total = pd.concat([X,X_submit])\n",
        "f'\"X.shape:\":{X.shape}, \"X_submit.shape:\":{X_submit.shape},\"X_total.shape:\":{X_total.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X.shape:\":(11033, 52), \"X_submit.shape:\":(1000, 52),\"X_total.shape:\":(12033, 52)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oACaNC2F9yD6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ec1139b-6c01-455d-aab6-85126500a561"
      },
      "source": [
        "X_total = pd.get_dummies(X_total, drop_first=False)\n",
        "f'\"X_total.shape:\":{X_total.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_total.shape:\":(12033, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzSPx7RSBsrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b64b46-d2a0-4c45-dadd-abd7eecdbd6d"
      },
      "source": [
        "X_total.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbmI06k3yItY"
      },
      "source": [
        "## Aqui, como passo intermediÃ¡rio, executei o modelo usando o dataframe default (getDataFrameDefault) e analisei a importÃ¢ncia das features:\n",
        "## entÃ£o fui modificando o dataframe excluindo as features menos importantes...\n",
        "## OBS: para utilizar, carregar antes a funÃ§Ã£o treina_testa\n",
        "'''\n",
        "df_default = otdf_Treino.getDataFrameDefault()\n",
        "preditoras = df_default.copy()\n",
        "preditoras.drop(columns=[\"Churn\",\"id\"],inplace=True)\n",
        "target = df_treinoTratado[\"Churn\"]\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0] #considerei todas as features que nÃ£o sÃ£o do tipo \"flutuante\" como categÃ³ricas\n",
        "print(f\"Qtde de features categÃ³ricas: {len(categorical_features_indices)}\")\n",
        "print(f\"Colunas preditoras: {preditoras.columns}\")\n",
        "\n",
        "acc = treina_testa(mostrarFI=True)\n",
        "print(f\"acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5oQMioHz93b"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mew6XsGRyItW",
        "outputId": "080baef5-2a5f-47de-db4d-3e473754d68c"
      },
      "source": [
        "#considerei todas as features que nÃ£o sÃ£o do tipo \"flutuante\" como categÃ³ricas\n",
        "#categorical_features_indices = np.where(preditoras.dtypes != np.float)[0]\n",
        "\n",
        "categorical_features_indices = ['cnae_secao', 'ind01','ind04','ind17','ind18', 'ind21','ind22', 'ind28', \n",
        "                                'ind31', 'ind32', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38','ind39',\n",
        "                                'ind42', 'ind43']\n",
        "len(categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xERF0WAy82gC"
      },
      "source": [
        "def treina_testa(ts=0.30,it=300, lr=0.03, depth=5, gerarArquivo=False, mostrarFI=False):\n",
        "   X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)#, random_state = i_Seed)\n",
        "   catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)\n",
        "   catb_tuned = catb.fit(  X_treinamento, y_treinamento, cat_features=categorical_features_indices)\n",
        "   y_pred = catb_tuned.predict(X_submit)\n",
        "   acc_catb = round(accuracy_score(y_pred, y_teste) * 100, 2)\n",
        "   #print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\n",
        "   if (mostrarFI == True):\n",
        "      l_fi = list(zip(catb_tuned.feature_importances_,X_treinamento.columns))\n",
        "      print(l_fi)\n",
        "\n",
        "   if gerarArquivo == True: \n",
        "      df_id = df_test[[\"id\"]]\n",
        "      df_teste3 = df_testeTratado #.drop(columns=[\"id\"],axis=1)\n",
        "      resposta = catb_tuned.predict(df_teste3)\n",
        "      resposta_df = pd.DataFrame(resposta, columns=['target'])\n",
        "      resultado_submissao = pd.concat([df_id, resposta_df],axis=1)\n",
        "      resultado_submissao.head().T\n",
        "      filename = 'submissao_kaggle_catb_fs_ts0{}_it{}_lr{}_depth{}_sc{}.csv'.format(round(ts*100,0),it, lr, depth,str(int(acc_catb*100)))\n",
        "      resultado_submissao.to_csv(filename, index=False)   \n",
        "      print(filename)\n",
        "   return acc_catb   \n",
        "   #result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "Mj0JVbdH89w1",
        "outputId": "7efe5d7b-f371-4710-d934-347b4a3a8937"
      },
      "source": [
        "acc = treina_testa(mostrarFI=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: bad object for id: 0.0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-d21779ef0020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-cd249ff4f9ff>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      2\u001b[0m    \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_teste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreditoras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, random_state = i_Seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m    \u001b[0mcatb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4300\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   4301\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4302\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   4303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m             \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             \u001b[0msave_snapshot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m         )\n\u001b[1;32m   1799\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1682\u001b[0m         train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[1;32m   1683\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m                                        baseline, column_description)\n\u001b[0m\u001b[1;32m   1685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[0;32m--> 985\u001b[0;31m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[0m\u001b[1;32m    986\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_baseline_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: Invalid type for cat_feature[non-default value idx=0,feature_idx=16]=0.0 : cat_features must be integer or string, real number values and NaN values should be converted to string."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEf7qd9yItW"
      },
      "source": [
        "ts=0.30\n",
        "it=300\n",
        "lr=0.03\n",
        "depth=5\n",
        "gerarArquivo=False\n",
        "mostrarFI=False\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg1ZO8CoyItX"
      },
      "source": [
        "catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oer3P4jcyItX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "a0dcf9c7-2b94-4cc4-a615-a77f3cc3f1dc"
      },
      "source": [
        "catb_tuned = catb.fit(X_treinamento, y_treinamento, cat_features=categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: bad object for id: 1.0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-079d45fdbf25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4300\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   4301\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4302\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   4303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m             \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             \u001b[0msave_snapshot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m         )\n\u001b[1;32m   1799\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1682\u001b[0m         train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[1;32m   1683\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m                                        baseline, column_description)\n\u001b[0m\u001b[1;32m   1685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[0;32m--> 985\u001b[0;31m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[0m\u001b[1;32m    986\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_baseline_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: Invalid type for cat_feature[non-default value idx=0,feature_idx=16]=1.0 : cat_features must be integer or string, real number values and NaN values should be converted to string."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITg22JTLyItY"
      },
      "source": [
        "y_pred = catb_tuned.predict(X_submit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS_5F2K4yItY",
        "outputId": "7c3dccaa-29d4-4911-a30f-26f6661740bd"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [963 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUNshKeM8qKm",
        "outputId": "11aa5ab0-d619-4186-d397-8385c720a5fb"
      },
      "source": [
        "categorical_features_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1y8ZaNQyItZ"
      },
      "source": [
        "def treina_testa(ts=0.30,it=300, lr=0.03, depth=5, gerarArquivo=False, mostrarFI=False):\n",
        "   X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)#, random_state = i_Seed)\n",
        "   catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)\n",
        "   catb_tuned = catb.fit(  X_treinamento, y_treinamento, cat_features=categorical_features_indices)\n",
        "   y_pred = catb_tuned.predict(X_submit)\n",
        "   acc_catb = round(accuracy_score(y_pred, y_teste) * 100, 2)\n",
        "   #print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\n",
        "   if (mostrarFI == True):\n",
        "      l_fi = list(zip(catb_tuned.feature_importances_,X_treinamento.columns))\n",
        "      print(l_fi)\n",
        "\n",
        "   if gerarArquivo == True: \n",
        "      df_id = df_test[[\"id\"]]\n",
        "      df_teste3 = df_testeTratado #.drop(columns=[\"id\"],axis=1)\n",
        "      resposta = catb_tuned.predict(df_teste3)\n",
        "      resposta_df = pd.DataFrame(resposta, columns=['target'])\n",
        "      resultado_submissao = pd.concat([df_id, resposta_df],axis=1)\n",
        "      resultado_submissao.head().T\n",
        "      filename = 'submissao_kaggle_catb_fs_ts0{}_it{}_lr{}_depth{}_sc{}.csv'.format(round(ts*100,0),it, lr, depth,str(int(acc_catb*100)))\n",
        "      resultado_submissao.to_csv(filename, index=False)   \n",
        "      print(filename)\n",
        "   return acc_catb   \n",
        "   #result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qHlX8NFSBDwK",
        "outputId": "f84da2ec-226a-455d-e82c-8d2d5a7fb96a"
      },
      "source": [
        "f'\"X_treinamento=\" : {X_treinamento.shape}, \"y_treinamento=\" : {y_treinamento.shape}, \"X_teste=\":{X_teste.shape},\"y_teste=\":{y_teste.shape},\"X_submit=\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento=\" : (7723, 70), \"y_treinamento=\" : (7723,), \"X_teste=\":(3310, 70),\"y_teste=\":(3310,),\"X_submit=\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "hlK6ScvayItZ",
        "outputId": "2de6fc56-250a-42ac-9318-5121166b6373"
      },
      "source": [
        "#l_ts = [0.22, 0.24, 0.25, 0.26, 0.28, 0.30, 0.32]\n",
        "#l_it =  [300, 400, 500], \n",
        "#l_lr = [0.02, 0.03, 0.04]\n",
        "#l_depth = [2, 3, 4, 5]\n",
        "l_ts, l_it, l_lr, l_depth = [0.26], [400], [0.02], [3]\n",
        "resultado = {}\n",
        "\n",
        "for vez in range(1,11):\n",
        "   resultado[vez] = {\"ts\":[], \"it\":[], \"lr\":[],\"depth\":[],\"score\":[]}\n",
        "   for ts in l_ts:\n",
        "       print(f'execuÃ§Ã£o {vez}/ts {ts}...')\n",
        "       for it in l_it:\n",
        "           for lr in l_lr:\n",
        "               for depth in l_depth:\n",
        "                  res = treina_testa(ts=ts, it=it, lr=lr, depth=depth,gerarArquivo=False, mostrarFI=False) #nÃ£o vai salvar o arquivo e nem mostrar as melhores features\n",
        "                  resultado[vez][\"ts\"].append(ts)\n",
        "                  resultado[vez][\"it\"].append(it)\n",
        "                  resultado[vez][\"lr\"].append(lr)\n",
        "                  resultado[vez][\"depth\"].append(depth)\n",
        "                  resultado[vez][\"score\"].append(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execuÃ§Ã£o 1/ts 0.26...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-c7cedf244408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgerarArquivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#nÃ£o vai salvar o arquivo e nem mostrar as melhores features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"it\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-cd249ff4f9ff>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 2869]"
          ]
        }
      ]
    }
  ]
}