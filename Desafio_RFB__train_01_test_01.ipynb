{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio_RFB__train_e_test_tr.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryssoga/DSWP/blob/master/Desafio_RFB__train_01_test_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOPOEiuuXb-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z0klE9on9bLm",
        "outputId": "ea1f66f3-e88b-4e3c-9934-510e0ec32d9b"
      },
      "source": [
        "url_train_tr = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/train_01.csv'\n",
        "url_test_tr = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/test_01.csv'\n",
        "df_train = pd.read_csv(url_train_tr)\n",
        "df_test = pd.read_csv(url_test_tr)\n",
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\":{df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 67), \"df_test.shape:\":(1000, 66)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvlgJn_fI60x",
        "outputId": "57814264-33b8-4b79-f60c-e1dd956c74a1"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11033 entries, 0 to 11032\n",
            "Data columns (total 67 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   id          11033 non-null  int64  \n",
            " 1   cnae2       11033 non-null  int64  \n",
            " 2   rf2         11033 non-null  object \n",
            " 3   md1         11033 non-null  float64\n",
            " 4   md2         11033 non-null  float64\n",
            " 5   md3         11033 non-null  float64\n",
            " 6   md4         11033 non-null  float64\n",
            " 7   md5         11033 non-null  float64\n",
            " 8   md6         11033 non-null  float64\n",
            " 9   md7         11033 non-null  float64\n",
            " 10  md8         11033 non-null  float64\n",
            " 11  md9         11033 non-null  float64\n",
            " 12  md10        11033 non-null  float64\n",
            " 13  md11        11033 non-null  float64\n",
            " 14  md12        11033 non-null  float64\n",
            " 15  mc1         11033 non-null  float64\n",
            " 16  mc2         11033 non-null  float64\n",
            " 17  mc3         11033 non-null  float64\n",
            " 18  mc4         11033 non-null  float64\n",
            " 19  ind01       11033 non-null  float64\n",
            " 20  ind02       11033 non-null  float64\n",
            " 21  ind03       11033 non-null  float64\n",
            " 22  ind04       11033 non-null  float64\n",
            " 23  ind05       11033 non-null  float64\n",
            " 24  ind06       11033 non-null  float64\n",
            " 25  ind07       11033 non-null  float64\n",
            " 26  ind08       11033 non-null  float64\n",
            " 27  ind09       11033 non-null  float64\n",
            " 28  ind10       11033 non-null  float64\n",
            " 29  ind11       11033 non-null  float64\n",
            " 30  ind12       11033 non-null  float64\n",
            " 31  ind13       11033 non-null  float64\n",
            " 32  ind14       11033 non-null  float64\n",
            " 33  ind15       11033 non-null  float64\n",
            " 34  ind16       11033 non-null  float64\n",
            " 35  ind17       11033 non-null  float64\n",
            " 36  ind18       11033 non-null  float64\n",
            " 37  ind19       11033 non-null  float64\n",
            " 38  ind20       11033 non-null  float64\n",
            " 39  ind21       11033 non-null  float64\n",
            " 40  ind22       11033 non-null  float64\n",
            " 41  ind23       11033 non-null  float64\n",
            " 42  ind24       11033 non-null  float64\n",
            " 43  ind25       11033 non-null  float64\n",
            " 44  ind26       11033 non-null  float64\n",
            " 45  ind27       11033 non-null  float64\n",
            " 46  ind28       11033 non-null  float64\n",
            " 47  ind29       11033 non-null  float64\n",
            " 48  ind30       11033 non-null  float64\n",
            " 49  ind31       11033 non-null  float64\n",
            " 50  ind32       11033 non-null  float64\n",
            " 51  ind33       11033 non-null  float64\n",
            " 52  ind34       11033 non-null  float64\n",
            " 53  ind35       11033 non-null  float64\n",
            " 54  ind36       11033 non-null  float64\n",
            " 55  ind37       11033 non-null  float64\n",
            " 56  ind38       11033 non-null  float64\n",
            " 57  ind39       11033 non-null  float64\n",
            " 58  ind40       11033 non-null  float64\n",
            " 59  ind41       11033 non-null  float64\n",
            " 60  ind42       11033 non-null  float64\n",
            " 61  ind43       11033 non-null  float64\n",
            " 62  target      11033 non-null  bool   \n",
            " 63  cnae_secao  11033 non-null  object \n",
            " 64  l_ind_1_mv  11033 non-null  int64  \n",
            " 65  l_ind_2_mv  11033 non-null  int64  \n",
            " 66  l_mc_1_mv   11033 non-null  int64  \n",
            "dtypes: bool(1), float64(59), int64(5), object(2)\n",
            "memory usage: 5.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arpXjjKmewYf"
      },
      "source": [
        "#df_total = pd.get_dummies(df_total, drop_first=False)\n",
        "#f'\"df_total.shape:\":{df_total.shape}'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cg0y_ylqAweG",
        "outputId": "9c4a9cff-283e-4cd8-dc6b-540c1b5c1408"
      },
      "source": [
        "df_train.set_index('id', inplace=True)\n",
        "df_test.set_index('id',inplace=True)\n",
        "\n",
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 66), \"df_test.shape:\": (1000, 65)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pa1o4_kd5Op",
        "outputId": "558497a2-404f-45de-9e7b-f2e301eb0f02"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cnae2', 'rf2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8',\n",
              "       'md9', 'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4', 'ind01',\n",
              "       'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08', 'ind09',\n",
              "       'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17',\n",
              "       'ind18', 'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24', 'ind25',\n",
              "       'ind26', 'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32', 'ind33',\n",
              "       'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40', 'ind41',\n",
              "       'ind42', 'ind43', 'target', 'cnae_secao', 'l_ind_1_mv', 'l_ind_2_mv',\n",
              "       'l_mc_1_mv'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvxuTajoJ7Mo"
      },
      "source": [
        "# categóricas = ['cnae2', 'rf2', 'cnae_secao','l_ind_1_mv', 'l_ind_2_mv', 'l_mc_1_mv']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp3lzZ3KMQYW"
      },
      "source": [
        "## PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F9_sJ10M9-G",
        "outputId": "0d076ab4-5e7e-49bf-c836-e978a66e61ed"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycaret\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/d0/390ff0f120c05795d45b353cedc81120f9c6558aae285a73e8fab62f322d/pycaret-2.2.1-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 5.6MB/s \n",
            "\u001b[?25hCollecting catboost>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |████████████████████████████████| 66.3MB 63kB/s \n",
            "\u001b[?25hCollecting xgboost>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/cc/fd3d5fc6b6616a03385a0f6492cc77a253940d1026406ecc07597095e381/xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9MB)\n",
            "\u001b[K     |████████████████████████████████| 148.9MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/55/d8ec1ae1f7e1e202a8a4184c6852a3ee993b202b0459672c699d0ac18fc8/kmodes-0.10.2-py2.py3-none-any.whl\n",
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.5)\n",
            "Collecting pandas-profiling>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/79/5d03ed1172e3e67a997a6a795bcdd2ab58f84851969d01a91455383795b6/pandas_profiling-2.9.0-py2.py3-none-any.whl (258kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.6.0)\n",
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.1.4)\n",
            "Collecting imbalanced-learn>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl (167kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.11.0)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.4.6)\n",
            "Collecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/1d/22a6c4e796fff1066bf80bf59b4494d6e3582e22012a61721f4cb730b3c3/pyod-0.8.4.tar.gz (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.18.5)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.14.0)\n",
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/69/c6b3911ccb421adc779390ca2ea54cb888a54e282d50e8d20ce751b5c7ab/mlflow-1.12.1-py3-none-any.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 344kB/s \n",
            "\u001b[?25hCollecting yellowbrick>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/ad/ae6744ddb9c7053916bed95430152b9a41b7d410e16a1cc7cd744a611d90/yellowbrick-1.2-py3-none-any.whl (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 44.2MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret) (7.5.1)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (4.4.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/4d/99073804bd31f15678f24a79e96981dcbaa840bc9926dfd132e9638d51bb/lightgbm-3.1.0-py2.py3-none-manylinux1_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (1.15.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (50.3.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.35.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Collecting confuse>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/55/b4726d81e5d6509fa3441f770f8a9524612627dc1b2a7d6209d1d20083fe/confuse-1.4.0-py2.py3-none-any.whl\n",
            "Collecting phik>=0.9.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/5a/7ef1c04ce62cd72f900c06298dc2385840550d5c653a0dbc19109a5477e6/phik-0.10.0-py3-none-any.whl (599kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 37.2MB/s \n",
            "\u001b[?25hCollecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting tqdm>=4.43.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/bc/857fff709f7ce9eabdc502d6fa71f4b7e964200b1bcd00f0a2f59667d1bf/tqdm-4.53.0-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.4.2)\n",
            "Collecting visions[type_image_path]==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e3/9416e94e767d59a86edcbcb8e1c8f42874d272c3b343676074879e9db0e0/visions-0.5.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.23.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (20.2.0)\n",
            "Collecting tangled-up-in-unicode>=0.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/e2/e588ab9298d4989ce7fdb2b97d18aac878d99dbdc379a4476a09d9271b68/tangled_up_in_unicode-0.0.6-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (3.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: numba!=0.47,>=0.46 in /usr/local/lib/python3.6/dist-packages (from umap-learn->pycaret) (0.48.0)\n",
            "Collecting combo\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/2a/61b6ac584e75d8df16dc27962aa5fe99d76b09da5b6710e83d4862c84001/combo-0.1.1.tar.gz\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Collecting suod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/87/9170cabe1b5e10a7d095c0e28f2e30e7c1886a13f063de85d3cfacc06f4b/suod-0.0.4.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Collecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Collecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.2MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.12.4)\n",
            "Collecting azure-storage-blob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/5d/0bb4ed37da2523c393789b1d8ecbf56b1d35fa344af30fe423da2c06cbe9/azure_storage_blob-12.6.0-py2.py3-none-any.whl (328kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 44.3MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.13)\n",
            "Collecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/88/ae1f78cf582b707c605c77df49b4c8786a4465edc51adb25d2f98ef4c4de/databricks-cli-0.14.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.20)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Collecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.1.2)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret) (7.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (5.0.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->pycaret) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis->pycaret) (1.1.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (8.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.9.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.4.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (2.5)\n",
            "Collecting imagehash; extra == \"type_image_path\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/9dbb772b5ef73a3069c66bb5bf29b9fb4dd57af0d5790c781c3f559bcca6/ImageHash-4.2.0-py2.py3-none-any.whl (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling>=2.8.0->pycaret) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling>=2.8.0->pycaret) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba!=0.47,>=0.46->umap-learn->pycaret) (0.31.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting msrest>=0.6.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/f5/9e315fe8cb985b0ce052b34bcb767883dc739f46fadb62f05a7e6d6eedbe/msrest-0.6.19-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.0MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/4b/ea7faaafac956a168ab9a95a7ebe583f9d308e8332a68af0ed3128ef520c/azure_core-1.9.0-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.4MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a2/6565c5271a79e3c96d7a079053b4d8408a740d4bf365f0f5f244a807bd09/cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.8.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.7)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (2.0.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.6.3)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (1.3.0)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (1.14.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.4.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (19.0.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.9.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob->mlflow->pycaret) (3.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob->mlflow->pycaret) (2.20)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.2.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.4)\n",
            "Building wheels for collected packages: pyLDAvis, pyod, htmlmin, combo, suod, alembic, prometheus-flask-exporter, databricks-cli\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=68fe7eba582c53ce444a41e143f15f77f76d3389d67515c49576bf2c8b028d2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.4-cp36-none-any.whl size=112083 sha256=a962b9a3f3c668ead4d46a367748ea8748862a8035fdd3636ed4a44025bbab86\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/31/0a/c2d4ba2d066145c55f0cb2846e59b18d874cb59c5d9adc81cf\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=8fb7770c9a9c46043beeaf8c15f2eac766dcce8403f54d6ae8665acd34dfd263\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.1-cp36-none-any.whl size=42113 sha256=74551f5e772e7d15fda43927c3da82906c5fb2313720ba0f1141f4da0052c17d\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/ec/e5/a2331372c676c467e70c6646e646edf6997d5c4905b8c0f5e6\n",
            "  Building wheel for suod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suod: filename=suod-0.0.4-cp36-none-any.whl size=2167158 sha256=d609d2a5dd4879d371459d3ebc0d6a2a1279d7f0fcdfd318649565d14dcd2daf\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/55/e5/a4fca65bba231f6d0115059b589148774b41faea25b3f2aa27\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=82ba02b74acdab927ce08981e81c5c741babf8ed132e93101fe1605b1095f5f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp36-none-any.whl size=17157 sha256=3474d552d9710644c63e65a452b3d297986972a19a491126bec8cd203665a841\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.1-cp36-none-any.whl size=100579 sha256=9074746eaaa08011d506a3372f1e689136a928aee30fce6fb65b87cb10f4285c\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/91/ac/5d417ee5ccbb76c8cca096cf4cfb9ed9d49d889d1d1ca0fc39\n",
            "Successfully built pyLDAvis pyod htmlmin combo suod alembic prometheus-flask-exporter databricks-cli\n",
            "Installing collected packages: catboost, xgboost, threadpoolctl, scikit-learn, kmodes, funcy, pyLDAvis, confuse, phik, htmlmin, tqdm, tangled-up-in-unicode, imagehash, visions, pandas-profiling, scikit-plot, imbalanced-learn, combo, suod, pyod, querystring-parser, Mako, python-editor, alembic, smmap, gitdb, gitpython, isodate, msrest, azure-core, cryptography, azure-storage-blob, prometheus-flask-exporter, websocket-client, docker, databricks-cli, gunicorn, mlflow, yellowbrick, lightgbm, pycaret\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "  Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.1 azure-core-1.9.0 azure-storage-blob-12.6.0 catboost-0.24.3 combo-0.1.1 confuse-1.4.0 cryptography-3.2.1 databricks-cli-0.14.1 docker-4.3.1 funcy-1.15 gitdb-4.0.5 gitpython-3.1.11 gunicorn-20.0.4 htmlmin-0.1.12 imagehash-4.2.0 imbalanced-learn-0.7.0 isodate-0.6.0 kmodes-0.10.2 lightgbm-3.1.0 mlflow-1.12.1 msrest-0.6.19 pandas-profiling-2.9.0 phik-0.10.0 prometheus-flask-exporter-0.18.1 pyLDAvis-2.1.2 pycaret-2.2.1 pyod-0.8.4 python-editor-1.0.4 querystring-parser-1.2.4 scikit-learn-0.23.2 scikit-plot-0.3.7 smmap-3.0.4 suod-0.0.4 tangled-up-in-unicode-0.0.6 threadpoolctl-2.1.0 tqdm-4.53.0 visions-0.5.0 websocket-client-0.57.0 xgboost-1.2.1 yellowbrick-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAjtbymSkJ2"
      },
      "source": [
        "# Carregar bibliotecas\n",
        "import pycaret\n",
        "from pycaret.classification import *                                       \n",
        "from pycaret.regression import *                      \n",
        "from pycaret.utils import enable_colab                # Para executar gráficos no Colab\n",
        "from pycaret import classification as pyclass \n",
        "from pycaret import regression as pyreg\n",
        "from sklearn.model_selection import train_test_split  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Khs3DL5jS6s-",
        "outputId": "8c8a4c51-658f-4ea1-e5b7-37255231d005"
      },
      "source": [
        "model = pyclass.setup(data = df_train,      \n",
        "                      target = 'target',     \n",
        "                      train_size = 0.7,\n",
        "                      categorical_features = ['cnae2', 'rf2', 'cnae_secao','l_ind_1_mv', 'l_ind_2_mv', 'l_mc_1_mv'],\n",
        "                      fix_imbalance = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>2978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>False: 0, True: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(11033, 66)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(7723, 166)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(3310, 166)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>2870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Description              Value\n",
              "0                               session_id               2978\n",
              "1                                   Target             target\n",
              "2                              Target Type             Binary\n",
              "3                            Label Encoded  False: 0, True: 1\n",
              "4                            Original Data        (11033, 66)\n",
              "5                           Missing Values              False\n",
              "6                         Numeric Features                 46\n",
              "7                     Categorical Features                 19\n",
              "8                         Ordinal Features              False\n",
              "9                High Cardinality Features              False\n",
              "10                 High Cardinality Method               None\n",
              "11                   Transformed Train Set        (7723, 166)\n",
              "12                    Transformed Test Set        (3310, 166)\n",
              "13                      Shuffle Train-Test               True\n",
              "14                     Stratify Train-Test              False\n",
              "15                          Fold Generator    StratifiedKFold\n",
              "16                             Fold Number                 10\n",
              "17                                CPU Jobs                 -1\n",
              "18                                 Use GPU              False\n",
              "19                          Log Experiment              False\n",
              "20                         Experiment Name   clf-default-name\n",
              "21                                     USI               2870\n",
              "22                         Imputation Type             simple\n",
              "23          Iterative Imputation Iteration               None\n",
              "24                         Numeric Imputer               mean\n",
              "25      Iterative Imputation Numeric Model               None\n",
              "26                     Categorical Imputer           constant\n",
              "27  Iterative Imputation Categorical Model               None\n",
              "28           Unknown Categoricals Handling     least_frequent\n",
              "29                               Normalize              False\n",
              "30                        Normalize Method               None\n",
              "31                          Transformation              False\n",
              "32                   Transformation Method               None\n",
              "33                                     PCA              False\n",
              "34                              PCA Method               None\n",
              "35                          PCA Components               None\n",
              "36                     Ignore Low Variance              False\n",
              "37                     Combine Rare Levels              False\n",
              "38                    Rare Level Threshold               None\n",
              "39                         Numeric Binning              False\n",
              "40                         Remove Outliers              False\n",
              "41                      Outliers Threshold               None\n",
              "42                Remove Multicollinearity              False\n",
              "43             Multicollinearity Threshold               None\n",
              "44                              Clustering              False\n",
              "45                    Clustering Iteration               None\n",
              "46                     Polynomial Features              False\n",
              "47                       Polynomial Degree               None\n",
              "48                    Trignometry Features              False\n",
              "49                    Polynomial Threshold               None\n",
              "50                          Group Features              False\n",
              "51                       Feature Selection              False\n",
              "52            Features Selection Threshold               None\n",
              "53                     Feature Interaction              False\n",
              "54                           Feature Ratio              False\n",
              "55                   Interaction Threshold               None\n",
              "56                           Fix Imbalance               True\n",
              "57                    Fix Imbalance Method              SMOTE"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "occvZWxxTMEg",
        "outputId": "24a415d0-3eae-4c3c-e014-b55b8136f4fa"
      },
      "source": [
        "_# Treinar modelos\n",
        "best = pyclass.compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Classifier</td>\n",
              "      <td>0.7489</td>\n",
              "      <td>0.7236</td>\n",
              "      <td>0.3013</td>\n",
              "      <td>0.4398</td>\n",
              "      <td>0.3573</td>\n",
              "      <td>0.2080</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>31.415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.7450</td>\n",
              "      <td>0.7129</td>\n",
              "      <td>0.3136</td>\n",
              "      <td>0.4322</td>\n",
              "      <td>0.3629</td>\n",
              "      <td>0.2086</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>8.599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.7440</td>\n",
              "      <td>0.7016</td>\n",
              "      <td>0.2666</td>\n",
              "      <td>0.4192</td>\n",
              "      <td>0.3256</td>\n",
              "      <td>0.1771</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>3.310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7222</td>\n",
              "      <td>0.3236</td>\n",
              "      <td>0.4280</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2109</td>\n",
              "      <td>0.2143</td>\n",
              "      <td>1.577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.7335</td>\n",
              "      <td>0.7128</td>\n",
              "      <td>0.3315</td>\n",
              "      <td>0.4070</td>\n",
              "      <td>0.3649</td>\n",
              "      <td>0.1988</td>\n",
              "      <td>0.2006</td>\n",
              "      <td>3.523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.7217</td>\n",
              "      <td>0.7175</td>\n",
              "      <td>0.4108</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4058</td>\n",
              "      <td>0.2243</td>\n",
              "      <td>0.2245</td>\n",
              "      <td>8.127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.6975</td>\n",
              "      <td>0.6993</td>\n",
              "      <td>0.4723</td>\n",
              "      <td>0.3780</td>\n",
              "      <td>0.4195</td>\n",
              "      <td>0.2186</td>\n",
              "      <td>0.2212</td>\n",
              "      <td>2.666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.6641</td>\n",
              "      <td>0.5797</td>\n",
              "      <td>0.4225</td>\n",
              "      <td>0.3265</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.1447</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>1.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.6354</td>\n",
              "      <td>0.7037</td>\n",
              "      <td>0.6735</td>\n",
              "      <td>0.3507</td>\n",
              "      <td>0.4611</td>\n",
              "      <td>0.2251</td>\n",
              "      <td>0.2526</td>\n",
              "      <td>1.097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.6992</td>\n",
              "      <td>0.6735</td>\n",
              "      <td>0.3492</td>\n",
              "      <td>0.4598</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>0.2502</td>\n",
              "      <td>1.941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.6270</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6747</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.4559</td>\n",
              "      <td>0.2152</td>\n",
              "      <td>0.2435</td>\n",
              "      <td>0.721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.6165</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6841</td>\n",
              "      <td>0.3416</td>\n",
              "      <td>0.4523</td>\n",
              "      <td>0.2082</td>\n",
              "      <td>0.2404</td>\n",
              "      <td>1.068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.5613</td>\n",
              "      <td>0.6152</td>\n",
              "      <td>0.6233</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.3970</td>\n",
              "      <td>0.1188</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>5.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.3399</td>\n",
              "      <td>0.5447</td>\n",
              "      <td>0.9178</td>\n",
              "      <td>0.2491</td>\n",
              "      <td>0.3918</td>\n",
              "      <td>0.0432</td>\n",
              "      <td>0.0996</td>\n",
              "      <td>0.717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.2344</td>\n",
              "      <td>0.4996</td>\n",
              "      <td>0.9939</td>\n",
              "      <td>0.2315</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>-0.0025</td>\n",
              "      <td>0.892</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "catboost              CatBoost Classifier    0.7489  0.7236  0.3013  0.4398   \n",
              "xgboost         Extreme Gradient Boosting    0.7450  0.7129  0.3136  0.4322   \n",
              "et                 Extra Trees Classifier    0.7440  0.7016  0.2666  0.4192   \n",
              "lightgbm  Light Gradient Boosting Machine    0.7430  0.7222  0.3236  0.4280   \n",
              "rf               Random Forest Classifier    0.7335  0.7128  0.3315  0.4070   \n",
              "gbc          Gradient Boosting Classifier    0.7217  0.7175  0.4108  0.4016   \n",
              "ada                  Ada Boost Classifier    0.6975  0.6993  0.4723  0.3780   \n",
              "dt               Decision Tree Classifier    0.6641  0.5797  0.4225  0.3265   \n",
              "lda          Linear Discriminant Analysis    0.6354  0.7037  0.6735  0.3507   \n",
              "lr                    Logistic Regression    0.6333  0.6992  0.6735  0.3492   \n",
              "ridge                    Ridge Classifier    0.6270  0.0000  0.6747  0.3444   \n",
              "svm                   SVM - Linear Kernel    0.6165  0.0000  0.6841  0.3416   \n",
              "knn                K Neighbors Classifier    0.5613  0.6152  0.6233  0.2914   \n",
              "nb                            Naive Bayes    0.3399  0.5447  0.9178  0.2491   \n",
              "qda       Quadratic Discriminant Analysis    0.2344  0.4996  0.9939  0.2315   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "catboost  0.3573  0.2080  0.2140    31.415  \n",
              "xgboost   0.3629  0.2086  0.2131     8.599  \n",
              "et        0.3256  0.1771  0.1842     3.310  \n",
              "lightgbm  0.3682  0.2109  0.2143     1.577  \n",
              "rf        0.3649  0.1988  0.2006     3.523  \n",
              "gbc       0.4058  0.2243  0.2245     8.127  \n",
              "ada       0.4195  0.2186  0.2212     2.666  \n",
              "dt        0.3682  0.1447  0.1470     1.106  \n",
              "lda       0.4611  0.2251  0.2526     1.097  \n",
              "lr        0.4598  0.2226  0.2502     1.941  \n",
              "ridge     0.4559  0.2152  0.2435     0.721  \n",
              "svm       0.4523  0.2082  0.2404     1.068  \n",
              "knn       0.3970  0.1188  0.1400     5.611  \n",
              "nb        0.3918  0.0432  0.0996     0.717  \n",
              "qda       0.3755 -0.0004 -0.0025     0.892  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "wzCG8d-in2ny",
        "outputId": "1dce126a-9ef2-49a8-8089-754b3f4b4149"
      },
      "source": [
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/regression/#create-model\n",
        "# Criar Modelo - Siglas dos modelos: https://pycaret.org/classification/#create-model\n",
        "cb = pyclass.create_model('catboost')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7361</td>\n",
              "      <td>0.7473</td>\n",
              "      <td>0.3128</td>\n",
              "      <td>0.4088</td>\n",
              "      <td>0.3544</td>\n",
              "      <td>0.1922</td>\n",
              "      <td>0.1950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7503</td>\n",
              "      <td>0.7067</td>\n",
              "      <td>0.3017</td>\n",
              "      <td>0.4426</td>\n",
              "      <td>0.3588</td>\n",
              "      <td>0.2106</td>\n",
              "      <td>0.2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7607</td>\n",
              "      <td>0.7334</td>\n",
              "      <td>0.3296</td>\n",
              "      <td>0.4758</td>\n",
              "      <td>0.3894</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.2531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7370</td>\n",
              "      <td>0.7029</td>\n",
              "      <td>0.2640</td>\n",
              "      <td>0.3950</td>\n",
              "      <td>0.3165</td>\n",
              "      <td>0.1616</td>\n",
              "      <td>0.1666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7707</td>\n",
              "      <td>0.7358</td>\n",
              "      <td>0.3296</td>\n",
              "      <td>0.5086</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.2662</td>\n",
              "      <td>0.2758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.7180</td>\n",
              "      <td>0.2961</td>\n",
              "      <td>0.4417</td>\n",
              "      <td>0.3545</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.2133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7552</td>\n",
              "      <td>0.7330</td>\n",
              "      <td>0.2793</td>\n",
              "      <td>0.4545</td>\n",
              "      <td>0.3460</td>\n",
              "      <td>0.2058</td>\n",
              "      <td>0.2151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.7058</td>\n",
              "      <td>0.2849</td>\n",
              "      <td>0.4113</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.1813</td>\n",
              "      <td>0.1860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.7366</td>\n",
              "      <td>0.3073</td>\n",
              "      <td>0.4435</td>\n",
              "      <td>0.3630</td>\n",
              "      <td>0.2138</td>\n",
              "      <td>0.2194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.7170</td>\n",
              "      <td>0.3073</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0.3537</td>\n",
              "      <td>0.1953</td>\n",
              "      <td>0.1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7489</td>\n",
              "      <td>0.7236</td>\n",
              "      <td>0.3013</td>\n",
              "      <td>0.4398</td>\n",
              "      <td>0.3573</td>\n",
              "      <td>0.2080</td>\n",
              "      <td>0.2140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0147</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0227</td>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7361  0.7473  0.3128  0.4088  0.3544  0.1922  0.1950\n",
              "1       0.7503  0.7067  0.3017  0.4426  0.3588  0.2106  0.2166\n",
              "2       0.7607  0.7334  0.3296  0.4758  0.3894  0.2467  0.2531\n",
              "3       0.7370  0.7029  0.2640  0.3950  0.3165  0.1616  0.1666\n",
              "4       0.7707  0.7358  0.3296  0.5086  0.4000  0.2662  0.2758\n",
              "5       0.7500  0.7180  0.2961  0.4417  0.3545  0.2069  0.2133\n",
              "6       0.7552  0.7330  0.2793  0.4545  0.3460  0.2058  0.2151\n",
              "7       0.7396  0.7058  0.2849  0.4113  0.3366  0.1813  0.1860\n",
              "8       0.7500  0.7366  0.3073  0.4435  0.3630  0.2138  0.2194\n",
              "9       0.7396  0.7170  0.3073  0.4167  0.3537  0.1953  0.1989\n",
              "Mean    0.7489  0.7236  0.3013  0.4398  0.3573  0.2080  0.2140\n",
              "SD      0.0107  0.0147  0.0199  0.0326  0.0227  0.0286  0.0300"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "3vrIvLxRokBF",
        "outputId": "7d6c1dbb-243c-489c-f6fa-c58abd9cbfc9"
      },
      "source": [
        "# Verificar importância das variáveis\n",
        "\n",
        "pyclass.plot_model(cb, 'feature')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns0RTh9JnXXp"
      },
      "source": [
        "holdout = pyclass.predict_model(cb, data = df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQJrjf7zT6YN",
        "outputId": "ee0429d9-a87f-4a17-848f-0cea5075cbaf"
      },
      "source": [
        "holdout['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    797\n",
              "True     203\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1lVo4rCKVc0",
        "outputId": "5756698a-631b-4b54-885e-5ae5a13d73d2"
      },
      "source": [
        "pycaret_cb_tr = pd.DataFrame(zip(holdout.index, holdout['Label'], holdout['Score']), columns=['id','Label','Score_cb_tr'])\n",
        "pycaret_cb_tr['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    797\n",
              "True     203\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "eXifNlrhThqM",
        "outputId": "e6772365-ae6a-4033-e814-81457ac45a92"
      },
      "source": [
        "pycaret_cb_tr.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score_cb_tr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>False</td>\n",
              "      <td>0.6564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>False</td>\n",
              "      <td>0.5969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>False</td>\n",
              "      <td>0.5278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>True</td>\n",
              "      <td>0.7930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>False</td>\n",
              "      <td>0.5805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  Label  Score_cb_tr\n",
              "0  3411  False       0.6564\n",
              "1  2177  False       0.5969\n",
              "2  8400  False       0.5278\n",
              "3   464   True       0.7930\n",
              "4  6672  False       0.5805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeiYmG0JTNjN"
      },
      "source": [
        "pycaret_cb_tr.to_csv('pycaret_cb_tr.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dY0kbA8Tp2D"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(holdout.index, holdout['Label']), columns=['id','target'])\n",
        "df_submit.to_csv('PyLadies.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHhDjV0cILKv"
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OT4CmbQUrH8"
      },
      "source": [
        "url_modelo_e_target = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/modelo_e_target%20(1).csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TLIh_VsU3Pt"
      },
      "source": [
        "modelo_e_teste = pd.read_csv(url_modelo_e_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "10zIuwKTVNiS",
        "outputId": "cd6c9156-6188-4cb3-8728-5869f45d86b7"
      },
      "source": [
        "modelo_e_teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nome_modelo</th>\n",
              "      <th>target_0</th>\n",
              "      <th>target_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb70</td>\n",
              "      <td>830</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cb70_tuned</td>\n",
              "      <td>820</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cb90</td>\n",
              "      <td>821</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cb90_tuned</td>\n",
              "      <td>811</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cb90_ensemble_boosting</td>\n",
              "      <td>839</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              nome_modelo  target_0  target_1\n",
              "0                    cb70       830       170\n",
              "1              cb70_tuned       820       180\n",
              "2                    cb90       821       179\n",
              "3              cb90_tuned       811       189\n",
              "4  cb90_ensemble_boosting       839       161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "PmbqFwnoWkmQ",
        "outputId": "f050d498-3626-422e-d657-1b28e05b1a06"
      },
      "source": [
        "modelo_e_teste['nome_modelo']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 5 is not in range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-94ed0f7655f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelo_e_teste\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nome_modelo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ui_WZ56zVFW5"
      },
      "source": [
        "modelo_e_teste['nome_modelo'].append('cb_tr')\n",
        "modelo_e_teste['target_0'].append(pycaret_cb_tr['Label'].value_counts()[0])\n",
        "modelo_e_teste['target_1'].append(pycaret_cb_tr['Label'].value_counts()[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-7gQgxOXUMk"
      },
      "source": [
        "### TUNED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "BT3QPZVeIa6-",
        "outputId": "8e53d996-465d-4ccf-ac0a-392ebfc9cfd2"
      },
      "source": [
        "tuned = pyclass.tune_model(modelo, n_iter = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7774</td>\n",
              "      <td>0.7348</td>\n",
              "      <td>0.3156</td>\n",
              "      <td>0.5145</td>\n",
              "      <td>0.3912</td>\n",
              "      <td>0.2645</td>\n",
              "      <td>0.2763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7654</td>\n",
              "      <td>0.7416</td>\n",
              "      <td>0.3067</td>\n",
              "      <td>0.4726</td>\n",
              "      <td>0.3720</td>\n",
              "      <td>0.2357</td>\n",
              "      <td>0.2440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7684</td>\n",
              "      <td>0.7441</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.4832</td>\n",
              "      <td>0.3850</td>\n",
              "      <td>0.2495</td>\n",
              "      <td>0.2576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7583</td>\n",
              "      <td>0.7259</td>\n",
              "      <td>0.2311</td>\n",
              "      <td>0.4370</td>\n",
              "      <td>0.3023</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.1854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7472</td>\n",
              "      <td>0.7364</td>\n",
              "      <td>0.3111</td>\n",
              "      <td>0.4217</td>\n",
              "      <td>0.3581</td>\n",
              "      <td>0.2051</td>\n",
              "      <td>0.2088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7392</td>\n",
              "      <td>0.7145</td>\n",
              "      <td>0.2844</td>\n",
              "      <td>0.3951</td>\n",
              "      <td>0.3307</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.1777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7774</td>\n",
              "      <td>0.7373</td>\n",
              "      <td>0.3156</td>\n",
              "      <td>0.5145</td>\n",
              "      <td>0.3912</td>\n",
              "      <td>0.2645</td>\n",
              "      <td>0.2763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7432</td>\n",
              "      <td>0.7424</td>\n",
              "      <td>0.2478</td>\n",
              "      <td>0.3972</td>\n",
              "      <td>0.3052</td>\n",
              "      <td>0.1579</td>\n",
              "      <td>0.1645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.7218</td>\n",
              "      <td>0.3319</td>\n",
              "      <td>0.4688</td>\n",
              "      <td>0.3886</td>\n",
              "      <td>0.2464</td>\n",
              "      <td>0.2521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7681</td>\n",
              "      <td>0.7434</td>\n",
              "      <td>0.3111</td>\n",
              "      <td>0.4828</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.2440</td>\n",
              "      <td>0.2529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7607</td>\n",
              "      <td>0.7342</td>\n",
              "      <td>0.2975</td>\n",
              "      <td>0.4587</td>\n",
              "      <td>0.3603</td>\n",
              "      <td>0.2214</td>\n",
              "      <td>0.2296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0314</td>\n",
              "      <td>0.0417</td>\n",
              "      <td>0.0333</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7774  0.7348  0.3156  0.5145  0.3912  0.2645  0.2763\n",
              "1       0.7654  0.7416  0.3067  0.4726  0.3720  0.2357  0.2440\n",
              "2       0.7684  0.7441  0.3200  0.4832  0.3850  0.2495  0.2576\n",
              "3       0.7583  0.7259  0.2311  0.4370  0.3023  0.1726  0.1854\n",
              "4       0.7472  0.7364  0.3111  0.4217  0.3581  0.2051  0.2088\n",
              "5       0.7392  0.7145  0.2844  0.3951  0.3307  0.1741  0.1777\n",
              "6       0.7774  0.7373  0.3156  0.5145  0.3912  0.2645  0.2763\n",
              "7       0.7432  0.7424  0.2478  0.3972  0.3052  0.1579  0.1645\n",
              "8       0.7623  0.7218  0.3319  0.4688  0.3886  0.2464  0.2521\n",
              "9       0.7681  0.7434  0.3111  0.4828  0.3784  0.2440  0.2529\n",
              "Mean    0.7607  0.7342  0.2975  0.4587  0.3603  0.2214  0.2296\n",
              "SD      0.0129  0.0097  0.0314  0.0417  0.0333  0.0384  0.0396"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "hza1TggsKkRB",
        "outputId": "3d3eb459-c5a7-42a3-89e7-9becd30b906a"
      },
      "source": [
        "# Verificar importância das variáveis\n",
        "pyclass.plot_model(tuned, 'feature')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8Nm4pjwKL0B",
        "outputId": "16be421d-d35e-4a60-f35c-6f76d8cb9a45"
      },
      "source": [
        "tuned_holdout = pyclass.predict_model(tuned, data = df_test)\n",
        "tuned_holdout['Label'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    811\n",
              "1    189\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQMbKRLjN4wM",
        "outputId": "8bbf5bcb-e7ae-4f92-8c3d-4baa7ddc18a8"
      },
      "source": [
        "#df_pycaret['lda_setup_tuned_AUC'] = holdout['Label']\n",
        "#df_pycaret.to_csv('df_pycaret_Label_modelos.csv', index=False, sep=',')\n",
        "pycaret_cb90_tuned = pd.DataFrame(zip(tuned_holdout.index, tuned_holdout['Label'], tuned_holdout['Score']), columns=['id','Label','Score'])\n",
        "pycaret_cb90_tuned['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    811\n",
              "1    189\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyS9YbXGb7VP",
        "outputId": "5614ad7b-d688-4a5d-942c-635c12a09d1b"
      },
      "source": [
        "pycaret_cb90_tuned['Label'].value_counts()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "9fcziqXScPbv",
        "outputId": "0e9999a8-4849-4702-c80e-1731cb3b64ed"
      },
      "source": [
        "pycaret_cb90.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cb90</th>\n",
              "      <th>Score_cb90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5982</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  cb90  Score_cb90\n",
              "0  3411     0      0.6379\n",
              "1  2177     0      0.7840\n",
              "2  8400     0      0.6227\n",
              "3   464     1      0.6403\n",
              "4  6672     0      0.5982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctoC2-2OaXoG",
        "outputId": "b95b95d2-7a12-4630-fc6f-c1a60a795113"
      },
      "source": [
        "modelos=['cb70', 'cb70_tuned', 'cb90', 'cb90_tuned', 'cb90_ensemble_boosting']\n",
        "modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cb70', 'cb70_tuned', 'cb90', 'cb90_tuned', 'cb90_ensemble_boosting']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBoQYVXyavBD",
        "outputId": "1a248efc-b7b9-4b0b-cb80-55ad13ddbe9b"
      },
      "source": [
        "target_0 = [pycaret_cb['Label'].value_counts()[0], pycaret_cb_tuned['Label'].value_counts()[0], pycaret_cb90['cb90'].value_counts()[0], pycaret_cb90_tuned['Label'].value_counts()[0],pycaret_cb90_ensemble_boosting['Label'].value_counts()[0]]\n",
        "type(target_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAZPJ6flcpoD"
      },
      "source": [
        "target_1 = [pycaret_cb['Label'].value_counts()[1], pycaret_cb_tuned['Label'].value_counts()[1], pycaret_cb90['cb90'].value_counts()[1], pycaret_cb90_tuned['Label'].value_counts()[1],pycaret_cb90_ensemble_boosting['Label'].value_counts()[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbulp98sc9jz"
      },
      "source": [
        "modelo_e_target = pd.DataFrame(zip(modelos, target_0,target_1),columns=['nome_modelo','target_0','target_1'])\n",
        "modelo_e_target.to_csv('modelo_e_target.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "4xwUyGkQfrA9",
        "outputId": "c52d695f-f524-49ee-934e-16aaf8609140"
      },
      "source": [
        "modelo_e_target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nome_modelo</th>\n",
              "      <th>target_0</th>\n",
              "      <th>target_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb70</td>\n",
              "      <td>830</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cb70_tuned</td>\n",
              "      <td>820</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cb90</td>\n",
              "      <td>821</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cb90_tuned</td>\n",
              "      <td>811</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cb90_ensemble_boosting</td>\n",
              "      <td>839</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              nome_modelo  target_0  target_1\n",
              "0                    cb70       830       170\n",
              "1              cb70_tuned       820       180\n",
              "2                    cb90       821       179\n",
              "3              cb90_tuned       811       189\n",
              "4  cb90_ensemble_boosting       839       161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQwbdM_iL7b-"
      },
      "source": [
        "df_submit = pd.DataFrame(zip(tuned_holdout.index, tuned_holdout['Label']), columns=['id','target'])\n",
        "df_submit.to_csv('PyLadies1.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh22ZcfDHBTH",
        "outputId": "08564a76-b408-4391-d5d4-74371d6b746e"
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    811\n",
              "1    189\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrFn0j2jHBKs",
        "outputId": "a70b87a1-0e64-4f3b-8b60-db7abe8daf3a"
      },
      "source": [
        "df_pycaret['catboost_setup_tuned_F1'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    844\n",
              "True     156\n",
              "Name: catboost_setup_tuned_F1, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UXpoFdtP9kv"
      },
      "source": [
        "pycaret_cb_tuned.to_csv('pycaret_cb_tuned.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR0PHYn1XDsQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INOSNxqBIYe8"
      },
      "source": [
        "### ENSEMBLE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8gX5K0mI0Vh"
      },
      "source": [
        "# cb90 => 'boosting'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "caXHz7EJXD1w",
        "outputId": "40b1bc61-189f-4543-dee8-df056a292383"
      },
      "source": [
        "boosting = pyclass.ensemble_model(modelo, method= 'Boosting')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7825</td>\n",
              "      <td>0.7459</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.5398</td>\n",
              "      <td>0.3609</td>\n",
              "      <td>0.2468</td>\n",
              "      <td>0.2681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7704</td>\n",
              "      <td>0.7281</td>\n",
              "      <td>0.2533</td>\n",
              "      <td>0.4872</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.2110</td>\n",
              "      <td>0.2275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7664</td>\n",
              "      <td>0.7468</td>\n",
              "      <td>0.2933</td>\n",
              "      <td>0.4748</td>\n",
              "      <td>0.3626</td>\n",
              "      <td>0.2293</td>\n",
              "      <td>0.2392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7573</td>\n",
              "      <td>0.7299</td>\n",
              "      <td>0.2178</td>\n",
              "      <td>0.4298</td>\n",
              "      <td>0.2891</td>\n",
              "      <td>0.1613</td>\n",
              "      <td>0.1748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>0.2622</td>\n",
              "      <td>0.4470</td>\n",
              "      <td>0.3305</td>\n",
              "      <td>0.1958</td>\n",
              "      <td>0.2061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7523</td>\n",
              "      <td>0.7198</td>\n",
              "      <td>0.2578</td>\n",
              "      <td>0.4234</td>\n",
              "      <td>0.3204</td>\n",
              "      <td>0.1798</td>\n",
              "      <td>0.1880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7293</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.4435</td>\n",
              "      <td>0.3152</td>\n",
              "      <td>0.1838</td>\n",
              "      <td>0.1958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7383</td>\n",
              "      <td>0.2124</td>\n",
              "      <td>0.4404</td>\n",
              "      <td>0.2866</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.1782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7654</td>\n",
              "      <td>0.7325</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.3399</td>\n",
              "      <td>0.2107</td>\n",
              "      <td>0.2236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7782</td>\n",
              "      <td>0.7495</td>\n",
              "      <td>0.2622</td>\n",
              "      <td>0.5221</td>\n",
              "      <td>0.3491</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7650</td>\n",
              "      <td>0.7354</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>0.4680</td>\n",
              "      <td>0.3288</td>\n",
              "      <td>0.2014</td>\n",
              "      <td>0.2154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0091</td>\n",
              "      <td>0.0091</td>\n",
              "      <td>0.0229</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0252</td>\n",
              "      <td>0.0282</td>\n",
              "      <td>0.0304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7825  0.7459  0.2711  0.5398  0.3609  0.2468  0.2681\n",
              "1       0.7704  0.7281  0.2533  0.4872  0.3333  0.2110  0.2275\n",
              "2       0.7664  0.7468  0.2933  0.4748  0.3626  0.2293  0.2392\n",
              "3       0.7573  0.7299  0.2178  0.4298  0.2891  0.1613  0.1748\n",
              "4       0.7593  0.7339  0.2622  0.4470  0.3305  0.1958  0.2061\n",
              "5       0.7523  0.7198  0.2578  0.4234  0.3204  0.1798  0.1880\n",
              "6       0.7593  0.7293  0.2444  0.4435  0.3152  0.1838  0.1958\n",
              "7       0.7593  0.7383  0.2124  0.4404  0.2866  0.1625  0.1782\n",
              "8       0.7654  0.7325  0.2655  0.4724  0.3399  0.2107  0.2236\n",
              "9       0.7782  0.7495  0.2622  0.5221  0.3491  0.2328  0.2528\n",
              "Mean    0.7650  0.7354  0.2540  0.4680  0.3288  0.2014  0.2154\n",
              "SD      0.0091  0.0091  0.0229  0.0371  0.0252  0.0282  0.0304"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiqwtRifJQ20",
        "outputId": "696391e1-d91f-4949-9e91-9d5e7f26946f"
      },
      "source": [
        "holdout = pyclass.predict_model(boosting, data = df_test)\n",
        "holdout['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    839\n",
              "1    161\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "p9wCjH5DKPod",
        "outputId": "b916a5b5-d3e2-4da7-939e-9e56efa7e71f"
      },
      "source": [
        "holdout.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>...</th>\n",
              "      <th>md5_o</th>\n",
              "      <th>md7_o</th>\n",
              "      <th>md8_o</th>\n",
              "      <th>md9_o</th>\n",
              "      <th>md10_o</th>\n",
              "      <th>md12_o</th>\n",
              "      <th>mc1_o</th>\n",
              "      <th>mc3_o</th>\n",
              "      <th>mc4_o</th>\n",
              "      <th>rf2_d</th>\n",
              "      <th>rf2_i</th>\n",
              "      <th>rf2_k</th>\n",
              "      <th>rf2_p</th>\n",
              "      <th>rf2_q</th>\n",
              "      <th>rf2_r</th>\n",
              "      <th>rf2_s</th>\n",
              "      <th>rf2_v</th>\n",
              "      <th>rf2_y</th>\n",
              "      <th>rf2_z</th>\n",
              "      <th>cnae_secao_0</th>\n",
              "      <th>cnae_secao_A</th>\n",
              "      <th>cnae_secao_B</th>\n",
              "      <th>cnae_secao_C</th>\n",
              "      <th>cnae_secao_D</th>\n",
              "      <th>cnae_secao_E</th>\n",
              "      <th>cnae_secao_F</th>\n",
              "      <th>cnae_secao_G</th>\n",
              "      <th>cnae_secao_H</th>\n",
              "      <th>cnae_secao_I</th>\n",
              "      <th>cnae_secao_J</th>\n",
              "      <th>cnae_secao_K</th>\n",
              "      <th>cnae_secao_L</th>\n",
              "      <th>cnae_secao_M</th>\n",
              "      <th>cnae_secao_N</th>\n",
              "      <th>cnae_secao_P</th>\n",
              "      <th>cnae_secao_Q</th>\n",
              "      <th>cnae_secao_R</th>\n",
              "      <th>cnae_secao_S</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3411</th>\n",
              "      <td>71</td>\n",
              "      <td>0.017485</td>\n",
              "      <td>0.004743</td>\n",
              "      <td>0.111771</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005432</td>\n",
              "      <td>0.023085</td>\n",
              "      <td>0.00989</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.13132</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.442161e-09</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297611</td>\n",
              "      <td>0.150525</td>\n",
              "      <td>0.425478</td>\n",
              "      <td>0.243343</td>\n",
              "      <td>0.623462</td>\n",
              "      <td>0.424363</td>\n",
              "      <td>0.04456</td>\n",
              "      <td>4.620425e-07</td>\n",
              "      <td>0.273459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 107 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cnae2       md1       md2  ...  cnae_secao_S  Label   Score\n",
              "id                               ...                             \n",
              "3411     71  0.017485  0.004743  ...             0      0  0.6018\n",
              "\n",
              "[1 rows x 107 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOwi-zh1JZFw",
        "outputId": "4fb2a1f6-2e06-4bac-97e8-07f48ea3147c"
      },
      "source": [
        "pycaret_cb90_ensemble_boosting = pd.DataFrame(zip(holdout.index, holdout['Label'], holdout['Score']), columns=['id','Label','Score'])\n",
        "pycaret_cb90_ensemble_boosting['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    839\n",
              "1    161\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXD8q3bgJTCw"
      },
      "source": [
        "#f'\"0 = \" : {pycaret_cb90_ensemble_boosting['Label'].value_counts()[0]}, \"1 = \" : {pycaret_cb90_ensemble_boosting['Label'].value_counts()[1]}'\n",
        "pycaret_cb90_ensemble_boosting.to_csv('pycaret_cb90_ensemble_boosting.csv', index=False, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQYErGjQUcG",
        "outputId": "facf1626-c790-4323-e536-bdf2129ce0a4"
      },
      "source": [
        "pycaret_cb90_ensemble_boosting['Label'].value_counts()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ckXKKMuK47_"
      },
      "source": [
        "classification.interpret_model(boosting)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK3T5r8xK51O"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKIdA04hTFp4"
      },
      "source": [
        "# tentando rodar: ensemble model com modelo 'tuned' (cb90_tuned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "1Jw7nmoJTGEQ",
        "outputId": "86a3a650-957a-4050-a469-6fb2866287c2"
      },
      "source": [
        "boosting_tuned = pyclass.ensemble_model(tuned, method= 'Boosting')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7784</td>\n",
              "      <td>0.7345</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.5214</td>\n",
              "      <td>0.3567</td>\n",
              "      <td>0.2387</td>\n",
              "      <td>0.2573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7613</td>\n",
              "      <td>0.7422</td>\n",
              "      <td>0.2400</td>\n",
              "      <td>0.4500</td>\n",
              "      <td>0.3130</td>\n",
              "      <td>0.1845</td>\n",
              "      <td>0.1979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7744</td>\n",
              "      <td>0.7468</td>\n",
              "      <td>0.3067</td>\n",
              "      <td>0.5036</td>\n",
              "      <td>0.3812</td>\n",
              "      <td>0.2531</td>\n",
              "      <td>0.2648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7523</td>\n",
              "      <td>0.7289</td>\n",
              "      <td>0.2044</td>\n",
              "      <td>0.4071</td>\n",
              "      <td>0.2722</td>\n",
              "      <td>0.1422</td>\n",
              "      <td>0.1545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7593</td>\n",
              "      <td>0.7373</td>\n",
              "      <td>0.2800</td>\n",
              "      <td>0.4500</td>\n",
              "      <td>0.3452</td>\n",
              "      <td>0.2074</td>\n",
              "      <td>0.2162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7523</td>\n",
              "      <td>0.7191</td>\n",
              "      <td>0.2622</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.3242</td>\n",
              "      <td>0.1827</td>\n",
              "      <td>0.1907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7805</td>\n",
              "      <td>0.7274</td>\n",
              "      <td>0.2889</td>\n",
              "      <td>0.5285</td>\n",
              "      <td>0.3736</td>\n",
              "      <td>0.2541</td>\n",
              "      <td>0.2711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7613</td>\n",
              "      <td>0.7415</td>\n",
              "      <td>0.2168</td>\n",
              "      <td>0.4495</td>\n",
              "      <td>0.2925</td>\n",
              "      <td>0.1695</td>\n",
              "      <td>0.1859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7704</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.3053</td>\n",
              "      <td>0.4929</td>\n",
              "      <td>0.3770</td>\n",
              "      <td>0.2457</td>\n",
              "      <td>0.2563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7792</td>\n",
              "      <td>0.7505</td>\n",
              "      <td>0.2533</td>\n",
              "      <td>0.5278</td>\n",
              "      <td>0.3423</td>\n",
              "      <td>0.2289</td>\n",
              "      <td>0.2512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.7353</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.4755</td>\n",
              "      <td>0.3378</td>\n",
              "      <td>0.2107</td>\n",
              "      <td>0.2246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0330</td>\n",
              "      <td>0.0424</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.0373</td>\n",
              "      <td>0.0386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.7784  0.7345  0.2711  0.5214  0.3567  0.2387  0.2573\n",
              "1       0.7613  0.7422  0.2400  0.4500  0.3130  0.1845  0.1979\n",
              "2       0.7744  0.7468  0.3067  0.5036  0.3812  0.2531  0.2648\n",
              "3       0.7523  0.7289  0.2044  0.4071  0.2722  0.1422  0.1545\n",
              "4       0.7593  0.7373  0.2800  0.4500  0.3452  0.2074  0.2162\n",
              "5       0.7523  0.7191  0.2622  0.4245  0.3242  0.1827  0.1907\n",
              "6       0.7805  0.7274  0.2889  0.5285  0.3736  0.2541  0.2711\n",
              "7       0.7613  0.7415  0.2168  0.4495  0.2925  0.1695  0.1859\n",
              "8       0.7704  0.7246  0.3053  0.4929  0.3770  0.2457  0.2563\n",
              "9       0.7792  0.7505  0.2533  0.5278  0.3423  0.2289  0.2512\n",
              "Mean    0.7669  0.7353  0.2629  0.4755  0.3378  0.2107  0.2246\n",
              "SD      0.0104  0.0097  0.0330  0.0424  0.0351  0.0373  0.0386"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "w4fYeP-Ago8U",
        "outputId": "eace10f1-373d-4af4-f44e-7a76207f174b"
      },
      "source": [
        "holdout = pyclass.predict_model(boosting_tuned, data = df_test)\n",
        "\n",
        "pycaret_cb90_tuned_ensemble_boosting = pd.DataFrame(zip(holdout.index, holdout['Label'], holdout['Score']), columns=['id','Label','Score'])\n",
        "pycaret_cb90_tuned_ensemble_boosting.to_csv('pycaret_cb90_tuned_ensemble_boosting.csv', index=False, sep=',')\n",
        "\n",
        "modelos[6] = ['pycaret_cb90_tuned_ensemble_boosting']\n",
        "target_0[6] = [pycaret_cb90_tuned_ensemble_boosting['Label'].value_counts()[0]]\n",
        "target_1[6] = [pycaret_cb90_tuned_ensemble_boosting['Label'].value_counts()[1]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f579f3da3c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mholdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboosting_tuned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpycaret_cb90_tuned_ensemble_boosting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpycaret_cb90_tuned_ensemble_boosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pycaret_cb90_tuned_ensemble_boosting.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pyclass' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXjbsi1oXno1"
      },
      "source": [
        "### SIMULAR REGRESSÃO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "tmJA8ZH7P-Lc",
        "outputId": "e03c28cb-90a3-489d-cf75-ce0064dd7ee1"
      },
      "source": [
        "_# Treinar modelos\n",
        "from pycaret import regression as pyreg\n",
        "best_reg = pyreg.compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-44662f4b5d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_\u001b[0m\u001b[0;31m# Treinar modelos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpyreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/regression.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, verbose)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, verbose, display)\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1951\u001b[0;31m                 \u001b[0;34mf\"Sort method not supported. See docstring for list of available parameters.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m             )\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sort method not supported. See docstring for list of available parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH09bBhcM80y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOaLYAnxFSDo"
      },
      "source": [
        "### PULAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypwM33UBpCw"
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/cryssoga/DSWP/master/Li%C3%A7%C3%A3o/desafio_test.csv'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oDXHvVPustij",
        "outputId": "ec4b7355-4299-4add-87e7-6c1fa1c4a2f1"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\": {df_test.shape}, \"df_total.shape:\": {df_total.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 63), \"df_test.shape:\": (1000, 62), \"df_total.shape:\": (12033, 80)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj2DFFRNt9uT",
        "outputId": "4fdc2ca6-c935-44f8-e614-a1018a61ed59"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11033 entries, 0 to 11032\n",
            "Data columns (total 63 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      11033 non-null  int64  \n",
            " 1   cnae2   11033 non-null  int64  \n",
            " 2   rf2     11033 non-null  object \n",
            " 3   md1     11033 non-null  float64\n",
            " 4   md2     11033 non-null  float64\n",
            " 5   md3     11033 non-null  float64\n",
            " 6   md4     11033 non-null  float64\n",
            " 7   md5     11033 non-null  float64\n",
            " 8   md6     11033 non-null  float64\n",
            " 9   md7     11033 non-null  float64\n",
            " 10  md8     11033 non-null  float64\n",
            " 11  md9     11033 non-null  float64\n",
            " 12  md10    11033 non-null  float64\n",
            " 13  md11    11033 non-null  float64\n",
            " 14  md12    11033 non-null  float64\n",
            " 15  mc1     10431 non-null  float64\n",
            " 16  mc2     10431 non-null  float64\n",
            " 17  mc3     10431 non-null  float64\n",
            " 18  mc4     11033 non-null  float64\n",
            " 19  ind01   10999 non-null  float64\n",
            " 20  ind02   10999 non-null  float64\n",
            " 21  ind03   10999 non-null  float64\n",
            " 22  ind04   10999 non-null  float64\n",
            " 23  ind05   10999 non-null  float64\n",
            " 24  ind06   10999 non-null  float64\n",
            " 25  ind07   10999 non-null  float64\n",
            " 26  ind08   10999 non-null  float64\n",
            " 27  ind09   10999 non-null  float64\n",
            " 28  ind10   10999 non-null  float64\n",
            " 29  ind11   10999 non-null  float64\n",
            " 30  ind12   10999 non-null  float64\n",
            " 31  ind13   10999 non-null  float64\n",
            " 32  ind14   10999 non-null  float64\n",
            " 33  ind15   10999 non-null  float64\n",
            " 34  ind16   10999 non-null  float64\n",
            " 35  ind17   10999 non-null  float64\n",
            " 36  ind18   10999 non-null  float64\n",
            " 37  ind19   10999 non-null  float64\n",
            " 38  ind20   10999 non-null  float64\n",
            " 39  ind21   10434 non-null  float64\n",
            " 40  ind22   10434 non-null  float64\n",
            " 41  ind23   10434 non-null  float64\n",
            " 42  ind24   10434 non-null  float64\n",
            " 43  ind25   10434 non-null  float64\n",
            " 44  ind26   10434 non-null  float64\n",
            " 45  ind27   10434 non-null  float64\n",
            " 46  ind28   10999 non-null  float64\n",
            " 47  ind29   10999 non-null  float64\n",
            " 48  ind30   10999 non-null  float64\n",
            " 49  ind31   10999 non-null  float64\n",
            " 50  ind32   10999 non-null  float64\n",
            " 51  ind33   10999 non-null  float64\n",
            " 52  ind34   10999 non-null  float64\n",
            " 53  ind35   10999 non-null  float64\n",
            " 54  ind36   10999 non-null  float64\n",
            " 55  ind37   10999 non-null  float64\n",
            " 56  ind38   10434 non-null  float64\n",
            " 57  ind39   10434 non-null  float64\n",
            " 58  ind40   10999 non-null  float64\n",
            " 59  ind41   10999 non-null  float64\n",
            " 60  ind42   10434 non-null  float64\n",
            " 61  ind43   10434 non-null  float64\n",
            " 62  target  11033 non-null  bool   \n",
            "dtypes: bool(1), float64(59), int64(2), object(1)\n",
            "memory usage: 5.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNVOd-U9uzXe",
        "outputId": "83a7dc81-5bef-454b-c91e-60ae74288ff5"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'cnae2', 'rf2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7',\n",
              "       'md8', 'md9', 'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4',\n",
              "       'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24',\n",
              "       'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32',\n",
              "       'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
              "       'ind41', 'ind42', 'ind43', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "mgT2KGJBt9ub",
        "outputId": "eea02333-d133-4a95-f54e-01d19e50b9e3"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10999.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "      <td>10434.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6007.300462</td>\n",
              "      <td>53.105774</td>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106722</td>\n",
              "      <td>0.157427</td>\n",
              "      <td>0.346646</td>\n",
              "      <td>0.364934</td>\n",
              "      <td>0.378858</td>\n",
              "      <td>0.397906</td>\n",
              "      <td>0.305112</td>\n",
              "      <td>0.355596</td>\n",
              "      <td>0.007454</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.141280</td>\n",
              "      <td>0.170552</td>\n",
              "      <td>0.034556</td>\n",
              "      <td>0.019556</td>\n",
              "      <td>0.003789</td>\n",
              "      <td>0.014774</td>\n",
              "      <td>0.004045</td>\n",
              "      <td>0.694791</td>\n",
              "      <td>0.700189</td>\n",
              "      <td>0.544750</td>\n",
              "      <td>0.538172</td>\n",
              "      <td>0.339573</td>\n",
              "      <td>0.333567</td>\n",
              "      <td>0.099865</td>\n",
              "      <td>0.570295</td>\n",
              "      <td>0.550792</td>\n",
              "      <td>0.005119</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.331121</td>\n",
              "      <td>0.367397</td>\n",
              "      <td>0.999182</td>\n",
              "      <td>0.489044</td>\n",
              "      <td>0.910992</td>\n",
              "      <td>0.729703</td>\n",
              "      <td>0.659605</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>0.134177</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.170692</td>\n",
              "      <td>0.090905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3470.840481</td>\n",
              "      <td>19.885298</td>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305922</td>\n",
              "      <td>0.315114</td>\n",
              "      <td>0.470182</td>\n",
              "      <td>0.451587</td>\n",
              "      <td>0.449015</td>\n",
              "      <td>0.473002</td>\n",
              "      <td>0.430549</td>\n",
              "      <td>0.440732</td>\n",
              "      <td>0.069064</td>\n",
              "      <td>0.031814</td>\n",
              "      <td>0.029262</td>\n",
              "      <td>0.312289</td>\n",
              "      <td>0.322844</td>\n",
              "      <td>0.161135</td>\n",
              "      <td>0.129848</td>\n",
              "      <td>0.059799</td>\n",
              "      <td>0.118014</td>\n",
              "      <td>0.062567</td>\n",
              "      <td>0.452090</td>\n",
              "      <td>0.450725</td>\n",
              "      <td>0.455767</td>\n",
              "      <td>0.457155</td>\n",
              "      <td>0.433901</td>\n",
              "      <td>0.434164</td>\n",
              "      <td>0.221941</td>\n",
              "      <td>0.425365</td>\n",
              "      <td>0.412976</td>\n",
              "      <td>0.060052</td>\n",
              "      <td>0.013340</td>\n",
              "      <td>0.018207</td>\n",
              "      <td>0.470638</td>\n",
              "      <td>0.482118</td>\n",
              "      <td>0.028595</td>\n",
              "      <td>0.499903</td>\n",
              "      <td>0.284768</td>\n",
              "      <td>0.444134</td>\n",
              "      <td>0.473863</td>\n",
              "      <td>0.071093</td>\n",
              "      <td>0.340858</td>\n",
              "      <td>0.016514</td>\n",
              "      <td>0.009535</td>\n",
              "      <td>0.376258</td>\n",
              "      <td>0.206764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3018.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6016.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9003.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862600</td>\n",
              "      <td>0.932700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id         cnae2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  10434.000000  10434.000000\n",
              "mean    6007.300462     53.105774  ...      0.170692      0.090905\n",
              "std     3470.840481     19.885298  ...      0.376258      0.206764\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%     3018.000000     42.000000  ...      0.000000      0.000000\n",
              "50%     6016.000000     47.000000  ...      0.000000      0.000000\n",
              "75%     9003.000000     69.000000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "J7U16Y6SQ4Zs",
        "outputId": "1bfaa59c-c8b3-44d4-b470-9f221cdd5cdf"
      },
      "source": [
        "l_train_unique = []\n",
        "for i in df_train.columns:\n",
        "  l_train_unique.append(len(df_train[i].unique()))\n",
        "  #print(\"coluna:\", i, \" - len(df_train[i].unique()):\", len(df_train[i].unique()))\n",
        "\n",
        "df_train_unique = pd.DataFrame(zip(df_train.columns,l_train_unique))\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>11033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cnae2</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rf2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>md1</td>\n",
              "      <td>8829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>md2</td>\n",
              "      <td>10968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>ind40</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>ind41</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>ind42</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>ind43</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>target</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0      1\n",
              "0       id  11033\n",
              "1    cnae2     80\n",
              "2      rf2     10\n",
              "3      md1   8829\n",
              "4      md2  10968\n",
              "..     ...    ...\n",
              "58   ind40      3\n",
              "59   ind41      3\n",
              "60   ind42      3\n",
              "61   ind43      4\n",
              "62  target      2\n",
              "\n",
              "[63 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "B2JdxJRJShUQ",
        "outputId": "f24734e0-41ae-4153-c402-dbfef6a396a7"
      },
      "source": [
        "df_train_unique.rename(columns={0:'coluna',1:'qtde_unique'})\n",
        "df_train_unique = df_train_unique.set_index(0).T\n",
        "df_train_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11033</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>8829</td>\n",
              "      <td>10968</td>\n",
              "      <td>10967</td>\n",
              "      <td>8168</td>\n",
              "      <td>5612</td>\n",
              "      <td>379</td>\n",
              "      <td>10970</td>\n",
              "      <td>10968</td>\n",
              "      <td>8282</td>\n",
              "      <td>5777</td>\n",
              "      <td>340</td>\n",
              "      <td>10967</td>\n",
              "      <td>9925</td>\n",
              "      <td>1484</td>\n",
              "      <td>8157</td>\n",
              "      <td>10451</td>\n",
              "      <td>14</td>\n",
              "      <td>1417</td>\n",
              "      <td>194</td>\n",
              "      <td>14</td>\n",
              "      <td>765</td>\n",
              "      <td>227</td>\n",
              "      <td>2101</td>\n",
              "      <td>2522</td>\n",
              "      <td>331</td>\n",
              "      <td>45</td>\n",
              "      <td>22</td>\n",
              "      <td>1554</td>\n",
              "      <td>2503</td>\n",
              "      <td>830</td>\n",
              "      <td>77</td>\n",
              "      <td>24</td>\n",
              "      <td>45</td>\n",
              "      <td>13</td>\n",
              "      <td>488</td>\n",
              "      <td>429</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>748</td>\n",
              "      <td>159</td>\n",
              "      <td>164</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0     id  cnae2  rf2   md1    md2  ...  ind40  ind41  ind42  ind43  target\n",
              "1  11033     80   10  8829  10968  ...      3      3      3      4       2\n",
              "\n",
              "[1 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yll7hKsUxWUK",
        "outputId": "22b004c4-e69a-4b96-b4ac-b14d83bb0602"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpnm_zhckXD9",
        "outputId": "d0293f89-1ee1-450d-cbf5-f1d686cfaf06"
      },
      "source": [
        "df_nan = df_train.isna().sum()\n",
        "df_nan[df_nan.values>0].sort_values()\n",
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy8hCEistGiR",
        "outputId": "f532aa00-480d-4eb9-e0d1-9096d0858f5b"
      },
      "source": [
        "df_nan[df_nan.values>0].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3', 'ind01', 'ind02', 'ind03', 'ind04', 'ind05',\n",
              "       'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11', 'ind12', 'ind13',\n",
              "       'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20', 'ind21',\n",
              "       'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29',\n",
              "       'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
              "       'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIaxV70rhhE-",
        "outputId": "f7e2eced-6a2d-4ec6-8ce2-3cbd338cfeac"
      },
      "source": [
        "df_nan[df_nan.values==34].index   \n",
        "\n",
        "# 32 colunas/variáveis que possuem 34 NaN cada\n",
        "#'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "#'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "#'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "#'ind40', 'ind41']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08',\n",
              "       'ind09', 'ind10', 'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16',\n",
              "       'ind17', 'ind18', 'ind19', 'ind20', 'ind28', 'ind29', 'ind30', 'ind31',\n",
              "       'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind40', 'ind41'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ERGm38u0oN",
        "outputId": "4f72eb49-82b0-4638-970d-04453d1c448d"
      },
      "source": [
        "len(df_nan[df_nan.values==34].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49eQZdrEpex6",
        "outputId": "eab85b83-a8e8-415d-e8b3-a23864d6ff33"
      },
      "source": [
        "df_nan[df_nan.values==599].index    \n",
        "\n",
        "# 11 colunas/variáveis que possuem 599 NaN cada:\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "# 'ind38', 'ind39',\n",
        "# 'ind42', 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind38',\n",
              "       'ind39', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o593PHygvLJ8",
        "outputId": "0e4aa74f-9572-4e25-9d89-5aa08cc581b1"
      },
      "source": [
        "len(df_nan[df_nan.values==599].index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5mETHrgpe_I",
        "outputId": "4b37dbdb-ef2f-4d98-cfd1-534af3742742"
      },
      "source": [
        "df_nan[df_nan.values==602].index    \n",
        "\n",
        "# 3 colunas/variáveis que possuem 602 NaN cada\n",
        "# ['mc1', 'mc2', 'mc3']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mc1', 'mc2', 'mc3'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHecZd8jfuGi",
        "outputId": "722fece4-a4fa-49e2-a0e8-cb209f74ac2d"
      },
      "source": [
        "linhas_602nan = df_train['mc1'][df_train['mc1'].isna()].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   26,    27,    32,    34,    47,    64,    76,    88,   100,\n",
              "              121,\n",
              "            ...\n",
              "            10848, 10891, 10911, 10921, 10935, 10941, 10979, 10986, 10991,\n",
              "            11007],\n",
              "           dtype='int64', length=602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EUky3VvxJH"
      },
      "source": [
        "linhas_599nan = df_train['ind21'][df_train['ind21'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI4pULl0wble",
        "outputId": "1fbcf7a7-e9f0-4d47-d135-2cd10f15172a"
      },
      "source": [
        "len(set(list(linhas_602nan)) & set(list(linhas_599nan)))  \n",
        "# 602nan e 599nan apresentam 596 linhas em comum\n",
        "# então tem 3 linhas em 599nan que não estão em 602 nan e\n",
        "# 6 linhas em 602nan que não estão em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXs7y99OyUEG",
        "outputId": "a6e963f8-43b9-4e53-d3cd-73c036721f9b"
      },
      "source": [
        "set(list(linhas_602nan)) - set(list(linhas_599nan)) # 6 linhas {1213, 1224, 3233, 5346, 6101, 7297} em 602nan mas não em 599nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpep48R0N19",
        "outputId": "54405911-141a-480b-dd4b-57daf90b6354"
      },
      "source": [
        "set(list(linhas_599nan)) - set(list(linhas_602nan)) # 3 linhas {5788, 10284, 10965} em 599nan mas não em 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5788, 10284, 10965}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VghwKgdRwF2Y"
      },
      "source": [
        "linhas_34nan = df_train['ind01'][df_train['ind01'].isna()].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozi0Gw990yml",
        "outputId": "04e1e738-a686-462c-fcc0-5b3493479a69"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_599nan))  # 34nan e 599nan não apresentam linhas nan em comum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFs38gIx0zIQ",
        "outputId": "ccb5b11a-512a-45df-b75a-fbae70a82fe6"
      },
      "source": [
        "set(list(linhas_34nan)) & set(list(linhas_602nan)) # linhas {1213, 1224, 3233, 5346, 6101, 7297} em comum em 34nan e 602nan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1213, 1224, 3233, 5346, 6101, 7297}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g41VmVkq-_R",
        "outputId": "5dee64cb-b577-4005-9ccb-cc336e42ca62"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdaAew8P89Jn",
        "outputId": "067f5309-3973-4017-8fb3-e069c718d740"
      },
      "source": [
        "df_train[df_train['mc1'].notna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    7917\n",
              "True     2514\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Ly8LJv2_9J_x",
        "outputId": "fa8b025e-00fc-4ad8-aa29-17f3a08c7bb5"
      },
      "source": [
        "df_train[df_train['mc1'].notna()].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.00000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>1.043100e+04</td>\n",
              "      <td>10431.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.00000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.00000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10403.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "      <td>10428.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5998.586521</td>\n",
              "      <td>53.33851</td>\n",
              "      <td>0.011993</td>\n",
              "      <td>0.013208</td>\n",
              "      <td>0.118480</td>\n",
              "      <td>0.014551</td>\n",
              "      <td>0.009693</td>\n",
              "      <td>0.002250</td>\n",
              "      <td>0.016025</td>\n",
              "      <td>0.032519</td>\n",
              "      <td>0.017690</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.134538</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>2.752463e-03</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.079664</td>\n",
              "      <td>0.133032</td>\n",
              "      <td>0.311410</td>\n",
              "      <td>0.330905</td>\n",
              "      <td>0.345606</td>\n",
              "      <td>0.365514</td>\n",
              "      <td>0.321753</td>\n",
              "      <td>0.37509</td>\n",
              "      <td>0.007881</td>\n",
              "      <td>0.001454</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.149238</td>\n",
              "      <td>0.178966</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.020676</td>\n",
              "      <td>0.00391</td>\n",
              "      <td>0.014755</td>\n",
              "      <td>0.004276</td>\n",
              "      <td>0.677786</td>\n",
              "      <td>0.686280</td>\n",
              "      <td>0.544727</td>\n",
              "      <td>0.53817</td>\n",
              "      <td>0.339742</td>\n",
              "      <td>0.333741</td>\n",
              "      <td>0.099889</td>\n",
              "      <td>0.570311</td>\n",
              "      <td>0.550781</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.295011</td>\n",
              "      <td>0.333269</td>\n",
              "      <td>0.999135</td>\n",
              "      <td>0.460636</td>\n",
              "      <td>0.907238</td>\n",
              "      <td>0.714602</td>\n",
              "      <td>0.644526</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>0.134254</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.170790</td>\n",
              "      <td>0.090957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3467.890242</td>\n",
              "      <td>19.98793</td>\n",
              "      <td>0.042113</td>\n",
              "      <td>0.026769</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.040304</td>\n",
              "      <td>0.037191</td>\n",
              "      <td>0.025934</td>\n",
              "      <td>0.029294</td>\n",
              "      <td>0.027583</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>0.038919</td>\n",
              "      <td>0.022033</td>\n",
              "      <td>0.013933</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.012619</td>\n",
              "      <td>1.366601e-02</td>\n",
              "      <td>0.007199</td>\n",
              "      <td>0.267626</td>\n",
              "      <td>0.283498</td>\n",
              "      <td>0.456864</td>\n",
              "      <td>0.438529</td>\n",
              "      <td>0.436875</td>\n",
              "      <td>0.463864</td>\n",
              "      <td>0.435993</td>\n",
              "      <td>0.44446</td>\n",
              "      <td>0.070991</td>\n",
              "      <td>0.032711</td>\n",
              "      <td>0.030087</td>\n",
              "      <td>0.319113</td>\n",
              "      <td>0.328067</td>\n",
              "      <td>0.164659</td>\n",
              "      <td>0.133429</td>\n",
              "      <td>0.06070</td>\n",
              "      <td>0.117785</td>\n",
              "      <td>0.064327</td>\n",
              "      <td>0.458565</td>\n",
              "      <td>0.456224</td>\n",
              "      <td>0.455770</td>\n",
              "      <td>0.45715</td>\n",
              "      <td>0.433962</td>\n",
              "      <td>0.434225</td>\n",
              "      <td>0.221986</td>\n",
              "      <td>0.425340</td>\n",
              "      <td>0.412952</td>\n",
              "      <td>0.059627</td>\n",
              "      <td>0.012832</td>\n",
              "      <td>0.018721</td>\n",
              "      <td>0.456070</td>\n",
              "      <td>0.471405</td>\n",
              "      <td>0.029402</td>\n",
              "      <td>0.498472</td>\n",
              "      <td>0.290112</td>\n",
              "      <td>0.451626</td>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>0.340941</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.206812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3012.500000</td>\n",
              "      <td>42.00000</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002518</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.020741</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130695</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.487921e-07</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6006.000000</td>\n",
              "      <td>47.00000</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.005624</td>\n",
              "      <td>0.112164</td>\n",
              "      <td>0.002776</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007169</td>\n",
              "      <td>0.024386</td>\n",
              "      <td>0.005072</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131472</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.110001e-05</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.58330</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8990.500000</td>\n",
              "      <td>69.00000</td>\n",
              "      <td>0.006366</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.118149</td>\n",
              "      <td>0.011908</td>\n",
              "      <td>0.004606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016753</td>\n",
              "      <td>0.033129</td>\n",
              "      <td>0.017071</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133913</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412918e-03</td>\n",
              "      <td>0.001486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918500</td>\n",
              "      <td>0.95860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12032.000000</td>\n",
              "      <td>96.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id        cnae2  ...         ind42         ind43\n",
              "count  10431.000000  10431.00000  ...  10428.000000  10428.000000\n",
              "mean    5998.586521     53.33851  ...      0.170790      0.090957\n",
              "std     3467.890242     19.98793  ...      0.376344      0.206812\n",
              "min        0.000000      0.00000  ...      0.000000      0.000000\n",
              "25%     3012.500000     42.00000  ...      0.000000      0.000000\n",
              "50%     6006.000000     47.00000  ...      0.000000      0.000000\n",
              "75%     8990.500000     69.00000  ...      0.000000      0.000000\n",
              "max    12032.000000     96.00000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWABZ-yWrQH2",
        "outputId": "e5092897-4659-4d79-969e-cc54bd1c11c4"
      },
      "source": [
        "df_train['target'].value_counts()   22,84% True e 77,16% False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3hg6GGQt9us"
      },
      "source": [
        "# Total de 46 Colunas/variáveis que apresentam NaN:\n",
        "# 'mc1', 'mc2', 'mc3',\n",
        "# 'ind01', 'ind02', 'ind03', 'ind04', 'ind05','ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
        "# 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27', 'ind28', 'ind29', 'ind30',\n",
        "# 'ind31', 'ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40',\n",
        "# 'ind41', 'ind42', 'ind43'\n",
        "sendo:\n",
        "  # 32 colunas/variáveis que possuem 34 NaN cada\n",
        "    #'ind01', 'ind02', 'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08','ind09', 'ind10',\n",
        "    #'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19', 'ind20',\n",
        "    #'ind28', 'ind29', 'ind30', 'ind31','ind32', 'ind33', 'ind34', 'ind35', 'ind36', 'ind37',\n",
        "    #'ind40', 'ind41'\n",
        "  # 11 colunas/variáveis que possuem 599 NaN cada:\n",
        "    # 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
        "    # 'ind38', 'ind39',\n",
        "    # 'ind42', 'ind43'\n",
        "  # 3 colunas/variáveis que possuem 602 NaN cada\n",
        "    # ['mc1', 'mc2', 'mc3']\n",
        "\n",
        "# 602nan e 599nan apresentam 596 linhas em comum, então:\n",
        "# 3 linhas em 599nan que não estão em 602 nan : {5788, 10284, 10965}\n",
        "# 6 linhas em 602nan que não estão em 599nan : {1213, 1224, 3233, 5346, 6101, 7297}\n",
        "\n",
        "# 602nan e 34nan apresentam 6 linhas em comum {1213, 1224, 3233, 5346, 6101, 7297} , que são as mesmas 6 linhas que não estão em 599nan\n",
        "# 599nan e 34nan não apresentam linhas em comum\n",
        "\n",
        "# Total de 633 linhas com NaN ( = 596 + 3 + 6 + 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUqmH2Bt9uz"
      },
      "source": [
        "s_coluna = pd.Series(list(df_train.columns))\n",
        "s_qtde = pd.Series(list(df_train.isna().sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOMEunK3U29"
      },
      "source": [
        "df_nan = pd.DataFrame(zip(s_coluna, s_qtde),columns = ['coluna','qtde_nan'])\n",
        "df_nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3rZDA3t3q2p"
      },
      "source": [
        "df_nan[df_nan['qtde_nan']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLD7DW9a3t-J",
        "outputId": "ac583888-6975-4f49-a1c1-c1d0ba843a64"
      },
      "source": [
        "len(df_nan[df_nan['qtde_nan']!=0])        # 46 variáveis/colunas apresentam NaN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKbN8oAZ6uRf",
        "outputId": "5d4a510a-76b9-4598-d86d-66b71d00973f"
      },
      "source": [
        "df_train[df_train['mc1'].isna()]['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    596\n",
              "True       6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PBBF4-719u",
        "outputId": "bd2e3929-89c5-4f4b-941b-61015797e002"
      },
      "source": [
        "df_train['ind06'].value_counts().head()     # alta correlação com 'ind32'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5441\n",
              "1.0000    4081\n",
              "0.1671      62\n",
              "0.1534      41\n",
              "0.1644      38\n",
              "Name: ind06, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyl-JR3y8B_9",
        "outputId": "5d1e8982-89c7-4a49-d77a-735e570da7da"
      },
      "source": [
        "df_train['ind32'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    6958\n",
              "1.0    4041\n",
              "Name: ind32, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyySiN6PK3iU",
        "outputId": "907b60c3-6ce4-4fd4-a96c-40b8cb143622"
      },
      "source": [
        "df_train['ind04'].value_counts().head()     # alta correlação com 'ind05'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5812\n",
              "1.0000    3151\n",
              "0.0833     532\n",
              "0.9167     258\n",
              "0.1667     224\n",
              "Name: ind04, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-2Obx4LK3xA",
        "outputId": "3d1043e4-60e6-406a-f734-ea7bb12f6d7f"
      },
      "source": [
        "df_train['ind05'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    4776\n",
              "1.0000    3161\n",
              "0.0833     434\n",
              "0.9167     250\n",
              "0.1667     179\n",
              "Name: ind05, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbhjyN3LUU2",
        "outputId": "baf93d03-285c-4688-d097-956ff3360fcf"
      },
      "source": [
        "df_train['ind03'].value_counts().head()     # alta correlação com 'ind31'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    6844\n",
              "1.0000    3642\n",
              "0.0027      21\n",
              "0.0055      12\n",
              "0.1671      11\n",
              "Name: ind03, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ZuDkAPLUgt",
        "outputId": "3e432775-b12a-41e4-fccd-f69eaabbcab3"
      },
      "source": [
        "df_train['ind31'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    7357\n",
              "1.0    3642\n",
              "Name: ind31, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrx-HSHHMyCq",
        "outputId": "55126dd1-48a4-43eb-900e-8f0db36de927"
      },
      "source": [
        "df_train['ind23'].value_counts().head()     # alta correlação com 'ind24'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5018\n",
              "1.0000    2847\n",
              "0.0833     833\n",
              "0.1667     400\n",
              "0.2500     218\n",
              "Name: ind23, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMjX8IY2MyNP",
        "outputId": "c53eb23f-5d06-435d-c8f8-92076a19f984"
      },
      "source": [
        "df_train['ind24'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0000    5136\n",
              "1.0000    2837\n",
              "0.0833     835\n",
              "0.1667     377\n",
              "0.2500     208\n",
              "Name: ind24, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMeKN8lNUIt",
        "outputId": "cc01503e-5456-426f-ae20-6ce841716839"
      },
      "source": [
        "df_train['ind42'].value_counts().head()   #alta correlação com 'ind43'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "1.0    1781\n",
              "Name: ind42, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXgzAeTgNUSM",
        "outputId": "6a572209-11ab-4302-8ccb-662e0738f363"
      },
      "source": [
        "df_train['ind43'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8653\n",
              "0.5    1665\n",
              "1.0     116\n",
              "Name: ind43, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-xtwpcNrad",
        "outputId": "9fe5fdf5-f4f2-4bf5-d673-e3ebdacc1719"
      },
      "source": [
        "df_train['md2'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015110    8\n",
              "0.001655    7\n",
              "0.004966    6\n",
              "0.001986    6\n",
              "0.001324    5\n",
              "Name: md2, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8QRBw3Nrnf",
        "outputId": "43c65572-3f64-46bb-caab-4dd7660ad0b9"
      },
      "source": [
        "df_train['md8'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.039463    8\n",
              "0.017749    7\n",
              "0.025066    6\n",
              "0.019375    5\n",
              "0.019700    5\n",
              "Name: md8, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltYMeW-N1wG",
        "outputId": "f916e55d-abb8-46ae-b123-250e71288746"
      },
      "source": [
        "df_train['md7'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022106    8\n",
              "0.001986    7\n",
              "0.001655    6\n",
              "0.007449    6\n",
              "0.003310    5\n",
              "Name: md7, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo_VW-5a_6hL",
        "outputId": "42af1401-fa12-4e09-ddcc-c5f507918878"
      },
      "source": [
        "df_train['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    8513\n",
              "True     2520\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv5QEKyPl0iG",
        "outputId": "35a463c7-5c68-4265-d5cd-bfb87ee1fcfa"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "cnae2     0\n",
              "rf2       0\n",
              "md1       0\n",
              "md2       0\n",
              "         ..\n",
              "ind40     0\n",
              "ind41     0\n",
              "ind42     0\n",
              "ind43     0\n",
              "target    0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxu66h0D2ZuV"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJStLm07t9u_"
      },
      "source": [
        "Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vSe45kBt9vA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WirO9VPz6tR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrodOQuDsKpc"
      },
      "source": [
        "def calcula_outliers(df):\n",
        "    Q1 = []\n",
        "    Q3 = []\n",
        "    IQR = []\n",
        "    linf = []\n",
        "    lsup = []\n",
        "    qtde_inf = []\n",
        "    qtde_sup = []\n",
        "    col = []\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        Q1.append(q1)\n",
        "        Q3.append(q3)\n",
        "        IQR.append(iqr)\n",
        "        linf.append(lim_inf)\n",
        "        lsup.append(lim_sup)\n",
        "        qtde_inf.append(len(df[df[i]<lim_inf]))\n",
        "        qtde_sup.append(len(df[df[i]>lim_sup]))\n",
        "        col.append(i)\n",
        "    return (Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6MkPFtYu7x7"
      },
      "source": [
        "Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup, col = calcula_outliers(df_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9t9BOagvPXU"
      },
      "source": [
        "df_outliers = pd.DataFrame(np.array([Q1, Q3, IQR, linf, lsup, qtde_inf, qtde_sup]), columns=[lcol] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "0EcHYgrfzoIN",
        "outputId": "7965cfb7-0685-46e1-e75e-97fffd0f714d"
      },
      "source": [
        "df_outliers.rename(index = {0:'q1', 1:'q3', 2:'iqr', 3:'lim_inf', 4:'lim_sup', 5:'abaixo_lim_inf', 6:'acima_lim_sup'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>q1</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>q3</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iqr</th>\n",
              "      <td>0.006032</td>\n",
              "      <td>0.010318</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013209</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.016188</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_inf</th>\n",
              "      <td>-0.009046</td>\n",
              "      <td>-0.013055</td>\n",
              "      <td>0.098338</td>\n",
              "      <td>-0.016855</td>\n",
              "      <td>-0.006283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.016656</td>\n",
              "      <td>0.002453</td>\n",
              "      <td>-0.024269</td>\n",
              "      <td>-0.010959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.001895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lim_sup</th>\n",
              "      <td>0.015083</td>\n",
              "      <td>0.028217</td>\n",
              "      <td>0.129641</td>\n",
              "      <td>0.028091</td>\n",
              "      <td>0.010472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036180</td>\n",
              "      <td>0.050965</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.018265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138690</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abaixo_lim_inf</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acima_lim_sup</th>\n",
              "      <td>1658.000000</td>\n",
              "      <td>1181.000000</td>\n",
              "      <td>1203.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1718.000000</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1110.000000</td>\n",
              "      <td>1098.000000</td>\n",
              "      <td>1129.000000</td>\n",
              "      <td>1578.000000</td>\n",
              "      <td>339.0</td>\n",
              "      <td>1297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1233.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        md1          md2          md3  ... ind41 ind42 ind43\n",
              "q1                 0.000003     0.002422     0.110077  ...   NaN   NaN   NaN\n",
              "q3                 0.006035     0.012740     0.117903  ...   NaN   NaN   NaN\n",
              "iqr                0.006032     0.010318     0.007826  ...   NaN   NaN   NaN\n",
              "lim_inf           -0.009046    -0.013055     0.098338  ...   NaN   NaN   NaN\n",
              "lim_sup            0.015083     0.028217     0.129641  ...   NaN   NaN   NaN\n",
              "abaixo_lim_inf     0.000000     0.000000     4.000000  ...   0.0   0.0   0.0\n",
              "acima_lim_sup   1658.000000  1181.000000  1203.000000  ...   0.0   0.0   0.0\n",
              "\n",
              "[7 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "j004R47yzwCU",
        "outputId": "03cf0785-03b9-4384-d70d-a2aa4ad79054"
      },
      "source": [
        "df_train.drop(['id','cnae2'],axis=1,inplace=False).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "      <td>11033.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.011670</td>\n",
              "      <td>0.012928</td>\n",
              "      <td>0.118267</td>\n",
              "      <td>0.013958</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.134558</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001607</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>0.106393</td>\n",
              "      <td>0.156942</td>\n",
              "      <td>0.345577</td>\n",
              "      <td>0.363809</td>\n",
              "      <td>0.377947</td>\n",
              "      <td>0.396748</td>\n",
              "      <td>0.304172</td>\n",
              "      <td>0.354500</td>\n",
              "      <td>0.007431</td>\n",
              "      <td>0.001371</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.170026</td>\n",
              "      <td>0.034449</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.003777</td>\n",
              "      <td>0.014728</td>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.695732</td>\n",
              "      <td>0.701113</td>\n",
              "      <td>0.555893</td>\n",
              "      <td>0.540622</td>\n",
              "      <td>0.325660</td>\n",
              "      <td>0.319979</td>\n",
              "      <td>0.094443</td>\n",
              "      <td>0.573265</td>\n",
              "      <td>0.549543</td>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.330101</td>\n",
              "      <td>0.366265</td>\n",
              "      <td>0.999184</td>\n",
              "      <td>0.487537</td>\n",
              "      <td>0.911266</td>\n",
              "      <td>0.730536</td>\n",
              "      <td>0.660654</td>\n",
              "      <td>0.004804</td>\n",
              "      <td>0.126892</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.161425</td>\n",
              "      <td>0.085969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.041618</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.021673</td>\n",
              "      <td>0.039367</td>\n",
              "      <td>0.036248</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.027332</td>\n",
              "      <td>0.041373</td>\n",
              "      <td>0.037942</td>\n",
              "      <td>0.021472</td>\n",
              "      <td>0.014230</td>\n",
              "      <td>0.012535</td>\n",
              "      <td>0.012276</td>\n",
              "      <td>0.013302</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.305507</td>\n",
              "      <td>0.314749</td>\n",
              "      <td>0.469850</td>\n",
              "      <td>0.451344</td>\n",
              "      <td>0.448622</td>\n",
              "      <td>0.472732</td>\n",
              "      <td>0.430218</td>\n",
              "      <td>0.440494</td>\n",
              "      <td>0.068959</td>\n",
              "      <td>0.031765</td>\n",
              "      <td>0.029217</td>\n",
              "      <td>0.311906</td>\n",
              "      <td>0.322485</td>\n",
              "      <td>0.160898</td>\n",
              "      <td>0.129652</td>\n",
              "      <td>0.059707</td>\n",
              "      <td>0.117835</td>\n",
              "      <td>0.062471</td>\n",
              "      <td>0.451710</td>\n",
              "      <td>0.450337</td>\n",
              "      <td>0.445655</td>\n",
              "      <td>0.444689</td>\n",
              "      <td>0.425934</td>\n",
              "      <td>0.426005</td>\n",
              "      <td>0.217015</td>\n",
              "      <td>0.413842</td>\n",
              "      <td>0.401642</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.013319</td>\n",
              "      <td>0.018179</td>\n",
              "      <td>0.470270</td>\n",
              "      <td>0.481805</td>\n",
              "      <td>0.028551</td>\n",
              "      <td>0.499867</td>\n",
              "      <td>0.284372</td>\n",
              "      <td>0.443702</td>\n",
              "      <td>0.473509</td>\n",
              "      <td>0.069146</td>\n",
              "      <td>0.332867</td>\n",
              "      <td>0.016488</td>\n",
              "      <td>0.009520</td>\n",
              "      <td>0.367939</td>\n",
              "      <td>0.202125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.110077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130696</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.138900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.112034</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006990</td>\n",
              "      <td>0.024210</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.583300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.527800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.117903</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.032773</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133893</td>\n",
              "      <td>0.001608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860800</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>0.956422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.394075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                md1           md2  ...         ind42         ind43\n",
              "count  11033.000000  11033.000000  ...  11033.000000  11033.000000\n",
              "mean       0.011670      0.012928  ...      0.161425      0.085969\n",
              "std        0.041618      0.026515  ...      0.367939      0.202125\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.000003      0.002422  ...      0.000000      0.000000\n",
              "50%        0.000316      0.005415  ...      0.000000      0.000000\n",
              "75%        0.006035      0.012740  ...      0.000000      0.000000\n",
              "max        1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJF8Q05rbSF",
        "outputId": "d9835c6f-551b-4605-ab2f-9ff7464e9c1b"
      },
      "source": [
        "df_test.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JWJ0Z3ZBT8x",
        "outputId": "82b334d4-5001-4a31-c9f8-914aeab58285"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "cnae2       0\n",
              "rf2         0\n",
              "md1         0\n",
              "md2         0\n",
              "         ... \n",
              "ind40      34\n",
              "ind41      34\n",
              "ind42     599\n",
              "ind43     599\n",
              "target      0\n",
              "Length: 63, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqmeyNYfBUkz"
      },
      "source": [
        "def f_trata_outliers(df):\n",
        "    for i in df.select_dtypes(include=['float64']).columns:\n",
        "        q1 = np.percentile(df[i],25)\n",
        "        q3 = np.percentile(df[i],75)\n",
        "        iqr = q3 - q1\n",
        "        lim_inf = q1 - 1.5 * iqr\n",
        "        lim_sup = q3 + 1.5 * iqr\n",
        "        df[i][df[i] < lim_inf] = lim_inf\n",
        "        df[i][df[i] > lim_sup] = lim_sup\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN--_ZdBdAb"
      },
      "source": [
        "f_trata_outliers(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6RCkr7CSAO"
      },
      "source": [
        "f_trata_outliers(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Y2TJ-Gt9vE"
      },
      "source": [
        "# função que trata NaN:\n",
        "def f_trata_NaN(df):\n",
        "    coluna_nan = df.isna().sum()[df.isna().sum().values>0].index\n",
        "    for col in coluna_nan:\n",
        "      df[col] = df[col].fillna(df[col].median())\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-4KOA0t9vK"
      },
      "source": [
        "# tratando NaN nos dataframes df_train e df_test:\n",
        "df_train = f_trata_NaN(df_train)\n",
        "df_test = f_trata_NaN(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0E1CSAYnch8"
      },
      "source": [
        "# criando dummies em df_train e df_test:\n",
        "df_train = pd.get_dummies(df_train, drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, drop_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Es33OXkQnyLc",
        "outputId": "0ea8aa72-ca3f-42fb-cd96-8ef1648ecbe8"
      },
      "source": [
        "f'\"df_train.shape:\":{df_train.shape}, \"df_test.shape:\":{df_test.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"df_train.shape:\":(11033, 72), \"df_test.shape:\":(1000, 71)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWjvdF3F2Xs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU4mjAscF4Ge"
      },
      "source": [
        "### PULAR PARA PYCARET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3tEEKJF2pO"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfiez91PF20t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj5Nlm_iEggt",
        "outputId": "7e32c74e-508b-4c85-bffb-13cdcc9e345e"
      },
      "source": [
        "df_train['target'].astype('category')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         True\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "11028    False\n",
              "11029    False\n",
              "11030     True\n",
              "11031    False\n",
              "11032     True\n",
              "Name: target, Length: 11033, dtype: category\n",
              "Categories (2, object): [False, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i57fUZmDt9vP",
        "outputId": "9098a979-065d-4cf5-90bd-977906908a55"
      },
      "source": [
        "# definindo X (sem 'id' e 'target'), y (variável target) e X_submit (sem 'id'): \n",
        "X = df_train.drop(columns= ['id','target'], axis= 1)\n",
        "y = df_train['target']\n",
        "X_submit = df_test.drop(columns='id',axis=1)\n",
        "\n",
        "f'\"X.shape:\":{X.shape}, \"y.shape:\":{y.shape}, \"X_submit.shape:\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X.shape:\":(11033, 70), \"y.shape:\":(11033,), \"X_submit.shape:\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsYMnSZXKogI",
        "outputId": "050ed15b-a6a2-48f3-e15e-f3250de8b219"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cnae2', 'md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8', 'md9',\n",
              "       'md10', 'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4', 'ind01', 'ind02',\n",
              "       'ind03', 'ind04', 'ind05', 'ind06', 'ind07', 'ind08', 'ind09', 'ind10',\n",
              "       'ind11', 'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18',\n",
              "       'ind19', 'ind20', 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26',\n",
              "       'ind27', 'ind28', 'ind29', 'ind30', 'ind31', 'ind32', 'ind33', 'ind34',\n",
              "       'ind35', 'ind36', 'ind37', 'ind38', 'ind39', 'ind40', 'ind41', 'ind42',\n",
              "       'ind43', 'rf2_d', 'rf2_i', 'rf2_k', 'rf2_p', 'rf2_q', 'rf2_r', 'rf2_s',\n",
              "       'rf2_v', 'rf2_y', 'rf2_z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8J8ej6t9vT"
      },
      "source": [
        "MODELO: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpaBkXMzmLwh"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsRI-rGxmnQC"
      },
      "source": [
        "# Função para cross validation:\n",
        "def funcao_cross_val_score(modelo, X_treinamento, y_treinamento, CV):\n",
        "    #versão com cross_val_score::\n",
        "    a_scores_CV = cross_val_score(modelo, X_treinamento, y_treinamento, cv = CV)\n",
        "    print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "    print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "    return a_scores_CV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaez67ksHsc0"
      },
      "source": [
        "# Função para Confusion Matrix:\n",
        "from sklearn.metrics import confusion_matrix \n",
        "def mostra_confusion_matrix(cf, \n",
        "                            group_names = None, \n",
        "                            categories = 'auto', \n",
        "                            count = True, \n",
        "                            percent = True, \n",
        "                            cbar = True, \n",
        "                            xyticks = False, \n",
        "                            xyplotlabels = True, \n",
        "                            sum_stats = True, \n",
        "                            figsize = (8, 8), \n",
        "                            cmap = 'Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_8spMrGt9vU"
      },
      "source": [
        "i_CV = 10 # Número de Cross-Validations\n",
        "i_Seed = 22091980 # semente por questões de reproducibilidade\n",
        "f_Test_Size = 0.3 # Proporção do dataframe de validação (outros valores poderiam ser 0.15, 0.20 ou 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eDY6msH0t9vY",
        "outputId": "864288a8-1c95-4378-93a6-c0ace2604968"
      },
      "source": [
        "# Definindo dataframes de TREINAMENTO e TESTE a partir de X e y:\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = f_Test_Size, random_state = i_Seed)\n",
        "f'\"X_treinamento.shape:\" {X_treinamento.shape}, \"y_treinamento_shape:\"{y_treinamento.shape},\"X_teste.shape:\"{X_teste.shape},\"y_teste.shape:\"{y_teste.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento.shape:\" (7723, 70), \"y_treinamento_shape:\"(7723,),\"X_teste.shape:\"(3310, 70),\"y_teste.shape:\"(3310,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjUjFaykt9vf"
      },
      "source": [
        "# Instancia...\n",
        "ml_XGB= XGBClassifier(silent=False,\n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 1,\n",
        "                      subsample = 0.8,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=1000, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth= 3, \n",
        "                      gamma=1, \n",
        "                      max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTFhHr6Ar4mP",
        "outputId": "623d16c7-d681-46a3-f908-a035a9fc2c8b"
      },
      "source": [
        "# Modelo treinado sobre base \"train-split-test\"\n",
        "ml_XGB.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
              "              learning_rate=0.01, max_delta_step=5, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=False, subsample=0.8, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EH4l3lAt9vo",
        "outputId": "1a6bc8da-8467-4c10-ceb3-4d79613a7dc6"
      },
      "source": [
        "# Chamando a função do CROSS VALIDATION - Modelo treinado sobre base \"train-split-test\":\n",
        "\n",
        "a_scores_CV = funcao_cross_val_score(ml_XGB, X_treinamento, y_treinamento, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média das Acurácias calculadas pelo CV....: 77.39\n",
            "std médio das Acurácias calculadas pelo CV: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHujyPesnWF",
        "outputId": "9c5bcd70-b10e-46fd-bcc1-af15cf57f38d"
      },
      "source": [
        "y_pred = ml_XGB.predict(X_teste)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3185  125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TXeOdfIsPkp",
        "outputId": "2587031c-0e86-4569-eec6-6a4beb2d825f"
      },
      "source": [
        "y_submit_0 = ml_XGB.predict(X_submit)     # Modelo treinado sobre base \"train-split-test\"\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_0, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Mr2xE0EMnQ"
      },
      "source": [
        "# CV com X_treinamento e y_treinamento:       # Modelo treinado sobre base \"train-split-test\"\n",
        "# Acurácia Média / STD médio\n",
        "# 77,38 / 0,54  tirando outliers - 70% X\n",
        "# 77,39 / 0,51  sem tirar outliers - 70% X\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste)\n",
        "# 0: 3177, 1: 133 => tirando outliers de df_train - 30% X\n",
        "# 0: 3185, 1: 125 => sem tirar outliers de df_train - 30% X\n",
        "\n",
        "# y_submit = ml_XGB.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "#  ???????????  => tirando outliers de df_train (não rodei)\n",
        "# 0: 952, 1: 48 => sem tirar outliers de df_train (70% X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "iQhLNFkyt9v5",
        "outputId": "5de1fb25-c83b-4706-c3e7-06fcabda7dbd"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "********* CONFUSION MATRIX - PARAMETER TUNNING ***********\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKFg_7V13qj"
      },
      "source": [
        "### Treinando o modelo sobre toda a base (100% de df_train, X_treinamento = 100% X, y_treinamento = 100% y)\n",
        "ml_XGB.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyMkW8EB-s1U"
      },
      "source": [
        "ml_XGB_1 = XGBClassifier(silent=False,\n",
        "                         scale_pos_weight=1,\n",
        "                         learning_rate=0.01,  \n",
        "                         colsample_bytree = 1,\n",
        "                         subsample = 0.8,\n",
        "                         objective='binary:logistic', \n",
        "                         n_estimators=1000, \n",
        "                         reg_alpha = 0.3,\n",
        "                         max_depth= 3, \n",
        "                         gamma=1, \n",
        "                         max_delta_step=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1AWis2Xt9v-"
      },
      "source": [
        "# treinando o modelo sobre toda a base X (100% de df_train)\n",
        "ml_XGB1.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STsWDYOunJXw",
        "outputId": "382f9662-bae4-4563-fbf8-1beae73a3be6"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média das Acurácias calculadas pelo CV....: 77.8\n",
            "std médio das Acurácias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTnHowjpQTQ"
      },
      "source": [
        "# ml_XGB_1                            # Modelo treinado sobre X e y (100% df_train)\n",
        "\n",
        "# CV com X e y:                                             # Modelo treinado sobre toda base X (100% df_train)\n",
        "# AcuráciaMédia / STD médio\n",
        "# ??????????? => tirando outliers\n",
        "# 77,80 / 0,559  => sem tirar outliers\n",
        "\n",
        "# y_pred = ml_XGB.predict(X_teste) ====> X_teste (% sobre X)\n",
        "# 0: 3194, 1: 116 => tirando outliers de df_train\n",
        "# 0: 3199, 1: 111 => sem tirar outliers de df_train\n",
        "\n",
        "# y_submit calculado com modelo treinado sobre TODA A BASE 'X' (100% df_train):\n",
        "\n",
        "# y_submit = ml_XGB_1.predict(X_submit) ====> X_submit (from df_test (test.csv), mas sem 'id')\n",
        "# 0: 955, 1: 45 => tirando outliers de df_train ==> PyLadies.csv com pontuação = 0,4610\n",
        "# 0: 956, 1: 44 => sem tirar outliers de df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uUSripHII-8",
        "outputId": "7257fa2c-54cd-41af-f7f5-32174e77b062"
      },
      "source": [
        "a_scores_CV = funcao_cross_val_score(ml_XGB_1, X, y, i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média das Acurácias calculadas pelo CV....: 77.8\n",
            "std médio das Acurácias calculadas pelo CV: 0.5599999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzvFPvCuJNbG",
        "outputId": "84b321e3-02cd-4324-cf97-c46e948b13fd"
      },
      "source": [
        "y_pred_1 = ml_XGB_1.predict(X_teste)\n",
        "unique_elements, counts_elements = np.unique(y_pred_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[   0    1]\n",
            " [3199  111]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53EqCaJgJsGg"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred_1)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bafMtn3IQzi",
        "outputId": "be823d3f-a9b3-42a9-a060-1d40a478b53c"
      },
      "source": [
        "y_submit_1 = ml_XGB_1.predict(X_submit)\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_submit_1, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [952  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9LGBShGt9wQ"
      },
      "source": [
        "df_submit_1 = pd.DataFrame(zip(df_test['id'],y_submit_1), columns = ['id','target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "MzStMVKLt9wU",
        "outputId": "cd759c29-e9a3-496d-cd20-763741fdae63"
      },
      "source": [
        "df_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  target\n",
              "0  3411   False\n",
              "1  2177   False\n",
              "2  8400   False\n",
              "3   464   False\n",
              "4  6672   False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUM9gFa1t9wa"
      },
      "source": [
        "df_submit_1.to_csv('PyLadies.csv',index = False, sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3zYdWgrzaOg"
      },
      "source": [
        "### LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llWEkYjWzZZF",
        "outputId": "732a26e2-e18d-416c-eef9-4bbd8a658a30"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmo-OjUYzZl5",
        "outputId": "892f8e50-78ea-4ec8-dcdb-2b9343f6d26f"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |████████████████████████████████| 66.3MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQmrMW_zpAi"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNuQMi0Lz9Gg"
      },
      "source": [
        "X_train = X\n",
        "y_train = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDTQPmLA2ANY"
      },
      "source": [
        "X_test = X_submit\n",
        "y_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-uejECUyItk"
      },
      "source": [
        "# Preprocessing our data\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#tfidf = TfidfVectorizer(max_features=2000)\n",
        "#X_train = tfidf.fit_transform(df_train).toarray()\n",
        "#X_test = tfidf.transform(df_test).toarray()\n",
        "#y_train, y_test = df_train, df_test\n",
        "X_train_sub, X_valid, y_train_sub, y_valid = train_test_split(X_train, y_train, test_size=0.5,random_state=1234)\n",
        "# Setting up our results dataframe\n",
        "df_results = pd.DataFrame(columns=['accuracy', 'run_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOVl-3DayIt6"
      },
      "source": [
        "lgbm = LGBMClassifier(n_estimators=2000,\n",
        "                      feature_fraction=0.06,\n",
        "                      bagging_fraction=0.67,\n",
        "                      bagging_freq=1,\n",
        "                      verbose=0,\n",
        "                      n_jobs=6,\n",
        "                      random_state=1234,\n",
        "                      force_row_wise=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kB4dRc2yIt6"
      },
      "source": [
        "cb = CatBoostClassifier(n_estimators=2000,\n",
        "                        colsample_bylevel=0.06,\n",
        "                        max_leaves=31,\n",
        "                        subsample=0.67,\n",
        "                        verbose=0,\n",
        "                        thread_count=6,\n",
        "                        random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-enhLnbPyIt6"
      },
      "source": [
        "models = [lgbm, cb]\n",
        "model_names = [i.__class__.__name__ for i in models]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIujmOn_yIt6"
      },
      "source": [
        "es_models = ['LGBMClassifier',\n",
        "             'CatBoostClassifier']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptnWWC5ByIt6",
        "outputId": "b9a23ffe-8e1c-44e0-d156-d109f8b2fe66"
      },
      "source": [
        "for m, n in zip(models, model_names):\n",
        "    \n",
        "    start_time = time()\n",
        "    if n in es_models:\n",
        "        m.fit(X_train_sub,\n",
        "              y_train_sub,\n",
        "              eval_set = [(X_valid, y_valid)],\n",
        "              early_stopping_rounds=15,\n",
        "              verbose=0)\n",
        "    else:\n",
        "        m.fit(X_train, y_train)\n",
        "    \n",
        "    run_time = time() - start_time\n",
        "    accuracy = np.mean(m.predict(X_test) == y_test)\n",
        "        \n",
        "    df_results.loc[n] = [accuracy, run_time]\n",
        "    \n",
        "    del m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "hsoMfK1dyIt_",
        "outputId": "ffba49ac-bc08-48ee-958c-ce1693a63fd4"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.917237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoostClassifier</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.017664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  run_time\n",
              "LGBMClassifier           0.0  0.917237\n",
              "CatBoostClassifier       0.0  2.017664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAoPBG4WyIuA"
      },
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJO5N2i8yIuA",
        "outputId": "0dc4f76f-d7c2-408a-e2ea-5e2ddb2a7adc"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_lgbm, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[[  0   1]\n",
            " [961  39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wBQ5TByIuA"
      },
      "source": [
        "y_pred_cb = cb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjEtLNQKyIuA",
        "outputId": "69fa58f0-da53-4ba6-c995-d18d25182939"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred_cb, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [965 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PsK2T-H7DZY"
      },
      "source": [
        "### ZENILSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lGpednyItU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c12_fw4I7TAt"
      },
      "source": [
        "i_Seed = 19961108\n",
        "\n",
        "preditoras = X\n",
        "target = y\n",
        "df_testeTratado = X_submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oACaNC2F9yD6"
      },
      "source": [
        "df_testeTratado.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbmI06k3yItY"
      },
      "source": [
        "## Aqui, como passo intermediário, executei o modelo usando o dataframe default (getDataFrameDefault) e analisei a importância das features:\n",
        "## então fui modificando o dataframe excluindo as features menos importantes...\n",
        "## OBS: para utilizar, carregar antes a função treina_testa\n",
        "'''\n",
        "df_default = otdf_Treino.getDataFrameDefault()\n",
        "preditoras = df_default.copy()\n",
        "preditoras.drop(columns=[\"Churn\",\"id\"],inplace=True)\n",
        "target = df_treinoTratado[\"Churn\"]\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0] #considerei todas as features que não são do tipo \"flutuante\" como categóricas\n",
        "print(f\"Qtde de features categóricas: {len(categorical_features_indices)}\")\n",
        "print(f\"Colunas preditoras: {preditoras.columns}\")\n",
        "\n",
        "acc = treina_testa(mostrarFI=True)\n",
        "print(f\"acc: {acc}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5oQMioHz93b"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mew6XsGRyItW",
        "outputId": "ff4bb2f9-06ad-4394-9e8e-5d5cc292b8ba"
      },
      "source": [
        "#considerei todas as features que não são do tipo \"flutuante\" como categóricas\n",
        "categorical_features_indices = np.where(preditoras.dtypes != np.float)[0]\n",
        "len(categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Mj0JVbdH89w1",
        "outputId": "75e5259a-2030-4858-83f1-ea56124d2eaf"
      },
      "source": [
        "acc = treina_testa(mostrarFI=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-d21779ef0020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-648fed880d09>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'bool' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEf7qd9yItW"
      },
      "source": [
        "ts=0.30\n",
        "it=300\n",
        "lr=0.03\n",
        "depth=5\n",
        "gerarArquivo=False\n",
        "mostrarFI=False\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg1ZO8CoyItX"
      },
      "source": [
        "catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oer3P4jcyItX"
      },
      "source": [
        "catb_tuned = catb.fit(X_treinamento, y_treinamento) # cat_features=categorical_features_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITg22JTLyItY"
      },
      "source": [
        "y_pred = catb_tuned.predict(X_submit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS_5F2K4yItY",
        "outputId": "7c3dccaa-29d4-4911-a30f-26f6661740bd"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[['False' 'True']\n",
            " [963 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUNshKeM8qKm",
        "outputId": "11aa5ab0-d619-4186-d397-8385c720a5fb"
      },
      "source": [
        "categorical_features_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1y8ZaNQyItZ"
      },
      "source": [
        "def treina_testa(ts=0.30,it=300, lr=0.03, depth=5, gerarArquivo=False, mostrarFI=False):\n",
        "   X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts)#, random_state = i_Seed)\n",
        "   catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)\n",
        "   catb_tuned = catb.fit(  X_treinamento, y_treinamento, cat_features=categorical_features_indices)\n",
        "   y_pred = catb_tuned.predict(X_submit)\n",
        "   acc_catb = round(accuracy_score(y_pred, y_teste) * 100, 2)\n",
        "   #print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\n",
        "   if (mostrarFI == True):\n",
        "      l_fi = list(zip(catb_tuned.feature_importances_,X_treinamento.columns))\n",
        "      print(l_fi)\n",
        "\n",
        "   if gerarArquivo == True: \n",
        "      df_id = df_test[[\"id\"]]\n",
        "      df_teste3 = df_testeTratado #.drop(columns=[\"id\"],axis=1)\n",
        "      resposta = catb_tuned.predict(df_teste3)\n",
        "      resposta_df = pd.DataFrame(resposta, columns=['target'])\n",
        "      resultado_submissao = pd.concat([df_id, resposta_df],axis=1)\n",
        "      resultado_submissao.head().T\n",
        "      filename = 'submissao_kaggle_catb_fs_ts0{}_it{}_lr{}_depth{}_sc{}.csv'.format(round(ts*100,0),it, lr, depth,str(int(acc_catb*100)))\n",
        "      resultado_submissao.to_csv(filename, index=False)   \n",
        "      print(filename)\n",
        "   return acc_catb   \n",
        "   #result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qHlX8NFSBDwK",
        "outputId": "f84da2ec-226a-455d-e82c-8d2d5a7fb96a"
      },
      "source": [
        "f'\"X_treinamento=\" : {X_treinamento.shape}, \"y_treinamento=\" : {y_treinamento.shape}, \"X_teste=\":{X_teste.shape},\"y_teste=\":{y_teste.shape},\"X_submit=\":{X_submit.shape}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"X_treinamento=\" : (7723, 70), \"y_treinamento=\" : (7723,), \"X_teste=\":(3310, 70),\"y_teste=\":(3310,),\"X_submit=\":(1000, 70)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "hlK6ScvayItZ",
        "outputId": "2de6fc56-250a-42ac-9318-5121166b6373"
      },
      "source": [
        "#l_ts = [0.22, 0.24, 0.25, 0.26, 0.28, 0.30, 0.32]\n",
        "#l_it =  [300, 400, 500], \n",
        "#l_lr = [0.02, 0.03, 0.04]\n",
        "#l_depth = [2, 3, 4, 5]\n",
        "l_ts, l_it, l_lr, l_depth = [0.26], [400], [0.02], [3]\n",
        "resultado = {}\n",
        "\n",
        "for vez in range(1,11):\n",
        "   resultado[vez] = {\"ts\":[], \"it\":[], \"lr\":[],\"depth\":[],\"score\":[]}\n",
        "   for ts in l_ts:\n",
        "       print(f'execução {vez}/ts {ts}...')\n",
        "       for it in l_it:\n",
        "           for lr in l_lr:\n",
        "               for depth in l_depth:\n",
        "                  res = treina_testa(ts=ts, it=it, lr=lr, depth=depth,gerarArquivo=False, mostrarFI=False) #não vai salvar o arquivo e nem mostrar as melhores features\n",
        "                  resultado[vez][\"ts\"].append(ts)\n",
        "                  resultado[vez][\"it\"].append(it)\n",
        "                  resultado[vez][\"lr\"].append(lr)\n",
        "                  resultado[vez][\"depth\"].append(depth)\n",
        "                  resultado[vez][\"score\"].append(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execução 1/ts 0.26...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-c7cedf244408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreina_testa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgerarArquivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmostrarFI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#não vai salvar o arquivo e nem mostrar as melhores features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"it\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-cd249ff4f9ff>\u001b[0m in \u001b[0;36mtreina_testa\u001b[0;34m(ts, it, lr, depth, gerarArquivo, mostrarFI)\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mcatb_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0macc_catb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#print('ts: {} it: {} lr: {} depth: {} -> '.format(ts,it,lr,depth)+'Train Data Success Score: %' + str(acc_catb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmostrarFI\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 2869]"
          ]
        }
      ]
    }
  ]
}